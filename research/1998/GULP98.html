  <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
           "http://www.w3.org/TR/REC-html40/loose.dtd"><HTML>
<META NAME="GENERATOR" CONTENT="TtH 2.00">
                                                                   
<title>3cm</title>
3cm

<p>

<H2> Abstract</H2>
We describe a scheme for moving living code between a set
of distributed processes coordinated with
unification based Linda operations and its
application to building a comprehensive Logic programming based
Internet programming framework.
<em>Mobile threads</em> are implemented by capturing
first order continuations
in a compact data structure sent over the network.
Code is fetched lazily from its original base turned into a server
as the continuation executes at the remote site.
Our code migration techniques,
in combination with a dynamic recompilation scheme
ensure that heavily used code moves up smoothly on a speed
hierarchy while volatile dynamic code is kept in a 
quickly updatable form.
Among the examples, we describe how to build programmable client
and server components (Web servers, in particular)
and mobile agents.

<p>
<em>Keywords:
  mobile computations, remote execution, networking, Internet programming,
  first order continuations, Linda coordination,
  blackboard-based logic programming, mobile agents,
  dynamic recompilation, code migration
</em>
<p>
<p>        <H2><A NAME="tth_sEc1">
1</A>&nbsp;&nbsp;Introduction</H2> <A NAME="intro">
</A>

<p>
<em>Data mobility</em> has been present since
the beginning of networked computing, and is
now used in numerous applications -
from remote consultation of a database, to
Web browsing.

<p>
<em>Code mobility</em> followed, often made transparent
to users as with network files systems (i.e. Sun's NFS).
Java's ability to execute applets directly in client browsers,
can be seen as its most recent incarnation.

<p>
Migrating the state of the computation from one machine or process to
another, still requires a separate set of tools. Java's remote method
invocations (RMI) add <em>control mobility</em>
and a (partially) automated form of <em>object mobility</em>
i.e. integrated code (class) and data (state) mobility.
The Oz 2.0 distributed programming proposal of [<a href="#DOZmobility" name=CITEDOZmobility>25</a>]
makes <em>object mobility</em> more
transparent, although the mobile entity is still
the state of the objects, not ``live'' code.

<p>
Mobility of ``live code'' is called <em>computation mobility</em> 
[<a href="#cardelli97:mobile" name=CITEcardelli97:mobile>4</a>].
It requires interrupting execution, moving the state of a runtime system
(stacks, for instance) from one site to another and then resuming
execution. Clearly, for some languages, this can be hard or completely
impossible to achieve.

<p>
Telescript and General Magic's new
Odyssey [<a href="#odissey" name=CITEodissey>8</a>] agent programming
framework, IBM's Java based <em>aglets</em> as well as
Luca Cardelli's Oblique [<a href="#migratory" name=CITEmigratory>2</a>]
have pioneered implementation technologies achieving
<em>computation mobility</em>.

<p>
This paper will show that we can achieve
full <em>computation mobility</em> through our
<em>mobile threads</em>, without needing a specially designed new language.
They are implemented by a surprisingly small, source level
modification of the BinProlog system, taking advantage of
the availability of <em>first order
continuations</em><a href="#tthFtNtAAB" name=tthFrefAAB><sup>1</sup></a> 
as well as
of BinProlog's high level networking primitives.
Mobile threads complete our Logic Programming based Internet
programming infrastructure built in view of
creating Prolog components which can interoperate
with mainstream languages and programming environments.
<em>Mobile threads</em> can be seen as a refinement of <em>mobile
computations</em> as corresponding to <em>mobile partial computations</em>
of any granularity. <em>Mobile agents</em> can be seen as a collection
of synchronized <em>mobile threads</em> sharing common
state [<a href="#TD96:coord" name=CITETD96:coord>18</a>]. We achieve synchronization using
a variant of the Linda coordination protocol.

<p>
The paper is organized as follows:

<UL>
<p>

<li> section <A href="#infra">2</A> describes our networking infrastructure 
and Linda based client/server components

<li> Section <A href="#mobcode">3</A> describes our code migration and
  code acceleration techniques (dynamic recompilation)

<li> Section <A href="#mobcomp">4</A> describes our mobile computation mechanism, as follows: 
   subsection <A href="#engines">4.2</A> intriduces engines and threads,
   subsection <A href="#bin">4.3</A>) reviews the underlying binarization mechanism
     used to implement our first order continuations,
   subsection <A href="#mobthreads">4.4</A> explains how we implement thread mobility
   by capturing continuations (subsection <A href="#capt">4.4.1</A>)
   and moving them from their base to their target
     (subsection <A href="#contmoving">4.4.2</A>), how this can be emulated
     with remote predicate calls (subsection <A href="#mobemu">4.4.3</A>) and how how mobile 
     agents can be built within our framework (subsection <A href="#mobags">4.5</A>)

<li> section <A href="#rel">5</A> discusses related work

<li> section <A href="#conc">6</A> presents our conclusions and future work
</UL>
<p>
The main ``paradigm independent'' novelties of our contribution are:

<p>

<UL>
<li> a technique, based on intuitionistic assumptions for dealing with
 complex networking code componentwise

<li> use of first order continuations for implementing <em>mobile computations</em>

<li> a flexible thread mobility algorithm expressed in terms of client-server 
 role alternation and communication through Linda operations
</UL>
<p>
Our contributions are synergetically integrated into a powerful agent building
infrastructure, by putting together logic programming
based knowledge processing, Linda-style coordination, 
and live code migration through mobile threads.

<p>
        <H2><A NAME="tth_sEc2">
2</A>&nbsp;&nbsp;Basic Linda and Remote Execution Operations</H2> <A NAME="infra">
</A>

<p>
      <H3><A NAME="tth_sEc2.1">
2.1</A>&nbsp;&nbsp;Coordination of Linda clients</H3>

<p>
Our networking constructs are built on top of the popular
Linda [<a href="#linda89" name=CITElinda89>5</a>] coordination framework,
enhanced with unification based pattern
matching, remote execution and a set of simple
client-server components
merged together into a scalable peer-to-peer
layer, forming a `web of interconnected worlds':

<p>
<font size="-1">
<pre>
out(X): puts X on the server
in(X):  waits until it can take an object 
        matching X from the server
all(X,Xs): reads the list Xs matching X 
        currently on the server
</pre></font>

<p>
 The presence of the <tt>all/2</tt> collector
avoids the need for backtracking over multiple
remote answers.
Note that the only blocking operation is <tt>in/1</tt>.
Typically, distributed programming with Linda coordination
follows consumer-producer patterns (see Fig. <A href="#../mobile/linda">1</A>) 
with added flexibility over message-passing communication
through associative search.
Blocking <tt>rd/1</tt>, which waits until a matching term becomes
available, without removing it, is easily
emulated in terms of <tt>in/1</tt> and <tt>out/1</tt>,
while non-blocking <tt>rd/1</tt> is emulated with <tt>all/2</tt>.


<p><A NAME="tth_fIg1">
</A> 
<p>

<center></center> <center>      Figure 1: Basic Linda operations</center><A NAME="../mobile/linda">
</A>
<p>
<p>
      <H3><A NAME="tth_sEc2.2">
2.2</A>&nbsp;&nbsp;Remote Execution Mechanisms</H3>

<p>
Implementation of arbitrary remote execution is easy
in a Linda + Prolog system, due to Prolog's <em>metaprogramming</em>
abilities. No complex serialization/remote object
packages are needed. Our primitive remote call operation is:

<p>
<font size="-1">
<pre>
host(Other_machine)=&#62;&#62;
   remote_run(Answer,RemoteGoal).
</pre></font>

<p>
 It implements deterministic <em>remote predicate calls</em>
with (first)-answer or <tt>`no'</tt> returned to the calling site.

<p>
For instance, to iterate over the set of servers forming
the receiving end of our `Web of Worlds', after retrieving
the list from a `master server' which constantly monitors
them making sure that the list reflects login/logout
information, we simply override <tt>host/1</tt> and <tt>port/1</tt> with
intuitionistic implication &#62;&#62; [<a href="#Tarau97:BinProlog" name=CITETarau97:BinProlog>15</a>,<a href="#DT97:AGNL" name=CITEDT97:AGNL>6</a>]:

<p>
<font size="-1">
<pre>
ask_all_servers(Channel,Servers,Query):-
  member(server_id(Channel,H,P),Servers),
  host(H)=&#62;&#62;port(P)=&#62;&#62;
    ask_a_server(Query,_),
  fail;true.
</pre></font>

<p>
 Note that a <tt>Channel</tt> pattern is used to select a subset
of relevant servers, and in particular, when <tt>Channel</tt> is
a ``match all'' free logical variable,  all of them.
By using term subsumption this allows building sophisticated "publish/subscribe"
communication patterns hierarchies.

<p>
      <H3><A NAME="tth_sEc2.3">
2.3</A>&nbsp;&nbsp;Servants: basic Linda agents</H3> <A NAME="servant">
</A>

<p>
 A <em>servant</em> is one of the simplest possible <em>agents</em>,
which pulls commands from a server and runs them locally:

<p>
<font size="-1">
<pre>
servant:-
  in(todo(Task)),
  call(Task),
  servant.
</pre></font>

<p>
 Note that <em>servant</em> is  started as a background thread.
No `busy wait' is involved,
as the servant's thread
blocks until <tt>in(todo(Task))</tt>
succeeds.
More generally, distributed event processing is implemented
by creating a `watching' agent attached to a thread
for each pattern.

<p>
As <em>servants</em>
pulling commands are operationally indistinguishable from
<em>servers</em> acting upon clients' requests, they
can be used as emulators for <em>servers</em>.
A class of obvious applications of this ability
is their use as pseudo-servers running on
machines with dynamically allocated
IP addresses (as offered by most ISP today),
laying behind firewalls.
This mechanism also works when, because of
security restrictions, server components
cannot be reached from outside, as in the case of
<em>Java applets</em> which cannot listen on ports of
the client side machine.

<p>
      <H3><A NAME="tth_sEc2.4">
2.4</A>&nbsp;&nbsp;Server side code</H3>

<p>
Servants as well as other clients can connect to
BinProlog <em>servers</em>.
Higher order <em>call/N</em> [<a href="#mycroft:poli" name=CITEmycroft:poli>13</a>], 
combined with intuitionistic assumptions <tt>``=&#62;&#62;''</tt>,
are used to pass arbitrary <em>interactors</em> to
generic server code:

<p>
<font size="-1">
<pre>

run_server(Port):-
  new_server(Port,Server),
  register_server(Port),
  server(Server)=&#62;&#62;server_loop,
  close_socket(Server).

server_loop:-
  repeat,
    interact,   
  assumed(server_done),
  !.

interact:-
  assumed(Interactor),
  assumed(Server),
  % higher-order call to interactor 
  call(Interactor,Server).
</pre></font>

<p>
 Note the use of a specialized <em>server-side</em> interpreter
<tt>server_loop</tt>, configurable through the use of higher-order 
`question/answer' closures we have called <em>interactors</em>.

<p>
The components of a `generic' default server can be 
overridden through the use of <em>intuitionistic
implication</em> to obtain customized special purpose servers.
The use of intuitionistic implications  
 (pioneered by
Miller's work [<a href="#Miller89Lex" name=CITEMiller89Lex>12</a>]) helps to overcome 
(to some extent) Prolog's lack
of object oriented programming facilities,
by allowing us to `inject' the right interactor into
the generic (and therefore reusable) interpreter.
BinProlog's <tt>``=&#62;&#62;''</tt> temporarily assumes a clause
in <tt>asserta</tt> order, i.e. at the beginning of the predicate.
The assumption is scoped to be only usable to prove its
right side goal and vanishes on backtracking.
We refer to [<a href="#Tarau97:BinProlog" name=CITETarau97:BinProlog>15</a>,<a href="#TDF:asian96" name=CITETDF:asian96>21</a>,<a href="#DT97:AGNL" name=CITEDT97:AGNL>6</a>]
for more information on assumptions and their applications.

<p>
      <H3><A NAME="tth_sEc2.5">
2.5</A>&nbsp;&nbsp;Modular HTTP server component building: <em>do or delegate</em></H3>

<p>
We will show in this section a typical application of our component based server
building technology: how to enhance efficiently the HTTP protocol, to handle
server side Prolog scripts directly, without using GGIs or vendor specific
server side extensions.

<p>
The top goal of the HTTP server looks as follows:

<p>
<font size="-1">
<pre>
run_http_server:-
  server_action(http_server_action)=&#62;&#62;run_server.

http_server_action(ServiceSocket):-
  socket(ServiceSocket)=&#62;&#62;http_server_step(ServiceSocket).
</pre></font>

<p>
The <tt>http_server_action</tt> is passed to the inner server
loop using intuitionistic implication. This allows reusing
general server logic, independently of a particular protocol.
The action itself is described in <tt>http_server_step</tt>: it
consists of preparing a fall-back mechanism to a standard
HTTP server, unless the request is for a file recognized as
Prolog code, using the <em>redirection</em> facilities built
in the HTTP protocol. 
<p>
<font size="-1">
<pre>
http_server_step(Socket):-
  ( assumed(fallback_server(FallBackServer))-&#62;true
  ; FallBackServer="http://localhost:80"
  ),
  server_try(Socket,sock_readln(Socket,Question)),
  http_get_client_header(Socket,Header),
  http_process_query(Socket,Question,Header,FallBackServer).
</pre></font>

<p>
Our very simple query processor uses Assumption Grammars [<a href="#DT97:AGNL" name=CITEDT97:AGNL>6</a>].
Their ability to handle multiple DCG streams [<a href="#TDF:asian96" name=CITETDF:asian96>21</a>] are instrumental,
as we use more than one independent grammar processor in the process.

<p>
<font size="-1">
<pre>
http_process_query(Socket,Qs,Css,FallBackServer):-
  #&lt;Qs, % sets input string from grammar
  match_word("GET "),
  match_before(" ",PathFile,_),
  match_word("HTTP/"),
  #&#62;_version, % 
  !,
  split_path_file(PathFile,Ds,Fs),
  !,
  has_text_file_sufix(Fs,Suf),
  !,
  ( Suf=".pro"-&#62;http_process_local(Socket,Ds,Fs,Suf,Css)
  ; write('redirecting '),write_chars(Ds),write_chars(Fs),nl,
    http_send_line(Socket,"HTTP/1.0 302 Found"),
    make_cmd0(["Location: ",FallBackServer,Ds,Fs],Redirect),
    http_send_line(Socket,Redirect),
    http_send_line(Socket,"")
  ),
  close_socket(Socket).
</pre></font>

<p>
Our HTTP server component fits in 76 lines of code and can be used
to set up Prolog based Web processing by simply staring it in
a command window on any Unix machine or PC, with no execution overhead,
as in the case of with CGI scripts. It basically offers the advantages
of server side includes (SSIs) without requiring integration
into a server, often subject to using the languages the server
supports.

<p>
      <H3><A NAME="tth_sEc2.6">
2.6</A>&nbsp;&nbsp;Master Servers: Connecting a Web of Virtual Places</H3>

<p>
A <em>virtual place</em> is implemented as a server listening
on a port which can spawn clients in the same
or separate threads interacting with other servers.

<p>
A master server on a `well-known' host/port
is used as a registration service to exchange identification information
among peers composed of clients and a server, usually running as threads of the same process.

<p>
As in the case of the HTTP server we can derive a master server by specializing
its interactor components through intuitionistic implications.

<p>
        <H2><A NAME="tth_sEc3">
3</A>&nbsp;&nbsp;Code migration and code acceleration techniques</H2> <A NAME="mobcode">
</A>

<p>
We have seen that setting up a self contained networking infrastructure
(Web protocols included) is fairly simple. The next step is emphasizing
on mobile agent support, particularly promising in synergy with
knowledge processing capabilities  - a key strength of Logic Programming
systems.

<p>
      <H3><A NAME="tth_sEc3.1">
3.1</A>&nbsp;&nbsp;Lazy code fetching</H3>

<p>
In BinProlog, code is fetched lazily over the network,
one predicate at a time, as needed by the execution flow.

<p>
Code is cached in a local database and then
dynamically recompiled on the fly if usage statistics
indicate that it is <em>not volatile</em> and it is <em>heavily used</em>
locally. 

<p>
The following operations

<p>
<font size="-1">
<pre>
host(Other_machine)=&#62;&#62;rload(File).
host(Other_machine)=&#62;&#62;code(File)=&#62;&#62;TopGoal.
</pre></font>

<p>
 allow fetching remote files <tt>rload/1</tt> or
on-demand fetching of a predicate at a time from a remote
host during execution of <tt>TopGoal</tt>. 

<p>
This is basically the same
mechanism as the one implemented for Java applet code fetching,
except that we have also implemented a caching mechanism,
at predicate level (predicates are cached as dynamic code
on the server to efficiently serve multiple clients).

<p>
      <H3><A NAME="tth_sEc3.2">
3.2</A>&nbsp;&nbsp;Dynamic recompilation</H3>

<p>
Dynamic recompilation is used on the client side to speed-up heavily
used, relatively non-volatile predicates.  With dynamically recompiled
consulted code, listing of sources and dynamic modification to any
predicate is available, while average performance stays close to
statically compiled code (usually within a factor of 2-3).

<p>
Our implementation of dynamic recompilation for BinProlog
is largely motivated by the difficulty/complexity of relying 
on the programmer
to specify execution methods for remote code.

<p>
The intuition behind the dynamic recompilation algorithm of BinProlog is
that <em>update</em> vs. <em>call</em> based <em>statistics</em> are associated
to each predicate declared or detected as dynamic.
Dynamic (re)compilation is triggered for relatively non-volatile predicates,
which are promoted on the <em>`speed-hierarchy'</em> to a faster
implementation method (interpreted <tt>-&#62;</tt> bytecode <tt>-&#62;</tt> native).
The process is restarted from the `easier to change' interpreted
representation, kept in memory in a compact form,
upon an update.

<p>
We can describe  BinProlog's dynamic <em>`recompilation
triggering statistics'</em> through a simple `thermostat' metaphor.
<em>Updates</em> (assert/retract) to a predicate have the effect of increasing its
associated `temperature', while <em>Calls</em>
will decrease it. Non-volatile (`cool') predicates 
are dynamically recompiled, while recompilation is avoided 
for volatile (`hot') predicates.
A <em>ratio</em> based on cooling factors (number of calls,
compiled/interpreted execution speed-up etc.) and
heating factors (recompilation time, number of updates etc.)
smoothly adjusts for optimal overall performance,
usually within a factor of 2 from static code.

<p>
        <H2><A NAME="tth_sEc4">
4</A>&nbsp;&nbsp;Computation Mobility with Threads and Continuations</H2> <A NAME="mobcomp">
</A>

<p>
      <H3><A NAME="tth_sEc4.1">
4.1</A>&nbsp;&nbsp;Why computations need to be mobile?</H3>

<p>
Advanced <em>mobile object</em> and <em>mobile agents</em> agent systems
have been built on top of Java's dynamic class loading and
its new reflection and remote method invocation classes.
IBM Japan's Aglets or General Magic's Odyssey
provide comprehensive mobility of code and data.
Moreover, data is encapsulated as state of objects.
This property allows protecting sensitive components of it
more easily. Distributed Oz 2 provides fully transparent
movement of objects over the network, giving the illusion
that the same program runs on all the computers.

<p>
So <em>why do we need</em> the apparently more powerful
concept of mobile ``live code'' i.e. mobile execution state?

<p>
Our answer to this question is that live mobile code is needed because
is still <em>semantically simpler</em> than
mobile object schemes. Basically, all that a programmer
needs to know is that his or her program has moved to
a new site and it is executing there. A unique (in our case
<tt>move_thread</tt>) primitive, with an
intuitive semantics,  needs to be learned.
When judging about how appropriate a language feature is,
we think that the way it looks to the end user is among the
most important ones. For this reason, mobile threads are
competitive with sophisticated <em>object mobility</em> constructs
on ``end-user ergonomy'' grounds,
while being fairly simple to implement, as we have shown,
in languages in which continuations can be easily
represented as data structures.

<p>
And <em>what if the host language does not offer first order
continuations</em>? A simple way around this is to implement
on top of it a script interpreter (e.g. a subset of Scheme or Prolog)
which does support them! As it is a good idea to limit code
migration to lightweight scripts anyway, this is a very
practical solution for either C/C++ or Java based mobile
code solutions, without requiring class-specific 
serialization mechanisms.

<p>
      <H3><A NAME="tth_sEc4.2">
4.2</A>&nbsp;&nbsp;Engines and Answer Threads</H3> <A NAME="engines">
</A>

<p>
Mobile computations really make sense only when multiple computation threads
can coexist at a given place. We build this infrastructure in two steps:
an engine encapsulating the state of an independent computation and a thread
actually running it. Note that engines can also be used without multi-threading,
as a form of coroutining.

<p>
       <H4><A NAME="tth_sEc4.2.1">
4.2.1</A>&nbsp;&nbsp;Engines</H4>
BinProlog allows launching
multiple Prolog engines having their own stack groups (heap, local stack
and trail). An engine can be seen as an abstract data-type which
produces a (possibly infinite) stream of solutions as needed.
To create a new engine, we use:

<p>
<font size="-1">
<pre>
  create_engine(+HeapSize,+StackSize,+TrailSize,-Handle)
</pre></font>

<p>
 or, by using default parameters for the stacks:

<p>
<font size="-1">
<pre>
  create_engine(-Handle)
</pre></font>

<p>
 The <tt>Handle</tt> is a unique integer denoting the engine for further
processing.
To `fuel' the engine with a goal and an expected answer variable
we use:

<p>
<font size="-1">
<pre>
  load_engine(+Handle,+Goal,+AnswerVariable)
</pre></font>

<p>
 No processing, except the initialization of the
engine takes place, and no answer
is returned with this operation.

<p>
To get an answer from the engine we use:
<font size="-1">
<pre>
  ask_engine(+Handle,-Answer)
</pre></font>

<p>
 Each engine has its own heap garbage collection process
and backtracks independently using its choice-point stack and trail
during the computation of an answer.
Once computed, an answer is copied from an engine to its ``master''.

<p>
When the stream of answers reaches its end, <tt>ask_engine/2</tt>
will simply fail. The resolution process in an engine
can be discarded at any time by simply loading another goal
with <tt>load_engine/3</tt>. This allows avoiding the
cost of backtracking, for instance in the case when a single
answer is needed, as well as garbage collection costs.

<p>
If for some reason we are not interested in the engine any more,
we can free the space allocated to the engine and completely discard it with:

<p>
<font size="-1">
<pre>
  destroy_engine(+Handle)
</pre></font>

<p>
 The following example <a href="#tthFtNtAAC" name=tthFrefAAC><sup>2</sup></a> in the BinProlog distribution [<a href="#Tarau97:BinProlog" name=CITETarau97:BinProlog>15</a>]
shows a sequence of the previously described operations:

<p>
<font size="-1">
<pre>
 ?-create_engine(E),
   load_engine(E,append(As,Bs,[1,2]),As+Bs),
   ask_engine(E,R1),write(R1),nl,
   ask_engine(E,R2),write(R2),nl,
   destroy_engine(E).
</pre></font>

<p>
 Multiple  `orthogonal engines' as shown in Figure <A href="#ortho">1</A>
enhance the expressiveness of
Prolog by allowing an AND-branch of an engine to
collect answers from multiple OR-branches of another engine.
They give to the programmer the means to see
as an abstract sequence and control, the answers
produced by an engine, in a way
similar to Java's <tt>Enumeration</tt> interface.

<p>

<p><A NAME="tth_fIg2">
</A> 
<center></center> <center>      Figure 2: Orthogonal Engines</center><A NAME="ortho">
</A>
<p>
<p>
       <H4><A NAME="tth_sEc4.2.2">
4.2.2</A>&nbsp;&nbsp;Threads</H4>

<p>
Engines can be assigned to their own thread by using
BinProlog's thread package (currently fully implemented on win32 platform).
A unique primitive is needed,
<font size="-1">
<pre>
   ask_thread(E,R)
</pre></font>

<p>
which launches a new thread <tt>R</tt> to perform the computation of
an answer of engine <tt>E</tt>.
On top of this facility each thread can implement a separate server,
client or become the base of a mobile agent.

<p>
Thread synchronization is provided through monitor objects, handled
with:

<p>
<font size="-1">
<pre>
   synchronize_on(Monitor,Goal,Answer)
</pre></font>

<p>
The thread waits until the monitor is free, executes Goal, frees the monitor and
returns Answer.

<p>
The thread attached to an engine can be obtained with: 

<p>
<font size="-1">
<pre>
   get_engine_thread(Engine,Thread)
</pre></font>

<p>
and can be controlled directly with:

<p>
<font size="-1">
<pre>
  thread_suspend(Thread) % suspends the thread
  thread_resume(Thread)  % resumes a suspended thread
  thread_join(Thread)   % waits until a thread terminates
  thread_cancel(Thread) % discards a thread
</pre></font>

<p>
      <H3><A NAME="tth_sEc4.3">
4.3</A>&nbsp;&nbsp;First order Continuations through Binarization</H3> <A NAME="bin">
</A>

<p>
Having first order continuations largely simplifies implementation of
mobile code operations - a thread is suspended, its continuation is packed,
sent over the network and resumed at a different place.

<p>
We will shortly explain here BinProlog's continuation passing
preprocessing technique, which results in availability of
continuations as data structures accessible to the programmer.

<p>

<b>The binarization transformation&nbsp;&nbsp;</b>
Binary clauses have only one atom in the body
(except for some in-line `builtin' operations like arithmetics),
and therefore they need no `return' after a call.
A transformation introduced in [<a href="#Tarau90:PLILP" name=CITETarau90:PLILP>17</a>] allows to
faithfully represent logic programs with operationally equivalent
binary programs.

<p>
To keep things simple, we will describe our transformations in the case
of definite programs.
We will follow here the notations of [<a href="#pt93b" name=CITEpt93b>23</a>].

<p>
Let us define the <em>composition</em> operator <font face=symbol>Å</font
> 
that combines clauses by unfolding the leftmost body-goal
of the first argument.

<p>
Let <tt>A<sub>0</sub>:-A<sub>1</sub>,A<sub>2</sub>,...,A<sub>n</sub></tt> and 
<tt>B<sub>0</sub>:-B<sub>1</sub>,...,B<sub>m</sub></tt> be two clauses (suppose n<font face=symbol> &gt; </font
>0, m <font face=symbol>³</font
> 0). We define 
 <tt>(A<sub>0</sub>:-A<sub>1</sub>,A<sub>2</sub>,...,A<sub>n</sub>)</tt> <font face=symbol>Å</font
> 
<tt>(B<sub>0</sub>:-B<sub>1</sub>,...,B<sub>m</sub>) = (A<sub>0</sub>:-B<sub>1</sub>,...,B<sub>m</sub>,A<sub>2</sub>,...,A<sub>n</sub>)</tt><font face=symbol>q</font
>

<p>
with <font face=symbol>q</font
> = mgu(<tt>A<sub>1</sub></tt>,<tt>B<sub>0</sub></tt>). If the atoms <tt>A<sub>1</sub></tt> and
<tt>B<sub>0</sub></tt> do not unify, the result of the composition is denoted as <font face=symbol>^</font
>.
Furthermore, as usual, we consider <tt>A<sub>0</sub>:-true,A<sub>2</sub>,...,A<sub>n</sub></tt> 
to be equivalent to <tt>A<sub>0</sub>:-A<sub>2</sub>,...,A<sub>n</sub></tt>, and for any clause <tt>C</tt>, <tt><font face=symbol>^</font
> <font face=symbol>Å</font
> C = C <font face=symbol>Å</font
> <font face=symbol>^</font
> = <font face=symbol>^</font
></tt>.
We assume that at least one operand has been renamed to a variant with
 variables standardized apart. 

<p>
This Prolog-like inference rule is called LD-resolution and it has
the advantage of giving a more accurate description of Prolog's operational semantics than SLD-resolution.
Before introducing the binarization transformation, we describe two
auxiliary transformations.

<p>
The first transformation converts facts into rules by  giving
them the atom <tt>true</tt> as body. E.g., the fact <tt>p</tt> is
transformed into the rule <tt>p :- true</tt>.

<p>
The second transformation, inspired by [<a href="#Warren82" name=CITEWarren82>27</a>],
eliminates the metavariables by wrapping them in a <tt>call/1</tt> goal.
E.g., the rule <tt>and(X,Y):-X, Y</tt> is transformed into <tt>
and(X,Y) :- call(X), call(Y).</tt>

<p>
The transformation of [<a href="#Tarau90:PLILP" name=CITETarau90:PLILP>17</a>]
(<em>binarization</em>) adds continuations
as  extra   arguments  of   atoms  in a way that  preserves
also first argument indexing.

<p>
Let   P be  a definite  program  and Cont  a  new
variable. Let  T and E = p(T<sub>1</sub>,...,T<sub>n</sub>) be  two 
expressions.<a href="#tthFtNtAAD" name=tthFrefAAD><sup>3</sup></a> We  denote by
<font face=symbol>y</font
>(E,T) the expression p(T<sub>1</sub>,...,T<sub>n</sub>,T). 
Starting with the clause

<p>
<tt>(C)</tt>  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A :- B<sub>1</sub>,B<sub>2</sub>,...,B<sub>n</sub>.

<p>
 we construct the clause

<p>
<tt>(C')</tt>  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font face=symbol>y</font
>(A,Cont) :- <font face=symbol>y</font
>(B<sub>1</sub>,<font face=symbol>y</font
>(B<sub>2</sub>,...,<font face=symbol>y</font
>(B<sub>n</sub>,Cont))).
                         
<p>
The set P<font face=symbol>¢</font
> of all clauses <tt>C'</tt> obtained from the clauses of P is called
the binarization of P. 

<p>
The following example shows the result of this
transformation on the well-known `naive reverse' program:

<p>
<font size="-1">
<pre>
   app([],Ys,Ys,Cont):-true(Cont).
   app([A|Xs],Ys,[A|Zs],Cont):-
     app(Xs,Ys,Zs,Cont).

   nrev([],[],Cont):-true(Cont).
   nrev([X|Xs],Zs,Cont):-
     nrev(Xs,Ys,app(Ys,[X],Zs,Cont)).
</pre></font>

<p>
 The transformation preserves a
strong operational equivalence with the
original program with respect to the LD resolution rule, which
is <em>reified</em> in the syntactical structure of the
resulting program, i.e. each resolution step
of an LD derivation on a definite program P
can be mapped to an SLD-resolution step of the binarized program P<font face=symbol>¢</font
>.

<p>
Clearly, continuations become explicit in the binary version of the program.
We have devised a technique to access and manipulate them in an intuitive
way, by modifying BinProlog's binarization preprocessor.
Basically, the clauses constructed with <tt>::-</tt> instead of <tt>:-</tt>
are considered as being already in binary form, and not subject
therefore to further binarization. By explicitly accessing
their arguments, a programmer is able to access and modify the
current continuation as a `first order object'.
Note however that code <em>referring</em> to the continuation
is also <em>part</em> of it, so that some care should be taken in
manipulating the circular term representing the continuation
from `inside'.

<p>
      <H3><A NAME="tth_sEc4.4">
4.4</A>&nbsp;&nbsp;Mobile threads: Take the <em>Future</em> and Run</H3> <A NAME="mobthreads">
</A>

<p>
As continuations (describing <em>future</em> computations
to be performed at a given point)
are first order objects in BinProlog,
it is easy to extract from them a conjunction of goals
representing
<em>future</em> computations intended to be performed at
another site,
send it over the network and resume working on it
at that site.
The natural unit of mobility is a <em>thread</em>
moving to a server executing multiple
local and remotely originated threads.
<em>Threads communicate with their local and remote
counterparts, listening on ports
through the Linda protocol, as described in [<a href="#dbt95a" name=CITEdbt95a>7</a>]</em>.
This combination of Linda based coordination and thread
mobility is intended to make building complex, pattern based
agent scripts fairly easy.

<p>
       <H4><A NAME="tth_sEc4.4.1">
4.4.1</A>&nbsp;&nbsp;Capturing continuations</H4> <A NAME="capt">
</A>

<p>
Before moving to another site, the current continuation
needs to be captured in a data structure (see Appendix I).
For flexibility, a wrapper <tt>capture_cont_for/1</tt>
is used first to
restrict the scope of the continuation to
a (deterministic) toplevel <tt>Goal</tt>. This avoids taking
irrelevant parts of the continuation (like prompting the user
for the next query) to the remote site inadvertently.

<p>
A unique logical variable is used through a backtrackable linear
assumption <tt>cont_marker(End)</tt> to mark the end
of the scope of the continuation with <tt>end_cont(End)</tt>.

<p>
From inside the continuation, <tt>call_with_cont/1</tt> is used to
extract the relevant segment of the continuation.  Towards
this end, <tt>consume_cont(Closure,Marker)</tt> extracts a conjunction of
goals from the current continuation until Marker is reached, and then it
applies <tt>Closure</tt> to this conjunction (calls it with the
conjunction passed to <tt>Closure</tt> as an argument).

<p>
Extracting the continuation itself
is easy, by using BinProlog's ability to
accept user defined binarized clauses
(introduced with ::- instead of :-),
accessing the continuation as a `first order' object:

<p>
<font size="-1">
<pre>
  get_cont(Cont,Cont)::-true(Cont).
</pre></font>

<p>
       <H4><A NAME="tth_sEc4.4.2">
4.4.2</A>&nbsp;&nbsp;The Continuation Moving Protocol</H4> <A NAME="contmoving">
</A>

<p>
Our continuation moving protocol can be described easily in terms
of synchronized <em>source side</em><a href="#tthFtNtAAE" name=tthFrefAAE><sup>4</sup></a>,
and <em>target side</em> operations.

<p>

<b>Source side operations&nbsp;&nbsp;</b>

<UL>
<p>

<li> wrap a Goal
with a unique terminator marking the end of the continuation to be
captured, and call it with the current continuation available
to it through a linearly assumed fact<a href="#tthFtNtAAF" name=tthFrefAAF><sup>5</sup></a>

<p>

<li> reserve a free port P for the future code server

<li> schedule on the target server a sequence of actions
 which will lead to resuming the execution from right after the
 <tt>move_thread</tt> operation (see target
side operations), return and become a code server allowing the mobile
thread to fetch required predicates one a time
</UL>
<p>

<b>Target side operations&nbsp;&nbsp;</b> are scheduled as a sequence of goals
extracted from the current continuation at the <em>source side </em>, and received
over the network together with a small set of synchronization commands:

<p>

<UL>
<li> schedule as delayed task a sequence of goals received from the
source side and return

<li> wait until the <em>source side</em> is in server mode

<li> set up the back links to the source side as assumptions

<li> execute the delayed operations representing the moved continuation

<li> fetch code from the source side as needed for execution of the goals
of the moved continuations and their subcalls

<li> shut down the code server on the source side
</UL>
<p>
Communication between the base and the target side
is done with <em>remote predicate calls</em>
protected with <em>dynamically generated passwords</em>
shared between the two sides before the migratory
component ``takes off''.

<p>
Initially the target side waits in server mode. Once the continuation
is received on the target side, the source side switches in server mode
ready to execute code fetching and persistent database
update requests from its mobile counterpart on the target side.

<p>
Fig. <A href="#mob">2</A> shows the connections between a mobile thread
and its base.

<p>
Note that when the base turns into a server, it offers its
<em>own code</em> for remote use by the moved thread - a kind of
virtual ``on demand'' process cloning operation, one step
at a time. As the server actually acts as a code cache,
multiple moving threads can benefit from this operation.
Note also that only predicates needed for the migratory
segment of the continuation are fetched. This ensures
that migratory code is kept lightweight for most mobile
applications. Synchronized communication, using Linda
operations can occur between the mobile thread and
its base server, and through the server, between
multiple mobile threads which have migrated to various
places.

<p>
As our networking infrastructure, our <em>mobile threads</em> are
platform independent. Like Java, BinProlog [<a href="#bp7user" name=CITEbp7user>16</a>] is a platform
independent emulator based language.
As a consequence, a thread can start on a Unix machine and
move transparently to a Windows NT system and back.
For faster, platform specific
execution, BinProlog provides compilation to C of static code using
an original partial translation technique described in [<a href="#tdb95rev" name=CITEtdb95rev>24</a>].

<p>

<p><A NAME="tth_fIg3">
</A> 
<center></center> <center>      Figure 3: Launching a mobile thread from its base</center><A NAME="mob">
</A>
<p>
<p>
       <H4><A NAME="tth_sEc4.4.3">
4.4.3</A>&nbsp;&nbsp;Emulating computation mobility through control mobility</H4> <A NAME="mobemu">
</A>

<p>
As shown in [<a href="#TDB:97" name=CITETDB:97>20</a>],
part of the functionality of <em>mobile computations</em> can be emulated
in terms of remote predicate calls combined with remote
code fetching.
An implicit <em>virtual place</em> (host+port) can be set as the target
of the remote calls.
Then, it is enough to send the top-level goal
to the remote side and have it fetch the code as needed from
a server at the site from where the code originates.

<p>
Note however that this is less efficient in terms of network
transactions and less reliable than
sending the full continuation at once as with
our <em>mobile threads</em>.

<p>
      <H3><A NAME="tth_sEc4.5">
4.5</A>&nbsp;&nbsp;Mobile Agents</H3> <A NAME="mobags">
</A>

<p>
<em>Mobile agents</em> can be seen as a collection
of synchronized <em>mobile threads</em> sharing common
state [<a href="#TD96:coord" name=CITETD96:coord>18</a>].

<p>
Mobile agents are implemented by iterating <em>thread mobility</em> over
a set of servers<a href="#tthFtNtAAG" name=tthFrefAAG><sup>6</sup></a> known to a given master server.
An efficient pyramidal deployment strategy can be used
to efficiently implement, for instance,
<em>push technology</em> through mobile
agents. Inter-agent communication can be achieved either by rendez-vous
of two mobile threads at a given site, by communicating through
a local Prolog database, or through the base server known to
all the deployed agents.
Communication with the base server
is easily achieved through remote predicate calls with
<tt>remote_run</tt>.
Basic security of mobile agents is achieved with
randomly generated passwords,
required for <tt>remote_run</tt> operations, and
by running them on a restricted BinProlog machine,
without user-level file write and
external process spawn operations.

<p>
        <H2><A NAME="tth_sEc5">
5</A>&nbsp;&nbsp;Related work</H2> <A NAME="rel">
</A>

<p>
Remote execution and code migration techniques are
pioneered by [<a href="#Alme85" name=CITEAlme85>1</a>,<a href="#Jul88" name=CITEJul88>10</a>,<a href="#Stam90" name=CITEStam90>14</a>]. Support for
remote procedure calls (RPC) are part of major operating
systems like Sun's Solaris and Microsoft's Windows NT.

<p>
A very large number of research projects
have recently started on mobile computations/mobile agent programming.
Among the pioneers, Kahn and Cerf's Knowbots [<a href="#knowbots" name=CITEknowbots>11</a>].
Among the most promising recent developments,
Luca Cardelli's Oblique project at  Digital and
mobile agent applications [<a href="#migratory" name=CITEmigratory>2</a>]
and IBM Japan's aglets [<a href="#aglets" name=CITEaglets>9</a>].
Mobile code technologies are pioneered by General Magic's
Telescript (see [<a href="#odissey" name=CITEodissey>8</a>] for their last Java based
<em>mobile agent</em> product). General Magic's Portico
software combines mobile code technologies and
voice recognition based command language (MagicTalk).
Another mobility framework, sharing some of our objectives
towards transparent high level distributed programming
is built on top of Distributed Oz [<a href="#DOZmobility" name=CITEDOZmobility>25</a>,<a href="#DOZmobs" name=CITEDOZmobs>26</a>],
a multi-paradigm language, also including a logic programming
component.
Although thread mobility is not implemented in Distributed Oz 2,
some of this functionality can be emulated in terms of
network transparent mobile objects.
Achieving the illusion of a unique application transparently
running on multiple sites makes implementing shared
multi-user applications particularly easy.
We can emulate this by implementing mobile agents (e.g.
avatars) as mobile threads with parts of the shared world <em>visible</em>
to an agent represented as dynamic facts, lazily replicated through our
lazy code fetching scheme when the agent moves.
Both Distributed Oz 2 and our BinProlog based infrastructure
need a full language processor
(Oz 2 or BinProlog) to be deployed at each node.
However, assuming that a Java processor is already installed,
our framework's Java client (see [<a href="#TDB:97" name=CITETDB:97>20</a>,<a href="#TDBwetice:97" name=CITETDBwetice:97>19</a>])
allows this functionality to be available through
applets attached to a server side BinProlog thread.
A calculus of <em>mobility</em> dealing with containers,
called <em>ambients</em>, is described in [<a href="#cardelli97:ambients" name=CITEcardelli97:ambients>3</a>].
The calculus covers at very high level of generality movement
and permissions to move from one ambient to another and
show how fundamental computational mechanisms like Turing machines
as well as process calculi can be expressed within the formalism.
Our <em>coordination logic</em> of
[<a href="#TD96:coord" name=CITETD96:coord>18</a>]
introduces similar concepts,
based on programming mobile avatars
in shared virtual worlds.
Two classes of containers, <em>clonable</em> and <em>unique</em>
regulate creation of new instances (clones) and
non-copiable (unique) entities (like electronic money),
as well as their movement.

<p>
        <H2><A NAME="tth_sEc6">
6</A>&nbsp;&nbsp;Conclusion</H2> <A NAME="conc">
</A>

<p>
We have described how mobile threads are implemented by capturing
first order continuations in a data structure sent over the network.
Supported by <em>lazy code fetching</em> and
<em>dynamic recompilation</em>,
they have been shown to be
an effective framework for
implementing mobile agents.

<p>
The techniques presented here are not (Bin)Prolog specific.
The most obvious porting target of our design is to functional
languages featuring first order continuations and threads.
Another porting target is Java and similar object oriented languages
having threads, reflection classes and
remote method invocation.
We are working on a Java based component
using an embedded continuation passing Prolog interpreter
which is already able to interoperate with BinProlog 
(latest version at urlhttp://www.binnetcorp.com/Jinni ).
An interesting application is using BinProlog as an accelerator
for Java based threads through migration to BinProlog, execution of
a computationally intensive task and return to the Java component.

<p>
Future work will focus on intelligent mobile agents integrating
knowledge and controlled natural language processing abilities,
following our previous work described in [<a href="#TDRB97:chi" name=CITETDRB97:chi>22</a>].

<p>
<H2>References</H2>
<DL compact>

<p>
<dt>[<a href="#CITEAlme85" name=Alme85>1</a>]</dt><dd>
G.&nbsp;T. Almes, A.&nbsp;P. Black, E.&nbsp;D. Lazowska, and J.&nbsp;D. Noe.
 The Eden System: A Technical Review.
 <em>IEEE Transactions on Software Engineering</em>, 11(1):43-59,
  January 1985.

<p>
<dt>[<a href="#CITEmigratory" name=migratory>2</a>]</dt><dd>
K.&nbsp;A. Bharat and L.&nbsp;Cardelli.
 Migratory applications.
 In <em>Proceedings of the 8th Annual ACM Symposium on User
  Interface Software and Technology</em>, Nov. 1995.
 http://gatekeeper.dec.com/ pub/DEC/SRC/research-reports/
  abstracts/src-rr-138.html.

<p>
<dt>[<a href="#CITEcardelli97:ambients" name=cardelli97:ambients>3</a>]</dt><dd>
L.&nbsp;Cardelli.
 Mobile ambients.
 Technical report, Digital, 1997.
 http://www.research.digital.com/
  SRC/personal/Luca_Cardelli/Papers.html.

<p>
<dt>[<a href="#CITEcardelli97:mobile" name=cardelli97:mobile>4</a>]</dt><dd>
L.&nbsp;Cardelli.
 Mobile Computation.
 In J.&nbsp;Vitek and C.&nbsp;Tschudin, editors, <em>Mobile Object Systems
  - Towards the Programmable Internet</em>, pages 3-6. Springer-Verlag,
  LNCS&nbsp;1228, 1997.

<p>
<dt>[<a href="#CITElinda89" name=linda89>5</a>]</dt><dd>
N.&nbsp;Carriero and D.&nbsp;Gelernter.
 Linda in context.
 <em>CACM</em>, 32(4):444-458, 1989.

<p>
<dt>[<a href="#CITEDT97:AGNL" name=DT97:AGNL>6</a>]</dt><dd>
V.&nbsp;Dahl, P.&nbsp;Tarau, and R.&nbsp;Li.
 Assumption Grammars for Processing Natural Language.
 In L.&nbsp;Naish, editor, <em>Proceedings of the Fourteenth International
  Conference on Logic Programming</em>, pages 256-270, MIT press, 1997.

<p>
<dt>[<a href="#CITEdbt95a" name=dbt95a>7</a>]</dt><dd>
K.&nbsp;De&nbsp;Bosschere and P.&nbsp;Tarau.
 Blackboard-based Extensions in Prolog.
 <em>Software - Practice and Experience</em>, 26(1):49-69, Jan. 1996.

<p>
<dt>[<a href="#CITEodissey" name=odissey>8</a>]</dt><dd>
GeneralMagicInc.
 Odissey.
 1997.
 available at http://www.genmagic.com/agents.

<p>
<dt>[<a href="#CITEaglets" name=aglets>9</a>]</dt><dd>
IBM.
 Aglets.
 http://www.trl.ibm.co.jp/aglets.

<p>
<dt>[<a href="#CITEJul88" name=Jul88>10</a>]</dt><dd>
E.&nbsp;Jul, H.&nbsp;Levy, N.&nbsp;Hutchinson, and A.&nbsp;Black.
 Fine-Grained Mobility in the Emerald System.
 <em>ACM Transactions on Computer Systems</em>, 6(1):109-133, February
  1988.

<p>
<dt>[<a href="#CITEknowbots" name=knowbots>11</a>]</dt><dd>
R.&nbsp;E. Kahn and V.&nbsp;G. Cerf.
 The digital library project, volume i: The world of knowbots.
 1988.
 Unpublished manuscript, Corporation for National Research
  Initiatives, Reston, Va., Mar.

<p>
<dt>[<a href="#CITEMiller89Lex" name=Miller89Lex>12</a>]</dt><dd>
D.&nbsp;A. Miller.
 Lexical scoping as universal quantification.
 In G.&nbsp;Levi and M.&nbsp;Martelli, editors, <em>Proceedings of the Sixth
  International Conference on Logic Programming</em>, pages 268-283, Cambridge,
  Massachusetts London, England, 1989. MIT Press.

<p>
<dt>[<a href="#CITEmycroft:poli" name=mycroft:poli>13</a>]</dt><dd>
A.&nbsp;Mycroft and R.&nbsp;A. O'Keefe.
 A polimorphic type system for prolog.
 <em>Artificial Intelligence</em>, (23):295-307, 1984.

<p>
<dt>[<a href="#CITEStam90" name=Stam90>14</a>]</dt><dd>
J.&nbsp;W. Stamos and D.&nbsp;K. Gifford.
 Remote Evaluation.
 <em>ACM Transaction on Programming Languages and Systems</em>,
  12(4):537-565, October 1990.

<p>
<dt>[<a href="#CITETarau97:BinProlog" name=Tarau97:BinProlog>15</a>]</dt><dd>
P.&nbsp;Tarau.
 BinProlog 5.75 User Guide.
 Technical Report 97-1, D&#233;partement d'Informatique, Universit&#233;
  de Moncton, Apr. 1997.
 Available from <em>http://clement.info.umoncton.ca/BinProlog</em>.

<p>
<dt>[<a href="#CITEbp7user" name=bp7user>16</a>]</dt><dd>
P.&nbsp;Tarau.
 BinProlog 7.0 Professional Edition: User Guide.
 Technical report, BinNet Corp., 1998.
 Available from http://www.binnetcorp.com/BinProlog.

<p>
<dt>[<a href="#CITETarau90:PLILP" name=Tarau90:PLILP>17</a>]</dt><dd>
P.&nbsp;Tarau and M.&nbsp;Boyer.
 Elementary Logic Programs.
 In P.&nbsp;Deransart and J.&nbsp;Maluszy\'nski, editors, <em>Proceedings of
  Programming Language Implementation and Logic Programming</em>, number 456 in
  Lecture Notes in Computer Science, pages 159-173. Springer, Aug. 1990.

<p>
<dt>[<a href="#CITETD96:coord" name=TD96:coord>18</a>]</dt><dd>
P.&nbsp;Tarau and V.&nbsp;Dahl.
 A Coordination Logic for Agent Programming in Virtual
  Worlds.
 In W.&nbsp;Conen and G.&nbsp;Neumann, editors, <em>Proceedings of Asian'96
  Post-Conference Workshop on Coordination Technology for Collaborative
  Applications</em>, Singapore, Dec. 1996.

<p>
<dt>[<a href="#CITETDBwetice:97" name=TDBwetice:97>19</a>]</dt><dd>
P.&nbsp;Tarau, V.&nbsp;Dahl, and K.&nbsp;De&nbsp;Bosschere.
 A Logic Programming Infrastructure for Remote Execution,
  Mobile Code and Agents.
 In <em>Proceedings of WETICE'97</em>, pages 106-112, IEEE Computer
  Society Press, June 1997.

<p>
<dt>[<a href="#CITETDB:97" name=TDB:97>20</a>]</dt><dd>
P.&nbsp;Tarau, V.&nbsp;Dahl, and K.&nbsp;De&nbsp;Bosschere.
 Logic Programming Tools for Remote Execution, Mobile
  Code and Agents.
 In <em>Proceedings of ICLP'97 Workshop on Logic Programming
  and Multi Agent Systems</em>, Leuven, Belgium, July 1997.

<p>
<dt>[<a href="#CITETDF:asian96" name=TDF:asian96>21</a>]</dt><dd>
P.&nbsp;Tarau, V.&nbsp;Dahl, and A.&nbsp;Fall.
 Backtrackable State with Linear Affine Implication and
  Assumption Grammars.
 In J.&nbsp;Jaffar and R.&nbsp;H. Yap, editors, <em>Concurrency and
  Parallelism, Programming, Networking, and Security</em>, Lecture Notes in
  Computer Science 1179, pages 53-64, Singapore, Dec. 1996. "Springer".

<p>
<dt>[<a href="#CITETDRB97:chi" name=TDRB97:chi>22</a>]</dt><dd>
P.&nbsp;Tarau, V.&nbsp;Dahl, S.&nbsp;Rochefort, and K.&nbsp;De&nbsp;Bosschere.
 LogiMOO: a Multi-User Virtual World with Agents and
  Natural Language Programming.
 In S.&nbsp;Pemberton, editor, <em>Proceedings of CHI'97</em>, pages 323-324,
  Mar. 1997.

<p>
<dt>[<a href="#CITEpt93b" name=pt93b>23</a>]</dt><dd>
P.&nbsp;Tarau and K.&nbsp;De&nbsp;Bosschere.
 Memoing with Abstract Answers and Delphi Lemmas.
 In Y.&nbsp;Deville, editor, <em>Logic Program Synthesis and
  Transformation</em>, Springer-Verlag, pages 196-209, Louvain-la-Neuve, July
  1993.

<p>
<dt>[<a href="#CITEtdb95rev" name=tdb95rev>24</a>]</dt><dd>
P.&nbsp;Tarau, K.&nbsp;De&nbsp;Bosschere, and B.&nbsp;Demoen.
 Partial Translation: Towards a Portable and Efficient Prolog
  Implementation Technology.
 <em>Journal of Logic Programming</em>, 29(1-3):65-83, Nov. 1996.

<p>
<dt>[<a href="#CITEDOZmobility" name=DOZmobility>25</a>]</dt><dd>
P.&nbsp;Van&nbsp;Roy, S.&nbsp;Haridi, and P.&nbsp;Brand.
 Using mobility to make transparent distribution practical.
 1997.
 manuscript.

<p>
<dt>[<a href="#CITEDOZmobs" name=DOZmobs>26</a>]</dt><dd>
P.&nbsp;Van&nbsp;Roy, S.&nbsp;Haridi, P.&nbsp;Brand, G.&nbsp;Smolka, M.&nbsp;Mehl, and R.&nbsp;Scheidhouer.
 Mobile Objects in Distributed Oz.
 <em>ACM TOPLAS</em>, 1997.
 to appear.

<p>
<dt>[<a href="#CITEWarren82" name=Warren82>27</a>]</dt><dd>
D.&nbsp;H.&nbsp;D. Warren.
 Higher-order extensions to Prolog - are they needed?
 In D.&nbsp;Michie, J.&nbsp;Hayes, and Y.&nbsp;H. Pao, editors, <em>Machine
  Intelligence 10</em>. Ellis Horwood, 1981.

<p>
</DL>
<H2>Appendix I: Capturing First Order Continuations in BinProlog</H2>
<font size="-1">
<pre>
% calls Goal with current continuation available to its inner calls
capture_cont_for(Goal):-
  assumeal(cont_marker(End)),
    Goal,
  end_cont(End).

% passes Closure to be called on accumulated continuation
call_with_cont(Closure):-
  assumed(cont_marker(End)),
  consume_cont(Closure,End).
  
% gathers in conjunction goals from the current continuation
% until Marker is reached when it calls Closure on it
consume_cont(Closure,Marker):-
  get_cont(Cont),
  consume_cont1(Marker,(_,_,_,Cs),Cont,NewCont), % first _
  call(Closure,Cs),                              % second _
  % sets current continuation to leftover NewCont    
  call_cont(NewCont).                            % third _

% gathers goals in Gs until Marker is hit in continuation Cont
% when leftover LastCont continuation (stripped of Gs) is returned
consume_cont1(Marker,Gs,Cont,LastCont):-
   strip_cont(Cont,Goal,NextCont),
   ( NextCont==true-&#62; !,errmes(in_consume_cont,expected_marker(Marker))
   ; arg(1,NextCont,X),Marker==X-&#62;
     Gs=Goal,arg(2,NextCont,LastCont)
   ; Gs=(Goal,OtherGs),
     consume_cont1(Marker,OtherGs,NextCont,LastCont)
   ).

% this `binarized clause' gets the current continuation
get_cont(Cont,Cont)::-true(Cont).

% sets calls NewCont as continuation to be called next
call_cont(NewCont,_) ::- true(NewCont).
</pre></font>

<p>

<H2>Appendix II: Thread Mobility in BinProlog</H2>
<font size="-1">
<pre>
% wraps continuation of current thread to be taken
% by inner move_thread goal to be executed remotely 
wrap_thread(Goal):-
  capture_cont_for(Goal).

% picks up wrapped continuation,
% jumps to default remote site and runs it there
move_thread:-
  call_with_cont(move_with_cont).
  
% moves to remote site goals Gs in current continuation
move_with_cont(Gs):-
  % gets info about this host
  detect_host(BackHost),
  get_free_port(BackPort),
  default_password(BackPasswd),
  default_code(BackCode),
  % runs delayed remote command (assumes is with +/1)
  remote_run(
     +todo(
       host(BackHost)=&#62;&#62;port(BackPort)=&#62;&#62;code(BackCode)=&#62;&#62;(
         sleep(5), % waits until server on BackPort is up
         % runs foals Gs picked up from current continuation 
         (Gs-&#62;true;true), % ignores failure
         % stops server back on site of origin
         stop_server(BackPasswd)
       )
     )
  ),
  % becomes data and code server for mobile code until is
  % stopped by mobile code possessing password
  server_port(BackPort)=&#62;&#62;run_unrestricted_server.
</pre></font>
<hr><H3>Footnotes:</H3>

<p><a name=tthFtNtAAB></a><a href="#tthFrefAAB"><sup>1</sup></a> I.e. continuations (representations 
of future computations)
accessible as an ordinary data structure - a 
Prolog term in this case.
<p><a name=tthFtNtAAC></a><a href="#tthFrefAAC"><sup>2</sup></a> See more in files
library/engines.pl, progs/engtest.pl
<p><a name=tthFtNtAAD></a><a href="#tthFrefAAD"><sup>3</sup></a> Atom or term.
<p><a name=tthFtNtAAE></a><a href="#tthFrefAAE"><sup>4</sup></a> which will be
also shortly called the <em>base</em> of the mobile thread
<p><a name=tthFtNtAAF></a><a href="#tthFrefAAF"><sup>5</sup></a> BinProlog's linear assumptions
 are backtrackable additions to the database, usable at most once.

<p><a name=tthFtNtAAG></a><a href="#tthFrefAAG"><sup>6</sup></a> possibly filtered down
to a relevant subset using
a `channel'-like pattern
<p><hr><small>File translated from T<sub><font size="-1">E</font></sub>X by <a href="http://hutchinson.belmont.ma.us/tth/">T<sub><font size="-1">T</font></sub>H</a>, version 2.00.<br>On  4 Mar 1999, 14:53.</small>
</HTML>
