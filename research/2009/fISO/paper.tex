\pdfoutput=1
%\NeedsTeXFormat{LaTeX2e}
%\documentclass{TOOLS/jfp1}
%\usepackage{dcpic,pictexwd}
%\input TOOLS/jhheader.tex

%\title[Journal of Functional Programming] {
%  Isomorphic Data Encodings in Haskell and their
%  Generalization to Hylomorphisms on Hereditarily Finite Data Types
%}q
           
%\author[Paul Tarau]
%   {PAUL TARAU\\
%   Department of Computer Science and Engineering\\
%   University of North Texas\\
%   \email{tarau@cs.unt.edu}}

\documentclass[]{INCLUDES/llncs}
\usepackage{TOOLS/dcpic,pictexwd}
\usepackage{amsfonts,amsmath}
\input TOOLS/jhheader.tex
\title{
    Isomorphic Data Encodings % in Haskell 
    and their
    Generalization to Hylomorphisms on Hereditarily Finite Data Types
}
\author{Paul Tarau}
\institute{
   Department of Computer Science and Engineering\\
   University of North Texas\\
   {\em E-mail: tarau@cs.unt.edu}
}

\begin{document}
\maketitle
\date{}

\begin{abstract}
This paper is an exploration in a functional programming framework
of {\em isomorphisms} between elementary
data types (natural numbers, sets, multisets, finite functions, permutations
binary decision diagrams, graphs, hypergraphs,
parenthesis languages, dyadic
rationals, primes, DNA sequences etc.) and their extension to hereditarily
finite universes through {\em hylomorphisms} derived
from {\em ranking/unranking} and
{\em pairing/unpairing} operations.

An embedded higher order {\em combinator language} provides
any-to-any encodings automatically.

Besides applications to experimental mathematics,
a few examples of
``free algorithms'' obtained by transferring 
operations between data types 
are shown. Other applications range from
stream iterators on
combinatorial objects to
self-delimiting codes,
succinct data representations and generation
of random instances.

The paper covers 60 data types and, through the use of
the embedded combinator language, provides 3660 distinct
bijective transformations between them.

\begin{comment}
The paper is part of a larger effort to cover in a declarative programming 
paradigm some fundamental combinatorial generation algorithms
along the lines of Knuth's recent work \cite{knuth06draft}.
\end{comment}

The self-contained source code of the paper, as generated from a
literate Haskell program, is available at
\url{http://logic.csci.unt.edu/tarau/research/2008/fISO.zip}.

A short, 5 page version of the paper,
published as \cite{sac09fISO} describes
the idea of organizing various data transformations
as encodings to sequences of natural numbers and
gives a few examples of hylomorphisms that lift the
encodings to related hereditarily finite universes.

{\bf Keywords}:
{\em 
Haskell data representations,
data type isomorphisms,
declarative combinatorics,
computational mathematics,
Ackermann encoding, G\"{o}del numberings, arithmetization,
ranking/unranking, 
hereditarily finite sets, functions and permutations,
encodings of binary decision diagrams,
dyadic rationals,
DNA encodings
}
\end{abstract}

%\tableofcontents

\begin{comment}
\begin{code}
module ISO where
import Data.List
import Data.Bits
import Data.Graph
import Data.Char
import Array
import Ratio
import Random
import Data.Graph.Inductive
import Graphics.Gnuplot.Simple
import Funsat.Solver
import Funsat.Types hiding (with)
import Data.Set hiding (map, filter, union, partition)
\end{code}
\end{comment}

\section{Introduction}

Analogical/metaphorical thinking routinely shifts entities and
operations from a field to another hoping to uncover similarities in representation
or use \cite{lakoff}.

Compilers convert programs from human centered to machine centered
representations - sometime reversibly.

Complexity classes are defined through compilation with limited resources
(time or space) to similar problems
\cite{Cook04theoriesfor,Cook93functionalinterpretations}.

Mathematical theories often borrow proof patterns and reasoning
techniques across close and sometime not so close fields.

A relatively small number of universal data types are used as basic building
blocks in programming languages and their runtime interpreters,
corresponding to a few well tested mathematical abstractions like sets,
functions, graphs, groups, categories etc.

\begin{comment}
Hence everyone explicitly or implicitly knows that ultimately, 
``everything is everything'' through lower common denominators like
bitstring representations in computer memory. From hackers and compiler writers 
to combinatorialists and experimental mathematicians,
it is not uncommon to shapeshift between various data types. 
Means as simple as binary editors, union types or overlapping variable
definitions are generously providing such alternate views.
\end{comment}

A less obvious leap is that if heterogeneous objects can be seen
in some way as isomorphic, then we can share them and
compress the underlying informational universe by collapsing
isomorphic encodings of data or programs whenever possible.

Sharing heterogeneous data objects faces two problems:
\begin{itemize}
\item some form of equivalence needs to be proven between two objects A and B before A can 
replace B in a data structure, a possibly tedious and error prone task

\item the fast growing diversity of data types makes harder and harder to
recognize sharing opportunities.
\end{itemize}

Besides, this rises the question: what
guaranties do we have that sharing across heterogeneous
data types is useful and safe?

The techniques introduced in this paper provide a generic solution to these
problems, through isomorphic mappings between heterogeneous data types, 
such that unified internal representations 
make equivalence checking and sharing possible. 
The added benefit of these ``shapeshifting" 
data types is that the functors transporting their data content will also transport their 
operations, resulting in  shortcuts that provide, for free, implementations of 
interesting algorithms. The simplest instance is the case of
isomorphisms -- reversible mappings that also transport operations.
In their simplest form such isomorphisms show up as {\em encodings}
to some simpler and easier to manipulate representation, for
instance natural numbers. 

Such encodings can be traced back to G\"{o}del
numberings \cite{Goedel:31,conf/icalp/HartmanisB74} associated to formulae,
but a wide diversity of common computer operations, ranging
from data compression and serialization to
wireless data transmissions and cryptographic codes qualify.
 
Encodings between data types provide a variety of services ranging from
free iterators and random objects to data compression and succinct
representations. Tasks like serialization and persistence are facilitated
by simplification of reading or writing operations without the need of
special purpose parsers. Sensitivity to internal data representation
format or size limitations can be circumvented without extra programming
effort.

\begin{comment}
Kolmogorov-Chaitin algorithmic complexity is based on the existence of
various equivalent representations of data objects, and in particular
(minimal) programs that produce them in a given language and encoding
\cite{vitanyi,Chaitin75atheory,Calude94algorithmicallycoding}.

In the context of algorithmic information theory, one can
interpret data structures like graphs and program constructs
like loops or recursion as compression mechanisms focusing
on sharing and reuse of equivalent blocks of information.
In this case, maximal sharing acts as the dual of minimal
program+input size. 
With this in mind, shapeshifting through a uniform set of encodings 
would extend sharing opportunities across 
heterogeneous data and code types.
\end{comment}



\section{An Embedded Data Transformation Language}

We will start by designing an embedded transformation language
as a set of operations on a groupoid of isomorphisms. We will then
extended it with a set of higher order combinators mediating the
composition of the encodings and the transfer of operations between 
data types.

\subsection{The Groupoid of Isomorphisms}

We implement an isomorphism between two objects X and Y as a 
Haskell data type encapsulating a bijection $f$ and its inverse $g$. 
We will call the {\em from} function the first component (a {\em
section} in category theory parlance) and
the {\em to} function the second component (a {\em retraction}) defining
the isomorphism.
We can organize isomorphisms as a {\em groupoid} as follows:

\begindc{\commdiag}[5]
\obj(14,11){$X$}
\obj(39,11){$Y$}
\mor(14,12)(39,12){$f=g^{-1}$}
\mor(39,10)(14,10){$g=f^{-1}$}
\enddc

\begin{code}
data Iso a b = Iso (a->b) (b->a)

from (Iso f _) = f
to (Iso _ g) = g

compose :: Iso a b -> Iso b c -> Iso a c
compose (Iso f g) (Iso f' g') = Iso (f' . f) (g . g')
itself = Iso id id
invert (Iso f g) = Iso g f
\end{code}
Assuming that for any pair of type {\tt Iso a b},  $f \circ g = id_a$ and $g
\circ f=id_b$, we can now formulate {\em laws} about isomorphisms
that can be used to test correctness of implementations with tools like
QuickCheck \cite{DBLP:journals/sigplan/ClaessenH02}.
\begin{prop} 
The data type Iso has a groupoid structure, i.e. the {\em compose} operation,
when defined, is associative, {\em itself} acts as an identity element
and {\em invert} computes the inverse of an isomorphism.
\end{prop}


We can transport operations from an object to another
with {\em borrow} and {\em lend} combinators defined as follows:

\begin{code}
borrow :: Iso t s -> (t -> t) -> s -> s
borrow (Iso f g) h x = f (h (g x))
borrow2 (Iso f g) h x y = f (h (g x) (g y))
borrowN (Iso f g) h xs = f (h (map g xs))

lend :: Iso s t -> (t -> t) -> s -> s
lend = borrow . invert
lend2 = borrow2 . invert
lendN = borrowN . invert
\end{code}

The combinators {\tt fit} and {\tt retrofit} 
just transport an object {\tt x}
through an isomorphism and and apply 
to it an operation {\tt op} available on
the other side:
\begin{code}
fit :: (b -> c) -> Iso a b -> a -> c
fit op iso x = op ((from iso) x)

retrofit :: (a -> c) -> Iso a b -> b -> c
retrofit op iso x = op ((to iso) x)
\end{code}

We can see the combinators {\tt from, to, compose, itself, invert, borrow,
etc.} as part of an {\em embedded data transformation language}.
Note that in this design we borrow from our
strongly typed host programming language
its abstraction layers and safety mechanisms
that continue to check the semantic validity of
the embedded language constructs.

\subsection{Choosing a Root in a connected groupoid}
Within each connected groupoid,
to avoid defining $n(n-1)/2$ isomorphisms between $n$ objects,
we can choose a {\em Root} object to/from which we will actually
implement isomorphisms. Then we can extend our embedded
combinator language using the groupoid structure of the isomorphisms
to connect {\em any} two objects through isomorphisms to/from
the {\em Root}.
\begin{comment}
\begindc{\commdiag}[20]
\obj(10,10)[X]{$Root$}
\obj(14,10)[Aa]{$A$}

\obj(13,12)[Ac]{$B$}
\obj(12,13)[Ad]{$C$}

\obj(10,14)[Af]{$D$}

\obj(8,13)[Ah]{$E$}
\obj(7,12)[Ai]{$F$}

\obj(6,10)[Ak]{$G$}

\obj(7,8)[Am]{$H$}
\obj(8,7)[An]{$I$}

\obj(10,6)[Ap]{$J$}

\obj(12,7)[Ar]{$K$}
\obj(13,8)[As]{$L$}

\mor{X}{Aa}{$a$}

\mor{X}{Ac}{$b$}
\mor{X}{Ad}{$c$}

\mor{X}{Af}{$d$}

\mor{X}{Ah}{$e$}
\mor{X}{Ai}{$f$}

\mor{X}{Ak}{$g$}

\mor{X}{Am}{$h$}
\mor{X}{An}{$i$}

\mor{X}{Ap}{$j$}

\mor{X}{Ar}{$k$}
\mor{X}{As}{$l$}
\enddc
\end{comment}

Choosing a {\em Root} object is somewhat arbitrary, but it makes sense to
pick a representation that is relatively easy convertible to various
others, efficiently implementable and, last but not least, scalable to
accommodate large objects up to the runtime system's 
actual memory limits.

We will choose as our {\em Root} object {\em finite sequences of natural
numbers}. They can be seen as {\tt finite functions} from an initial 
segment of $\mathbb{N}$, say $[0..n]$, to $\mathbb{N}$.
 This implies that a finite
function can be seen as an array or a list of natural 
numbers except that we do not limit the size of 
the representation of its values.
We will represent them as lists i.e. their Haskell type is $[\mathbb{N}]$.
\begin{code}
type N = Integer
type Root = [N]
\end{code}
We can now define an {\em Encoder} as an isomorphism
connecting an object to {\em Root} 
\begin{code}
type Encoder a = Iso a Root
\end{code}
together with the combinators {\em with} and {\em as}
providing an {\em embedded transformation language} for routing
isomorphisms through two {\em Encoders}.
\begin{code}  
with :: Encoder a->Encoder b->Iso a b
with this that = compose this (invert that)

as :: Encoder a -> Encoder b -> b -> a
as that this thing = to (with that this) thing
\end{code}
The combinator {\tt with} turns two Encoders
into an arbitrary isomorphism, i.e. acts as a connection hub between
their domains. The combinator {\tt as} adds a more convenient syntax
such that converters between A and B can be designed as:
\begin{codex}
a2b x = as B A x
b2a x = as A B x
\end{codex}
\vskip 0.30cm
\begindc{\commdiag}[5]
\obj(26,0){$Root$}
\obj(14,11){$A$}
\obj(39,11){$B$}

\mor(26,0)(39,10){$b$}
\mor(26,0)(14,10){$a^{-1}$}
\mor(39,10)(26,0){$b^{-1}$}
\mor(14,10)(26,0){$a$}
\mor(14,12)(39,12){$a2b=as~B~A$}
\mor(39,10)(14,10){$b2a=as~A~B$}
\enddc
\vskip 0.30cm
A particularly useful combinator that
transports functions from an Encoder to another, {\tt
borrow\_from}, can be defined as follows:
\begin{code}
borrow_from :: Encoder b -> (b -> b) ->
               Encoder a -> a -> a

borrow_from lender f borrower = 
  (as borrower lender) . f . (as lender borrower)
\end{code}
Similarly, a two argument function {\tt op} is transported between data types
using the combinator {\tt borrow\_from2}:
\begin{code}
borrow_from2 :: Encoder a -> (a -> a -> a) -> 
                Encoder b -> b -> b -> b

borrow_from2 lender op borrower x y = 
    as borrower lender r where
       x'= as lender borrower x
       y'= as lender borrower y
       r = op x' y'
\end{code}
We will provide extensive use cases for these combinators
as we populate our groupoid of isomorphisms.
\noindent Given that $[\mathbb{N}]$ has been chosen as the root, we will define our
finite function data type {\em fun} simply as the identity isomorphism 
on sequences in $[\mathbb{N}]$.
\begin{code}  
fun :: Encoder [N]
fun = itself
\end{code}

\section{Extending the Groupoid of Isomorphisms}
We will now populate our groupoid of isomorphisms with
combinators based on a few primitive converters.

\subsection{A ranking/unranking algorithm for finite sequences}

A {\em ranking/unranking} function defined on a data type is a bijection to/from
the set of natural numbers (denoted $\mathbb{N}$ through the paper). 
We start with an unusually simple but (at our best knowledge) novel
ranking/unranking algorithm for finite sequences of arbitrary 
unbounded size natural numbers. Given the definitions
\begin{code}
cons :: N->N->N
cons x y  = (2^x)*(2*y+1)

hd :: N->N
hd n | n>0 = if odd n then 0 else 1+hd  (n `div` 2)

tl :: N->N
tl n = n `div` 2^((hd n)+1)

nat2fun :: N->[N]
nat2fun 0 = []
nat2fun n = hd n : nat2fun (tl n)
 
fun2nat :: [N]->N  
fun2nat [] = 0
fun2nat (x:xs) = cons x (fun2nat xs)
\end{code}
\begin{prop}
{\tt fun2nat} is a bijection from finite sequences of natural numbers to natural
numbers and {\tt nat2fun} is its inverse.
\end{prop}
This follows from the fact that {\tt cons} and the pair {\tt (hd, tl)} define a bijection between
$\mathbb{N}-\{0\}$ and $\mathbb{N} \times \mathbb{N}$ and that the value of {\tt fun2nat} is uniquely
determined by the sequence of applications of {\tt tl} and the sequence of
values returned by {\tt hd}.
\begin{codex}
*ISO> hd 2008
3
*ISO> tl 2008
125
*ISO> cons 3 125
2008
\end{codex}
We can define the {\tt Encoder}
\begin{code}
nat :: Encoder N
nat = Iso nat2fun fun2nat
\end{code}
working as follows
\begin{codex}
*ISO> as fun nat 2008
[3,0,1,0,0,0,0]
*ISO> as nat fun [3,0,1,0,0,0,0]
2008
\end{codex}
Note also that this isomorphism preserves ``list processing'' operations i.e.
if one defines:
\begin{code}
app 0 ys = ys
app xs ys = cons (hd xs) (app (tl xs) ys)
\end{code}
then the isomorphism commutes with operations like list concatenation:
\begin{prop}
(as fun nat n) ++ (as fun nat m) $\equiv$ as fun nat (app n m)

as nat fun (ns ++ ms) $\equiv$ app (as nat fun ns) (as nat fun ms)
\end{prop}
Given the definitions:
\begin{code}
unpair z = (hd (z+1),tl (z+1))
pair (x,y) = (cons x y)-1
\end{code}
shifting by 1 turns {\tt hd} and {\tt tl} in
total functions on $\mathbb{N}$ such that $unpair~0=(0,0)$ i.e.
\begin{prop}
$unpair:\mathbb{N} \rightarrow \mathbb{N} \times \mathbb{N}$ 
is a bijection and $pair=unpair^{-1}$.
\end{prop}
Note that unlike {\tt hd} and {\tt tl}, {\tt
unpair} is defined for all natural numbers:
\begin{codex}
*ISO> map unpair [0..7]
[(0,0),(1,0),(0,1),(2,0),(0,2),(1,1),(0,3),(3,0)]
\end{codex}

As the cognoscenti might notice, this is in fact a classic {\em
pairing/unpairing function} that has been used, by Pepis, Kalmar and Robinson 
in some fundamental work on recursion theory, 
decidability and Hilbert's Tenth Problem in
\cite{pepis,kalmar1,robinson50,robinson68a,robinsons68b} and 
{\tt hd,tl,cons,0}
define on $\mathbb{N}$ an algebraic structure isomorphic to the one 
introduced by {\tt CAR,CDR,CONS,NIL} in John McCarthy's classic LISP paper
\cite{mccarthy60}.

\begin{comment}
% buggy
Alternatively, using the implicit list structure induced by {\tt cons, hd, tl}
one can design the following pairing/unpairng functions:
\begin{code}
cpair  (0,0)  = 0
cpair  (0,y)  = cons e (cpair (y,0))
cpair  (x,y) = cons (hd x) (cpair (y,(tl x)))  
 
cunpair 0 = (0,0)
cunpair z = (cons (hd z) x,y) where (y,x)=cunpair (tl z)
\end{code}
working as follows:
\begin{codex}

\end{codex}
\end{comment}

We will revisit pairing functions in section \ref{pairings}.

\subsection{An Isomorphism between Finite Multisets and Finite Functions}
\label{msetiso}

Multisets \cite{multisetOver} are unordered collections with repeated
elements. Non-decreasing sequences provide a canonical representation for
multisets of natural numbers. 
The isomorphism between finite multisets and finite functions is specified with
two bijections {\tt mset2fun} and {\tt fun2mset}.
\begin{code}
mset :: Encoder [N]
mset = Iso mset2fun fun2mset
\end{code}
While finite multisets and sequences representing finite functions share a
common representation $[\mathbb{N}]$, multisets are subject to the implicit constraint that their
order is immaterial \footnote{Such
constraints can be regarded as {\em laws} that we assume about 
a given data type, when needed, restricting it to the
appropriate domain of the underlying mathematical concept.}.
This suggest that a multiset like $[4,4,1,3,3,3]$ could be
represented by first ordering it as $[1,3,3,3,4,4]$ and then compute the 
differences between consecutive elements i.e.
$[x_0 \ldots x_i, x_{i+1} \ldots] \rightarrow [x_0 \ldots x_{i+1}-x_i
\ldots]$.
This gives $[1,2,0,0,1,0]$, with
the first element $1$ followed by the increments $[2,0,0,1,0]$,
as implemented by {\tt mset2fun}:
\begin{code}
mset2fun = to_diffs . sort . (map must_be_nat)

to_diffs xs = zipWith (-) (xs) (0:xs)

must_be_nat n | n>=0 = n
\end{code}
It can now be verified easily that prefix sums of the
numbers in such a sequence
return the original set
in sorted form, as implemented by {\tt fun2mset}:
\begin{code}
fun2mset ns = tail (scanl (+) 0 (map must_be_nat ns)) 
\end{code}
The resulting isomorphism {\tt mset} can be applied directly using its two
components {\tt mset2fun} and {\tt fun2mset}. Equivalently, it can be
expressed more ``generically'' by using the {\tt as} combinator, as
follows:
\begin{codex}
*ISO> mset2fun [1,3,3,3,4,4]
[1,2,0,0,1,0]
*ISO> fun2mset [1,2,0,0,1,0]
[1,3,3,3,4,4]
*ISO> as fun mset [1,3,3,3,4,4]
[1,2,0,0,1,0]
*ISO> as mset fun [1,2,0,0,1,0]
[1,3,3,3,4,4]
\end{codex}

\subsection{An Isomorphism to Finite Sets of Natural Numbers}
While finite sets and sequences share a common representation $[\mathbb{N}]$,
sets are subject to the implicit constraints that all their elements
are distinct and order is immaterial.
Like in the case of multisets, this suggest that a set like $\{7,1,4,3\}$ could
be represented by first ordering it as $\{1,3,4,7\}$ and then compute the 
differences between consecutive elements. This gives $[1,2,1,3]$, with
the first element $1$ followed by the increments $[2,1,3]$. To turn
it into a bijection, including $0$ as a possible member of a sequence,
another adjustment is needed: elements in the sequence of increments should
be replaced by their predecessors. This gives $[1,1,0,2]$ as implemented
by {\tt set2fun}:
\begin{code}
set2fun xs | is_set xs = shift_tail pred (mset2fun xs)

shift_tail _ [] = []
shift_tail f (x:xs) = x:(map f xs)

is_set ns = ns==nub ns
\end{code}
It can now be verified easily that predecessors of the incremental sums of the
successors of numbers in such a sequence, return the original set
in sorted form, as implemented by {\tt fun2set}:
\begin{code}
fun2set = (map pred) . fun2mset . (map succ)
\end{code}
together with the dual definition, equivalent to {\tt set2fun}:
\begin{code}
set2fun' = (map pred) . mset2fun . (map succ)
\end{code}
The {\em Encoder} (an isomorphism with {\tt fun}) can be specified with the two
bijections {\tt set2fun} and {\tt fun2set}.
\begin{code}
set :: Encoder [N]
set = Iso set2fun fun2set
\end{code}
The Encoder ({\tt set}) is now ready to interoperate 
with another Encoder:
\begin{codex}
*ISO> as fun set [0,2,3,4,9]
[0,1,0,0,4]
*ISO> as set fun [0,1,0,0,4]
[0,2,3,4,9]
*ISO> as mset set [0,2,3,4,9]
[0,1,1,1,5]
*ISO> as set mset [0,1,1,1,5]
[0,2,3,4,9]
\end{codex}
As the example shows,the Encoder {\tt set} connects arbitrary lists of
natural numbers representing finite functions
to strictly increasing sequences
of (distinct) natural numbers representing sets.
Then, through the use of the combinator {\tt as}, sets represented by {\tt set}
are connected to multisets represented by {\tt mset}. This connection is
(implicitly) routed through a connection to {\tt fun}, as if
\begin{codex}
*ISO> as mset fun [0,1,0,0,4]
[0,1,1,1,5]
\end{codex}
were executed.


% \subsection{Embeddings and Approximations} #### todo

\subsection{On sharing the underlying datatypes}
We have seen so far that finite functions, multisets and sets share the same
representation $[\mathbb{N}]$. This hides injective applications between the 
corresponding mathematical abstractions.
However, the overlap of representations is safe, provided that we think of 
multisets canonically represented as nondecreasing sequences and sets 
canonically represented as strictly increasing sequences. It is also safe to apply
to unordered sequences seen as representations of sets or multisets
operations that are order independent - for instance sums or products.
With this warning in mind, we can use the injective mappings from
overlapping set, multiset, sequence representations {\em implicitely}
under the assumption that the order of operations is immaterial.

Alternatively, one can approximate a sequence as the set of its elements,
ignoring order and multiplicity.

\subsection{Folding Sets into Natural Numbers Directly} \label{natset}
We can fold a set, represented as a list of distinct
natural numbers into a single natural number,
reversibly, by observing that it can be seen
as the list of exponents of {\tt 2} in the number's
base {\tt 2} representation.

\begin{code}
nat_set = Iso nat2set set2nat 

nat2set n | n>=0 = nat2exps n 0 where
  nat2exps 0 _ = []
  nat2exps n x = 
    if (even n) then xs else (x:xs) where
      xs=nat2exps (n `div` 2) (succ x)

set2nat ns | is_set ns = sum (map (2^) ns)
\end{code}

We can standardize this pair of operations as an {\em Encoder} 
for a natural number using our Root as a mediator: 
\begin{code}
nat' :: Encoder N
nat' = compose nat_set set
\end{code}
The following holds:
\begin{prop}
$nat \equiv nat'$
\end{prop}
Given that {\tt nat} is an isomorphism with the Root {\tt fun}, one can use
directly its {\tt from} and {\tt to} components:
\begin{codex}
*ISO> from nat' 2008
[3,0,1,0,0,0,0]
*ISO> to nat' it
2008
\end{codex}
The resulting Encoder ({\tt nat}) is now ready to interoperate 
with any Encoder, in a generic way:
\begin{codex}
*ISO> as fun nat' 2008
[3,0,1,0,0,0,0]
*ISO> as set nat' 2008
[3,4,6,7,8,9,10]
*ISO> as nat' set [3,4,6,7,8,9,10]
2008
*ISO> lend nat' reverse 2008
1135
*ISO> lend nat_set reverse 2008
2008
*ISO> borrow nat_set succ [1,2,3]
[0,1,2,3]
*ISO> as set nat' 42
[1,3,5]
*ISO> fit length nat' 42
3
*ISO> retrofit succ nat_set [1,3,5]
43
\end{codex}
The reader might notice at this point that we have
already made full circle - as finite sets can be seen as
instances of finite sequences. 
Injective functions that are not surjections with wider and wider gaps can be
generated using the fact that one of the representations is information theoretically
``denser'' than the other, for a given range:
\begin{codex}
*ISO> as set fun [0,1,2,3]
[0,2,5,9]
*ISO> as set fun $ as set fun [0,1,2,3]
[0,3,9,19]
*ISO> as set fun $ as set fun $ as set fun [0,1,2,3]
[0,4,14,34]
\end{codex}
%$
One can now define, for instance, a mapping from natural numbers to multi-sets
simply as:
\begin{code}
nat2mset = as mset nat
mset2nat = as nat mset 
\end{code}
but we will not explicitly need such definitions as the the equivalent
function is clearly provided by the combinator {\tt as}.
One can now borrow operations between {\tt set} and {nat} as follows:
\begin{codex}
*ISO> borrow_from2 set union nat 42 2008
2042
*ISO> 42 .|. 2008 :: N
2042
*ISO> borrow_from2 set intersect nat 42 2008
8
*ISO> 42 .&. 2008 :: N
8
*ISO> borrow_from2 nat (*) set [1,2,3] [4,5]
[5,7,9]
*ISO> borrow_from2 nat (+) set [1,2,3] [3,4,5]
[1,2,6]
\end{codex}
and notice that operations like union and intersection of sets map to boolean
operations on numbers as expected, while other operations are not necessarily
meaningful at first sight. We will show next a few cases where such
``shapshiftings'' of operations reveal more interesting analogies.

\subsection{Encoding Finite Multisets with Primes}

A factorization of a natural number is uniquely
described as multi-set or primes. We will use the fact that each prime number 
is uniquely associated to its position in the infinite stream of primes
to obtain a bijection from multisets of natural numbers to natural numbers.
We assume defined a prime generator {\tt primes} and a factoring function
{\tt to\_factors} (see Appendix).

The function {\tt nat2pmset} maps a natural number to the multiset of prime
positions in its factoring. Note that we treat {\tt 0} as {\tt []} and shift
{\tt n} to {\tt n+1} to accomodate {\tt 0} and {\tt 1}, to which prime factoring
operations do not apply.
\begin{code}
nat2pmset 0 = []
nat2pmset n = map (to_pos_in (h:ts)) (to_factors (n+1) h ts) where
  (h:ts)=genericTake (n+1) primes
  
to_pos_in xs x = fromIntegral i where
   Just i=elemIndex x xs
\end{code}

The function {\tt pmset2nat} maps back a multiset of positions of primes to
the result of the product of the corresponding primes. Again, we map {\tt []} to
{\tt 0} and shift back by {\tt 1} the result.
\begin{code}
pmset2nat [] = 0
pmset2nat ns = (product ks)-1 where
  ks=map (from_pos_in ps) ns
  ps=primes

from_pos_in xs n = xs !! (fromIntegral n)
\end{code}
We obtain the Encoder:
\begin{code}
pmset :: Encoder [N]
pmset = compose (Iso pmset2nat nat2pmset) nat
\end{code}
working as follows:
\begin{codex}
*ISO> as pmset nat 2008
[3,3,12]
*ISO> as nat pmset it
2008
*ISO> map (as pmset nat) [0..7]
[[],[0],[1],[0,0],[2],[0,1],[3],[0,0,0]]
\end{codex}
Note that the mappings from a set or sequence to a number work in time and
space linear in the bitsize of the number. On the other hand, as prime number
enumeration and factoring are involved in the mapping from numbers to multisets
this encoding is intractable for all but small values.

We are now ready to ``shapeshift'' between data types while watching for
interesting landscapes to show up.

\subsection{Exploring the analogy between multiset decompositions and factoring}

As natural numbers can be uniquely represented as a multiset
of prime factors and, independently, they can also be represented as a multiset
with the Encoder {\tt mset} described in subsection \ref{msetiso}, the following
question arises naturally:

{\em Can in any way the ``easy to reverse'' encoding {\tt mset} emulate or
predict properties of the the difficult to reverse factoring operation?}

The first step is to define an analog of the multiplication operation in terms
of the computationally easy multiset encoding {\tt mset}. Clearly, it makes
sense to take inspiration from the fact that factoring of an ordinary product of 
two numbers can be computed by concatenating the multisets of 
prime factors of its operands.

\begin{code}
mprod = borrow_from2 mset (++) nat
\end{code}
\begin{prop}
$<N,mprod,0>$ is a commutative monoid i.e. {\tt mprod} is defined for all pairs of natural
numbers and it is associative, commutative
and has 0 as an identity element.
\end{prop}
After rewriting the definition of {\tt mprod} as the equivalent:
\begin{code}
mprod_alt n m = as nat mset ((as mset nat n) ++ (as mset nat m))
\end{code}
the proposition follows immediately from the associativity of the
concatenation operation and the order independence of the multiset
encoding provided by {\tt mset}.

We can derive an exponentiation operation as a repeated application of
{\tt mprod}:
\begin{code}
mexp n 0 = 0
mexp n k = mprod n (mexp n (k-1))
\end{code}

Here are a few examples comparing {\tt mprod} to ordinary multiplication and
exponentiation:
\begin{codex}
*ISO> mprod 41 (mprod 33 88)
3539
*ISO> mprod (mprod 41 33)  88
3539
*ISO> mprod 33 46
605
*ISO> mprod 46 33
605
*ISO> mprod 0 712
712
*ISO> mprod 5513 0
5513

*ISO> (41*33)*88
119064
*ISO> 41*(33*88)
119064
*ISO> 33*46
1518
*ISO> 46*33
1518
*ISO> 1*712
712
*ISO> 5513*1
5513
*ISO> map (\x->mexp x 2) [0..15]
[0,3,6,15,12,27,30,63,24,51,54,111,60,123,126,255]
*ISO> map (\x->x^2) [0..15]
[0,1,4,9,16,25,36,49,64,81,100,121,144,169,196,225]
\end{codex}
Note also that any multiset encoding of natural numbers can be
used to define a similar commutative monoid structure. In the case of {\tt
pmset} we obtain:
\begin{code}
pmprod n m = as nat pmset ((as pmset nat n) ++ (as pmset nat m))
\end{code}
If one defines:
\begin{code}
pmprod' n m = (n+1)*(m+1)-1
\end{code}
it follows immediately from the definition of {\tt mprod} that:
\begin{equation}
pmprod \equiv pmprod'
\end{equation}
This is useful as computing {\tt pmprod'} is easy while computing {\tt mprod} is
intractable for large values. This brings us back to observe that:
\begin{prop}
$<N,pmprod,0>$ is a commutative monoid i.e. {\tt pmprod} is defined for all pairs of
natural numbers and it is associative, commutative
and has 0 as an identity element.
\end{prop}

Fig. \ref{mprodfig} compares the shapes of {\tt pmprod'} (virtually the same as
ordinary multiplication) and mprod for operands in $[0..2^7-1]$. 
One can see the contrast between the regular shape of ordinary multiplication
and the recursively ``self-similar'' landscape induced by {\tt mprod}.
\VFIGS{mprodfig}
{multiplication vs mprod}
{pmprod'}{mprod}{isoProdN.pdf}{isoMprodN.pdf}

One can also bring {\tt mprod} closer to ordinary multiplication by defining
\begin{code}
mprod' 0 _ = 0
mprod' _ 0 = 0
mprod' m n = (mprod (n-1) (m-1)) + 1

mexp' n 0 = 1
mexp' n k = mprod' n (mexp' n (k-1))
\end{code}
and by observing that they correlate as follows:
\begin{codex}
*ISO> map (\x->mexp' x 2) [0..16]
[0,1,4,7,16,13,28,31,64,25,52,55,112,61,124,127,256]
*ISO> map (\x->x^2) [0..16]
[0,1,4,9,16,25,36,49,64,81,100,121,144,169,196,225,256]
[0,1,8,15,64,29,120,127,512,57,232,239,960,253,1016,1023,4096]
*ISO> map (\x->x^3) [0..16]
[0,1,8,27,64,125,216,343,512,729,1000,1331,1728,2197,2744,3375,4096]
\end{codex}
Fig. \ref{isoExpMexp} shows that values for {\tt mexp'} follow from below those
of the $x^2$ function and that equality only holds when x is a power of 2.
\FIG{isoExpMexp}{Square vs. mexp' n 2 }{0.40}{isoExpMexp.pdf}

Note that the structure induced by {\tt mprod'} is similar to ordinary
multiplication:
\begin{prop}
$<N,mprod',1>$ is a commutative monoid i.e. {\tt mprod'} is defined for all pairs of
natural numbers and it is associative, commutative
and has {\tt 1} as an identity element.
\end{prop}
Interestingly, {\tt mprod'} coincides with ordinary multiplication if one of the
operands is a power of 2. More precisely, the following holds:
\begin{prop}
$mprod'~x~y = x * y$ if and only if 
$\exists n \geq 0$ such that $x=2^n$ or $y=2^n$.
Otherwise, $mprod'~x~y <  x * y$.
\end{prop}
Fig. \ref{isoMdivP} shows the self-similar landscape
generated by the $[0..1]$-valued function {\tt (mprod' x y) / (x*y)}
for values of x,y in $[1..128]$.
\FIG{isoMdivP}{Ratio between mprod' and product}{0.40}{isoMdivP.pdf}

Besides the connection with products, natural mappings worth investigating are
the analogies between {\em multiset intersection} and {\tt gcd} of the
corresponding numbers or between {\em multiset
union} and the {\tt lcm} of the corresponding numbers. Assuming the
definitions of multiset operations provided in the Appendix, one can define:

\begin{code}
mgcd :: N -> N -> N
mgcd = borrow_from2 mset msetInter nat

mlcm :: N -> N -> N
mlcm = borrow_from2 mset msetUnion nat

mdiv :: N -> N -> N
mdiv = borrow_from2 mset msetDif nat
\end{code}
and note that properties similar to usual arithmetic operations hold:
\begin{equation}
mprod (mgcd~x~y) (mlcm~x~y)  \equiv mprod~x~y
\end{equation}
\begin{equation}
mdiv (mprod~x~y)~y \equiv x
\end{equation}
\begin{equation}
mdiv (mprod~x~y)~x \equiv y
\end{equation}

We are now ready to ``emulate'' primality in our multiset monoid by defining
{\tt is\_mprime} as a recognizer for {\em multiset primes} and {\tt mprimes} as
a generator of their infinite stream:
\begin{code}
is_mprime p = []==[n|n<-[1..p-1],n `mdiv` p==0]

mprimes = filter is_mprime [1..]
\end{code}
Trying out {\tt mprimes} gives:
\begin{codex}
*ISO> take 10 mprimes
[1,2,4,8,16,32,64,128,256,512]
\end{codex}
suggesting the following proposition:
\begin{prop}
There's an infinite number of {\em multiset primes} and they are exactly the
powers of 2.
\end{prop}
The proof follows immediately from obeserving that the first value of {\tt
as mset nat n} to contain $k$ is $n=2^k$ and the definition of {\tt mdiv} as
derived from multiset difference operation {\tt msetDif}.

While {\tt mprod,mprod',pmprod'} and {\tt pmprod} are not distributive with
ordinary addition, it looks like an interesting problem to find for each of
them compatible additive operations.

\subsection{Unfolding Natural Numbers into Bitstrings} \label{bits}
The isomorphism between natural numbers and bitstrings is well known, except
that it is usually ignored that conventional bit representations
of integers need a twist to be mapped one-to-one to
{\em arbitrary} sequences of {\tt 0}s and {\tt 1}s.
As the usual binary representation always has
{\tt 1} as its highest digit, {\tt nat2bits}
will drop this bit, given
that the length of the list of digits is 
(implicitly) known. This transformation (a variant of the so called {\em
bijective base n} representation), brings us an isomorphism between $\mathbb{N}$ and
the regular language $\{0,1\}^*$.
\begin{code}
bits :: Encoder [N]
bits = compose (Iso bits2nat nat2bits) nat

nat2bits = drop_last . (to_base 2) . succ

bits2nat bs = pred (from_base 2 (bs ++ [1]))

drop_last =
    reverse . tail . reverse

bits1 :: Encoder [N]
bits1 = compose (Iso (from_base 2) (to_base 2)) nat

to_base base n = d : 
  (if q==0 then [] else (to_base base q)) where
     (q,d) = quotRem n base
    
from_base base [] = 0
from_base base (x:xs) | x>=0 && x<base = 
   x+base*(from_base base xs)
\end{code}
In contrast with the conventional 1-terminated {\tt bits1} encoder, the {\tt
bits} encoder achieves the information theoretical optimum. Note also that,
strictly speaking, this is only an isomorphism when the digits in the bitlist are in $\{0,1\}$,
therefore we shall assume this constraint
as a {\em law} governing this Encoder. Similarly, {\tt bits1} is assumed
constrained by working on 1-terminated bit sequences or {\tt [0]} retresenting
{\tt 0} as usual. The following examples show two conversion operations and
$bits$ borrowing a multiplication operation from $nat$.
\begin{codex}
*ISO> as bits nat 42
[1,1,0,1,0]
*ISO> as nat bits [1,1,0,1,0]
42
*ISO> as bits1 nat 42
[0,1,0,1,0,1]
*ISO> as nat bits1 it
42
*ISO> borrow2 (with nat bits) (*) [1,1,0] [1,0,1,1]
[1,0,0,1,1,0,0,0]
\end{codex}

The reader might notice at this point that we have
made full circle again - as bitstrings can be seen as
instances of finite sequences. 
Injective functions that are not surjections 
with wider and wider gaps can be generated
by composing the {\tt as} combinators:
\begin{codex}
*ISO> as bits fun [1,1]
[1,1,0]
*ISO> as bits fun (as bits fun [1,1])
[1,1,0,1]
*ISO> as bits fun $ as bits fun $ as bits fun [1,1]
[1,1,0,1,1,0]
\end{codex}

One can introduce an automorphism\footnote{An isomorphism from a data type to
itself} on bit sequences by defining:
\begin{code}
dual bs = map f bs where
  f 0=1
  f 1=0
\end{code}
and derive the Encoder
\begin{code}
bits' :: Encoder [N]
bits' = compose (Iso dual dual) bits
\end{code}
The action of {\tt bits'} can be seen as the one of {\tt bits} with {\tt 0}s
and {\tt 1}s interchanged.
\begin{codex}
*ISO> as bits nat 42
[1,1,0,1,0]
*ISO> as bits' nat 42
[0,0,1,0,1]
*ISO> as nat bits' it
42
\end{codex}
One can see the effect of this duality on natural numbers with
\begin{code}
ndual = borrow_from bits dual nat
\end{code}
working as follows:
\begin{codex}
*ISO> map ndual [0..15]
[0,2,1,6,5,4,3,14,13,12,11,10,9,8,7,30]
\end{codex}

\subsection{Encoding Binary reflected Gray code}
{\em Binary reflected Gray code}
provides an encoding such that successive natural numbers differ by only one bit
(except for steep transitions when cycles end).
\begin{code}
nat2gray :: N->N
nat2gray n= n `xor` (shiftR n 1)

gray2nat = borrow_from bits1 (scanr1 xor) nat

gray :: Encoder N
gray = compose (Iso nat2gray gray2nat) nat
\end{code}
This encoder provides an automorphism on $\mathbb{N}$ with the remarcable
property that it is also a permutation for each initial segment $[0..2^n-1]$.
\begin{codex}
*ISO> map (as gray nat) [0..15]
[0,1,3,2,7,6,4,5,15,14,12,13,8,9,11,10]
*ISO> map (as nat gray) it
[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]
*ISO> map (as nat gray) [0..15]
[0,1,3,2,6,7,5,4,12,13,15,14,10,11,9,8]
*ISO> map (as gray nat) it
[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]
\end{codex}
The two automorphisms are respectively sequences A003188 and A006068 in the
{\em On-Line Encyclopedia of Integer Sequences}, 
\url{http://www.research.att.com/~njas/sequences}:

\subsection{Encoding numbers in bijective base-k} \label{bijnat}

The conventional numbering system does not provide a bijection between
arbitrary combinations of digits and natural numbers, given that leading 0s are
ignored. An encoder generalizing {\tt bits} for {\em numbers in bijective
base-k} that provides such a bijection is implemented as follows:
\begin{code}
bijnat :: N->Encoder [N]

bijnat a = compose (Iso (from_bbase a) (to_bbase a)) nat

from_bbase base xs = from_base' base (map succ xs)

from_base' base [] = 0
from_base' base (x:xs) | x>0 && x<=base = 
   x+base*(from_base' base xs)
   
to_bbase base n = map pred (to_base' base n)

to_base' _ 0 = []
to_base' base n = d' : ds where
   (q,d) = quotRem n base
   d'=if d==0 then base else d
   q'=if d==0 then q-1 else q
   ds=if q'==0 then [] else to_base' base q'
\end{code}
Note that the encoder bijnat is parametrized by the base of numberation, i.e.
the {\tt as} combinator works as follows:
\begin{codex}
*ISO> as (bijnat 3) nat 2009
[1,2,2,0,2,0,1]
*ISO> as nat (bijnat 3) it
2009
*ISO> as (bijnat 10) nat 2009
[8,9,8,0]
*ISO> as nat (bijnat 10) it
2009
*ISO> map (as (bijnat 3) nat) [0..12]
[[],[0],[1],[2],[0,0],[1,0],[2,0],[0,1],
    [1,1],[2,1],[0,2],[1,2],[2,2]]
\end{codex}
This encoding will turn out to be useful for instance in uniquely encoding
symbols and strings of a finite alphabet.

\subsection{Encoding Signed Integers}
To encode signed integers one can map positive numbers to even numbers and
strictly negative numbers to odd numbers. This gives the Encoder:
\begin{code}
type Z = Integer
z:: Encoder Z
z = compose (Iso z2nat nat2z) nat

nat2z n = if even n then n `div` 2 else (-n-1) `div` 2
z2nat n = if n<0 then -2*n-1 else 2*n
\end{code}
working as follows:
\begin{codex}
*ISO> as set z (-42)
[0,1,4,6]
*ISO> as z set [0,1,4,6]
-42
\end{codex}
As an interesting consequence, one can turn natural numbers into a {\em} group
by borrowing subtraction from integers as follows:
\begin{codex}
0
*ISO> borrow_from2 z (-) nat 0 1
2
*ISO> borrow_from2 z (-) nat 0 2
1
*ISO> borrow_from2 z (-) nat 0 3
4
*ISO> borrow_from2 z (-) nat 0 4
3
*ISO> borrow_from2 z (-) nat 0 5
6
*ISO> borrow_from2 z (-) nat 10 20
9
\end{codex}
More precisely one can borrow the additive group structure of {\tt z} and
induce an additive group strucure on {\tt nat} by defining:
\begin{code}
nplus x y = borrow_from2 z (+) nat x y
nneg x = borrow_from z (\x->0-x) nat x
\end{code}
The following holds:
\begin{prop}
$<\mathbb{N},nplus,nneg,0>$ is an additive group, with addition provided $nplus$ and
inverse by $nneg$.
\end{prop}
Similarly after defining a multiplication operation
\begin{code}
nprod = borrow_from2 z (*) nat
\end{code}
one can obtain a ring structure on $\mathbb{N}$ with units {\tt 1 = as nat z (-1)} and
{\tt 2=as nat z 1}.


\subsection{Functional Binary Numbers}

Church numerals are well known as a functional
representation for Peano arithmetic. While
benefiting from lazy evaluation, they
implement a form of unary arithmetic
that uses $O(n)$ space to represent $n$.
This suggest devising a functional representation
that mimics binary numbers. We will do this 
following the model described in subsection \ref{bits}
to provide an isomorphism between $\mathbb{N}$ 
and the functional equivalent of
the regular language $\{0,1\}^*$. We will
view each bit as a $\mathbb{N} \rightarrow \mathbb{N}$ 
transformer:
\begin{code}
b x = pred x -- begin
o x = 2*x+0  -- bit 0
i x = 2*x+1  -- bit 1
e = 1        -- end
\end{code}
As the following example shows, composition
of functions $o$ and $i$
closely parallels the corresponding bitlists: 
\begin{codex}
*ISO> b$i$o$o$i$i$o$i$i$i$i$e
2008
*ISO> as bits nat 2008
[1,0,0,1,1,0,1,1,1,1]
\end{codex}
%$

We can follow the same model with an abstract data type:
\begin{code}
data D = E | O D | I D deriving (Eq,Ord,Show,Read)
data B = B D deriving (Eq,Ord,Show,Read)
\end{code}
from which we can generate functional
bitstrings as an instance of a {\em fold} operation:
\begin{code}
funbits2nat :: B -> N
funbits2nat = bfold b o i e

bfold fb fo fi fe (B d) = fb (dfold d) where
  dfold E = fe
  dfold (O x) = fo (dfold x)
  dfold (I x) = fi (dfold x)
\end{code}
Dually, we can reverse the effect of the functions $b,o,i,e$ as:
\begin{code}
b' x = succ x
o' x | even x = x `div` 2
i' x | odd x = (x-1) `div` 2
e' = 1
\end{code}
and define a generator for our data type as an {\em unfold} operation:
\begin{code}
nat2funbits :: N -> B
nat2funbits = bunfold b' o' i' e'

bunfold fb fo fi fe x = B (dunfold (fb x)) where
  dunfold n | n==fe = E
  dunfold n | even n = O (dunfold (fo n))
  dunfold n | odd n = I (dunfold (fi n))
\end{code}
The two operations form an isomorphism:
\begin{codex}
*ISO> funbits2nat (B $ I $ O $ O $ I $ I $ O $ I $ I $ I $ I $ E)
2008
*ISO> nat2funbits it
B (I (O (O (I (I (O (I (I (I (I E))))))))))
\end{codex}
%$
We can define our Encoder as follows:
\begin{code}
funbits :: Encoder B
funbits = compose (Iso funbits2nat nat2funbits) nat
\end{code}

Arithmetic operations can now be performed directly on this representation.
For instance, one can define a successor function as:
\begin{code}
bsucc (B d) = B (dsucc d) where
  dsucc E = O E
  dsucc (O x) = I x
  dsucc (I x) = O (dsucc x) 
\end{code}
Equivalently arithmetics can be borrowed from $\mathbb{N}$:
\begin{codex}
*ISO> bsucc (B $ I $ O $ O $ I $ I $ O $ I $ I $ I $ I $ E)
B (O (I (O (I (I (O (I (I (I (I E))))))))))
*ISO> as nat funbits it
2009
*ISO> borrow (with nat funbits) 
             succ (B $ I $ O $ O $ I $ I $ O $ I $ I $ I $ I $ E)
B (O (I (O (I (I (O (I (I (I (I E))))))))))
*ISO> as nat funbits it
2009
\end{codex}
While Haskell's C-based arbitrary length integers are likely
to be more efficient for most operations, this representation, like Church
numerals, has the benefit of supporting partial or delayed computations
through lazy evaluation.

\section{Generic Unranking and Ranking Hylomorphisms}
\label{unrank}

The {\em ranking problem} for a family of
combinatorial objects is finding a unique 
natural number associated to it,
called its {\em rank}.
The inverse {\em unranking problem} consists of generating a unique
combinatorial object associated to each natural number. 

\subsection{Pure Hereditarily Finite Data Types}

The unranking operation is seen here as an instance of a generic
{\em anamorphism} mechanism (an {\em unfold} operation), while the ranking
operation is seen as an instance of the corresponding catamorphism (a {\em
fold} operation) \cite{DBLP:journals/jfp/Hutton99,DBLP:conf/fpca/MeijerH95}.
Together they form a mixed transformation called {\em hylomorphism}. 
We will use such hylomorphisms to lift isomorphisms between lists
and natural numbers to isomorphisms between a derived ``self-similar'' tree
data type and natural numbers.
In particular we will derive Ackermann's encoding
from Hereditarily Finite Sets to Natural Numbers.

The data type representing hereditarily finite structures will be
a generic multi-way tree with a single leaf type {\tt []}.

\begin{code}
data T = H [T] deriving (Eq,Ord,Read,Show)
\end{code}
The two sides of our hylomorphism 
are parameterized by two transformations
{\tt f} and {\tt g} forming
an isomorphism {\tt Iso f g}:
\begin{code}
unrank f n = H (unranks f (f n))
unranks f ns = map (unrank f) ns

rank g (H ts) = g (ranks g ts)
ranks g ts = map (rank g) ts
\end{code}
Both combinators can be seen as a form of ``structured recursion''
that propagate a simpler operation guided by the structure of
the data type. For instance, the size of a tree of type $T$ is
obtained as:
\begin{code}
tsize = rank (\xs->1 + (sum xs))
\end{code}
Note also that {\tt unrank} and {\tt rank}
work on $T$ in cooperation
with {\tt unranks} and {\tt ranks} 
working on $[T]$. 

We can now combine an 
anamorphism+catamorphism pair into
an isomorphism {\tt hylo} defined
with {\tt rank} and {\tt unrank} 
on the corresponding
hereditarily finite data types:
\begin{code}
hylo :: Iso b [b] -> Iso T b
hylo (Iso f g) = Iso (rank g) (unrank f)

hylos :: Iso b [b] -> Iso [T] [b]
hylos (Iso f g) = Iso (ranks g) (unranks f)
\end{code}

\subsubsection{Hereditarily Finite Sets}
Hereditarily Finite Sets will be represented
as an Encoder for the tree type {\tt T}:
\begin{code}
hfs :: Encoder T
hfs = compose (hylo nat_set) nat
\end{code}
The {\tt hfs} Encoder can now borrow operations from
sets or natural numbers as follows:
\begin{code}
hfs_union = borrow2 (with set hfs) union
hfs_succ = borrow (with nat hfs) succ
hfs_pred = borrow (with nat hfs) pred
\end{code}
\begin{codex}
*ISO> hfs_succ (H [])
H [H []]
*ISO> hfs_union (H [H []] ) (H [])
H [H []]
\end{codex}
Otherwise, hylomorphism induced isomorphisms
work as usual with our embedded
transformation language:
\begin{codex}
*ISO> as hfs nat 42
H [H [H []],H [H [],H [H []]],H [H [],H [H [H []]]]]
*ISO> as hfs nat 2008
H [H [H [],H [H []]],H [H [H [H []]]],H [H [H []],
   H [H [H []]]],H [H [],H [H []],H [H [H []]]],
   H [H [H [],H [H []]]],H [H [],H [H [],H [H []]]],
   H [H [H []],H [H [],H [H []]]]]
\end{codex}
One can notice that we have just derived as a
``free algorithm'' Ackermann's encoding
\cite{ackencoding,DBLP:journals/tplp/PiazzaP04}
from Hereditarily Finite Sets to Natural Numbers:
\vskip 0.30cm
$f(x)$ = {\tt if} $x=\{\}$ {\tt then} $0$ {\tt else} $\sum_{a \in x}2^{f(a)}$
\vskip 0.30cm
\noindent together with its inverse:
\begin{code}
ackermann = as nat hfs
inverse_ackermann = as hfs nat
\end{code}
One can represent the action of a hylomorphism unfolding a natural number into
a hereditarily finite set as a directed graph with outgoing edges
induced by by applying the {\tt inverse\_ackermann} function as shown
in Fig. \ref{f1}.

\FIG{f1}{2008 as a HFS}{0.60}{isof1.pdf}

\subsubsection{Hereditarily Finite Functions}
The same tree data type can host a hylomorphism
derived from finite functions instead of
finite sets:
\begin{code}
hff :: Encoder T
hff = compose (hylo nat) nat
\end{code}
The {\tt hff} Encoder can be seen as another ``free algorithm'', providing
data compression/succinct representation for Hereditarily 
Finite Sets. Note, for instance,
the significantly smaller tree size in:
\begin{codex}
*ISO> as hff nat 42
H [H [H []],H [H []],H [H []]]
*ISO> as hff nat 2008
H [H [H [],H []],H [],H [H []],H [],H [],H [],H []]
\end{codex}
As the cognoscenti might observe 
this is explained by the fact that
{\tt hff} provides higher information density
than {\tt hfs}, by incorporating order information
that matters in the case of a sequence and
is ignored in the case of a set.
One can represent the action of a hylomorphism unfolding a natural number into
a hereditarily finite function as a directed ordered multi-graph as shown
in Fig. \ref{f2}. Note that as the mapping {\tt as fun nat} generates
a sequence where the order of the edges matters, this order is
indicated integers starting from {\tt 0} labeling the edges.
\FIG{f2}{2008 as a HFF}{0.60}{isof2.pdf}

It is also interesting to connect sequences and HFF directly - in case one
wants to represent giant ``sparse numbers'' that correspond to sequences
that would overflow memory if represented as natural numbers but have a
relatively simple structure as formulae used to compute them. We obtain the
Encoder:
\begin{code}
hffs :: Encoder T
hffs = Iso hff2fun fun2hff

fun2hff ns = H (map (as hff nat) ns)
hff2fun (H hs) = map (as nat hff) hs
\end{code}
which can be used to generate HFFs associated to very large numbers:
\begin{codex}
*ISO> as hffs fun [2^65,2^131]
H [H [H [H [],H [H [],H [H []]]]],H [H [H [],H [],H [H [],H [H []]]]]]
\end{codex}

\subsection{Hereditarily Finite Multisets}
In a similar way, one can derive an Encoder for Hereditarily Finite Multisets
based on either the {\tt mset} or the {\tt pmset} isomorphisms:
\begin{code}
nat_mset = Iso nat2mset mset2nat

hfm :: Encoder T
hfm = compose (hylo nat_mset) nat

nat_pmset = Iso nat2pmset pmset2nat

hfpm :: Encoder T
hfpm = compose (hylo nat_pmset) nat
\end{code}
working as follows:
\begin{codex}
*ISO> as hfm nat 2008
H [H [H [],H []],H [H [],H []],H [H [H [H []]]],H [H [H [H []]]],
   H [H [H [H []]]],H [H [H [H []]]],H [H [H [H []]]]]
*ISO> as nat hfm it
2008

*ISO> as hfpm nat 2008
H [H [H [],H []],H [H [],H []],H [H [H [],H [H []]]]]
*ISO> as nat hfpm it
2008
\end{codex}
After implementing this encoding some Google search revealed that it is
essentially the same as \cite{DBLP:journals/jct/Gobel80} where
it appears as an encoding of {\em rooted trees}.

\subsection{A Hylomorphism with Atoms/Urelements}
A similar construction can be carried out for the
more practical case when Atoms ({\em Urelements}
in Set Theory parlance) are present.
Hereditarily Finite Sets with Urelements are
represented as generic multi-way trees with a
leaf type holding urelements/atoms:
\begin{code}
data UT a = A a | F [UT a] deriving (Eq,Ord,Read,Show)
\end{code}
Atoms will be mapped to natural numbers in {\tt [0..ulimit-1]}.
Assuming for simplicity that {\tt ulimit} is fixed, we 
denote this set $A$ and 
denote $UT$ the set of trees of type $UT$ with atoms in $A$.

\paragraph*{Unranking} As an adaptation of the {\em unfold} 
operation, natural numbers will be mapped to elements of $UT$ with a generic 
higher order function {\tt unrankU f}, defined from $\mathbb{N}$ to $UT$, 
parameterized by the natural number {\tt ulimit}
and the transformer function {\tt f}:
\begin{code}
ulimit = 2^14
\end{code}

\begin{code}
unrankU = unrankUL ulimit
unranksU = unranksUL ulimit

unrankUL l _ n | n>=0 && n<l = A n
unrankUL l f n = F (unranksUL l f (f (n-l)))

unranksUL l f ns =  map (unrankUL l f) ns
\end{code}

\paragraph*{Ranking} Similarly, as an adaptation of {\em fold}, a generic
inverse mapping {\tt rankU} is defined as:
\begin{code}
rankU = rankUL ulimit
ranksU = ranksUL ulimit

rankUL l _ (A n) | n>=0 && n<l = n
rankUL l g (F ts) = l+(g (ranksUL l g ts))

ranksUL l g ts = map (rankUL l g) ts
\end{code}
where {\tt rankU g} maps trees to numbers and
{\tt ranksU g} maps lists of trees to lists of numbers.

The following proposition describes conditions under which
{\tt rankU} and {\tt unrankU} can be used to lift isomorphisms
between $[\mathbb{N}]$ and $\mathbb{N}$ to isomorphisms involving
hereditarily finite structures:

\begin{prop}
If the transformer function $f:\mathbb{N} \rightarrow [\mathbb{N}]$ is a bijection 
with inverse $g$, such that 
$n \geq ulimit \wedge f(n)=[n_0,...n_i,...n_k] \Rightarrow n_i<n$, 
then $(unrankU~f) : \mathbb{N} \rightarrow UT$ 
is a bijection  
with inverse $(rankU~ g) : UT \rightarrow \mathbb{N}$ 
and the recursive computations defining both functions
terminate in a finite number of steps.
\end{prop}

\begin{proof} Note that {\tt unrankU} terminates as its arguments strictly
decrease at each step and {\tt rankU} terminates as leaf nodes are eventually
reached. That both are bijections, follows by induction on the 
structure of $\mathbb{N}$ and $UT$,
given that {\tt map} preserves bijections and that adding/subtracting 
{$ulimit$} ensures that encodings of atoms and sets never overlap.
\end{proof}

The resulting hylomorphisms are defined as previously:
\begin{code}
hyloU (Iso f g) = Iso (rankU g) (unrankU f)
hylosU (Iso f g) = Iso (ranksU g) (unranksU f)
\end{code}
An Encoder for Hereditarily Finite Sets with Urelements is defined as:
\begin{code}
uhfs :: Encoder (UT N)
uhfs = compose (hyloU nat_set) nat
\end{code}
Note that this encoder provides a generalization of Ackermann's mapping,
to Hereditarily Finite Sets with Urelements in $[0..u-1]$ defined as:

\vskip 0.30cm
$f_{u}(x)$ = 
{\tt if} $x<u$ 
{\tt then} $x$
{\tt else} $u+\sum_{a\in x}2^{f_{u}(a)}$ 
\vskip 0.30cm

A similar Encoder for Hereditarily Finite Functions with Urelements is defined
as:
\begin{code}
uhff :: Encoder (UT N)
uhff = compose (hyloU nat) nat
\end{code}

\subsection{Extending the encoding for the case of an infinite 
set of Atoms/Urelements} 

An adaptation of the previous construction for the case when an infinite supply
of atoms/urelements is needed (i.e. when their number is not known in  advance)
follows.

\paragraph*{Unranking} As an adaptation of the {\em unfold} 
operation, natural numbers will be mapped to elements of $UT$ with a generic 
higher order function {\tt unrankIU f}, defined from $\mathbb{N}$ to $UT$, 
parameterized by the transformer function {\tt f}:

\begin{code}
unrankIU _ n | even n = A (n `div` 2) 
unrankIU f n = F (unranksIU f (f  ((n-1) `div` 2)))

unranksIU f ns =  map (unrankIU f) ns
\end{code}
Note that (an infinite supply of) even numbers provides codes for atoms, while
odd numbers are used to encode the non-leaf structure of the trees in {\tt UT}.

\paragraph*{Ranking} Similarly, as an adaptation of {\em fold}, a generic
inverse mapping {\tt rankIU g} is defined as:
\begin{code}
rankIU _ (A n) = 2*n
rankIU g (F ts) = 1+2*(g (ranksIU g ts))

ranksIU g ts = map (rankIU g) ts
\end{code}
where {\tt rankIU g} maps trees to numbers and
{\tt ranksIU g} maps lists of trees to lists of numbers.

The resulting hylomorphisms are defined as previously:
\begin{code}
hyloIU (Iso f g) = Iso (rankIU g) (unrankIU f)
hylosIU (Iso f g) = Iso (ranksIU g) (unranksIU f)
\end{code}
An Encoder for Hereditarily Finite Sets with an infinite supply of Urelements is
defined as:
\begin{code}
iuhfs :: Encoder (UT N)
iuhfs = compose (hyloIU nat_set) nat
\end{code}

A similar Encoder for Hereditarily Finite Functions with and infinite
supply of Urelements is defined as:
\begin{code}
iuhff :: Encoder (UT N)
iuhff = compose (hyloIU nat) nat
\end{code}

\section{Permutations and Hereditarily Finite Permutations} \label{perm}
We have seen that finite sets and their derivatives represent
information in an {\em order} independent way, focusing exclusively
on information {\em content}. 
We will now look at data representations that focus exclusively on {\em order}
in a {\em content} independent way - finite permutations and their hereditarily
finite derivatives.

To obtain an encoding for finite permutations
we will first review a ranking/unranking mechanism for permutations that
involves an unconventional numeric representation, {\em factoradics}.

\subsection{The Factoradic Numeral System}
The factoradic numeral system \cite{knuth_art_1997-1} replaces digits
multiplied by a power of a base $n$ with digits that multiply successive values
of the factorial of $n$. In the increasing order variant {\tt fr} the first
digit $d_0$ is 0, the second is $d_1 \in \{0,1\}$ and the $n$-th is $d_n \in
[0..n]$. For instance, $42=0*0!+0*1!+0*2!+3*3!+1*4!$.
The left-to-right, decreasing order variant {\tt fl} 
is obtained by reversing the digits of {\tt fr}.
\begin{codex}
fr 42
  [0,0,0,3,1]
rf [0,0,0,3,1]
  42
fl 42
  [1,3,0,0,0]
lf [1,3,0,0,0]
  42
\end{codex}
\noindent The function {\tt fr} 
generating the factoradics of n, right to left,
handles the special case of $0$ and
calls a local function {\tt f} which recurses and divides with increasing values
of $n$ while collecting digits with {\tt mod}:
% f n = foldl (*) 1 [1..n]
\begin{code}
fr 0 = [0]
fr n = f 1 n where
   f _ 0 = []
   f j k = (k `mod` j) : 
           (f (j+1) (k `div` j))
\end{code}
The function {\tt fl}, with digits left to right is obtained as follows:
\begin{code}
fl = reverse . fr
\end{code}
The function {\tt lf} (inverse of {\tt fl}) converts back to decimals by
summing up results while computing the factorial progressively:
\begin{code}
rf ns = sum (zipWith (*) ns factorials) where
  factorials=scanl (*) 1 [1..]
\end{code}
Finally, {\tt lf}, the inverse of {\tt fl} is obtained as:
\begin{code}
lf = rf . reverse
\end{code}

\subsection{Ranking and unranking permutations of given size with Lehmer codes
and factoradics} 
The Lehmer code of a permutation $f$ of size $n$ is defined as the sequence
$l(f)=(l_1(f) \ldots l_i(f) \ldots l_n(f))$ 
where $l_i(f)$ is the number
of elements of the set $\{j>i|f(j)<f(i)\}$
\cite{DBLP:journals/dmtcs/MantaciR01}.
 \begin{prop}
 The Lehmer code of a permutation determines the permutation uniquely.
 \end{prop} 
The function {\tt perm2nth} computes a {\tt rank} 
for a permutation {\tt ps} of {\tt size>0}. 
It starts by first computing its Lehmer code {\tt ls} with 
{\tt perm2lehmer}. Then  it associates a unique natural 
number {\tt n} to {\tt ls}, 
by converting it with the function {\tt lf} 
from factoradics to decimals. 
Note that the Lehmer code {\tt Ls} is used as the list of digits
in the factoradic representation.
\begin{code}
perm2nth ps = (l,lf ls) where 
  ls=perm2lehmer ps
  l=genericLength ls

perm2lehmer [] = []
perm2lehmer (i:is) = l:(perm2lehmer is) where
  l=genericLength [j|j<-is,j<i]  
\end{code}

The function {\tt nat2perm} provides the matching {\em unranking}
operation associating a permutation {\tt ps} to a given {\tt size>0} 
and a natural number {\tt n}. It generates the $n$-th permutation of a given
size.
\begin{code}
nth2perm (size,n) = 
  apply_lehmer2perm (zs++xs) [0..size-1] where 
    xs=fl n
    l=genericLength xs
    k=size-l
    zs=genericReplicate k 0
\end{code}
The following function extracts 
a permutation from a ``digit'' list
in factoradic representation.
\begin{code}
apply_lehmer2perm [] [] = []
apply_lehmer2perm (n:ns) ps@(x:xs) = 
   y : (apply_lehmer2perm ns ys) where
   (y,ys) = pick n ps

pick i xs = (x,ys++zs) where 
  (ys,(x:zs)) = genericSplitAt i xs
\end{code}
\begin{comment}
\begin{code}
lehmer2perm ls = apply_lehmer2perm ls [0..(genericLength ls)-1]
\end{code}
\end{comment}
Note also that {\tt apply\_lehmer2perm} is used this time
to reconstruct the permutation {\tt ps} from its Lehmer code,
which in turn is computed from the permutation's 
factoradic representation.

One can try out this bijective mapping as follows:
\begin{codex}
nth2perm (5,42)
  [1,4,0,2,3]
perm2nth [1,4,0,2,3]
  (5,42)
nth2perm (8,2008)
  [0,3,6,5,4,7,1,2]
perm2nth [0,3,6,5,4,7,1,2]
  (8,2008)
\end{codex}

\subsection{A bijective mapping from permutations to natural numbers}
Like in the case of BDDs, one more step is needed to to extend the mapping
between permutations of a given length to a bijective 
mapping from/to $\mathbb{N}$: we will have to ``shift
towards infinity'' the starting point of each new bloc of permutations in $\mathbb{N}$
as permutations of larger and larger sizes are enumerated.

First, we need to know by how much - so we compute the sum of
all factorials up to $n!$.
\begin{code}
sf n = rf (genericReplicate n 1)
\end{code}
This is done by noticing that the factoradic representation of
[0,1,1,..] does just that.

What we are really interested into, is decomposing {\tt n} into
the distance to the
last sum of factorials smaller than {\tt n}, {\tt n\_m}
and the its index in the sum, {\tt k}.
\begin{code}
to_sf n = (k,n-m) where 
  k=pred (head [x|x<-[0..],sf x>n])
  m=sf k
\end{code}
{\em Unranking} of an arbitrary permutation is now easy - the index {\tt k}
determines the size of the permutation and {\tt n-m} determines
the rank. Together they select the right permutation with {\tt nth2perm}.
\begin{code}
nat2perm 0 = []
nat2perm n = nth2perm (to_sf n)
\end{code}
{\em Ranking} of a permutation is even easier: we first compute
its size and its rank, then we shift the rank by 
the sum of all factorials up to its size, enumerating the
ranks previously assigned.
\begin{code}
perm2nat ps = (sf l)+k where 
  (l,k) = perm2nth ps
\end{code}
It works as follows:
\begin{codex}
nat2perm 2008
  [0,2,3,1,4]
perm2nat [0,2,3,1,4]
  42
nat2perm 2008
  [1,4,3,2,0,5,6]
perm2nat [1,4,3,2,0,5,6]
  2008
\end{codex}

We can now define the Encoder as:
\begin{code}
perm :: Encoder [N]
perm = compose (Iso perm2nat nat2perm) nat
\end{code}
The Encoder works as follows:
\begin{codex}
*ISO> as perm nat 2008
[1,4,3,2,0,5,6]
*ISO> as nat perm it
2008
*ISO> as perm nat 1234567890
[1,6,11,2,0,3,10,7,8,5,9,4,12]
*ISO> as nat perm it
1234567890
\end{codex}

\subsection{Hereditarily Finite Permutations}

By using the generic {\tt unrank} and {\tt rank} functions defined 
in section \ref{unrank} we can extend the isomorphism defined by {\tt nat2perm}
and {\tt perm2nat} to encodings of Hereditarily Finite Permutations ($HFP$).
\begin{code}
nat2hfp = unrank nat2perm
hfp2nat = rank perm2nat
\end{code}
The encoding works  as follows:
\begin{codex}
*ISO> nat2hfp 42
H [H [],H [H [],H [H []]],H [H [H []],H []],
   H [H []],H [H [],H [H []],H [H [],H [H []]]]]
*ISO> hfp2nat it
  42
\end{codex}
We can now define the Encoder as:
\begin{code}
hfp :: Encoder T
hfp = compose (Iso hfp2nat nat2hfp) nat
\end{code}
The Encoder works as follows:
\begin{codex}
*ISO> as hfp nat 42
H [H [],H [H [],H [H []]],H [H [H []],H []],
   H [H []],H [H [],H [H []],H [H [],H [H []]]]]
*ISO> as nat hfp it
42
*JFISO> as hfp nat 2008
H [H [H []],H [H [],H [H []],H [H [],H [H []]]],H [H [H []],H []],
  H [H [],H [H []]],H [],H [H [],H [H [],H [H []]],H [H []]],
  H [H [H []],H [],H [H [],H [H []]]]]
*ISO> as nat hfp it
2008
\end{codex}
As shown in Fig \ref{f3} an ordered digraph (with labels starting from 0
representing the order of outgoing edges) can be used to represent the unfolding
of a natural number to the associated hereditarily finite permutation.
\FIG{f3}{2008 as a HFP}{0.60}{isof3.pdf}
An interesting property of graphs associated to hereditarily finite permutations
is that moving from a number n to its successor typically only induces a
reordering of the labeled edges, as shown in Fig. \ref{f4}.
\FIG{f4}{2009 as a HFP}{0.60}{isof4.pdf}

\section{Operations on hereditarily finite structures}

Operations on trees describing hereditarily finite structures induce operations
on natural numbers. Such and operation is replacing the (empty) root of B with
A, {\tt rerootWith}.

\begin{code}
rerootWith a (H []) = a
rerootWith a (H bs) = H (map (rerootWith a) bs)

nreroot t = borrow_from2 t rerootWith nat
\end{code}
working as follows
\begin{codex}
*ISO> nreroot hff 5 0
5
*ISO> nreroot hff 0 5
5
*ISO> nreroot hff 2 3
36
*ISO> nreroot hff 3 2
256
*ISO> nreroot hff 3 3
136
*ISO> nreroot hff 3 4
115792089237316195423570985008687907853269984665640564039457584007913129639936
\end{codex}
An oposite operation {\tt weedWith} can be defined as follows
\begin{code}
weedWith _ (H []) = H []
weedWith w b | w == b = H [] 
weedWith w (H bs) = H (map (weedWith w) bs)

nweed t = borrow_from2 t weedWith nat
\end{code}
\begin{codex}
*ISO> map (nweed hff 1) [0..15]
[0,0,1,3,2,3,3,7,8,5,3,7,6,7,7,15]
*ISO> map (nweed hff 2) [0..15]
[0,1,0,3,1,5,6,7,8,3,10,11,3,13,14,15]
\end{codex}
Note that the weedWith operation is not total on HFS.
Note also that rerroot and weed are not inverse operations
as weed might also remove subtrees not originating from a previous
reroot operation.

Another interesting operation is trimming of empty leaves.
\begin{code}
trimEmpty (H []) = H []
trimEmpty (H xs) = H (trimEmpties xs)

trimEmpties [] = []
trimEmpties ((H []):xs) = trimEmpties xs
trimEmpties (x:xs)=(trimEmpty x):trimEmpties xs

ntrim t = borrow_from t trimEmpty nat
\end{code}
\begin{codex}
*ISO> map (ntrim hff) [0..31]
[0,0,1,0,2,1,1,0,1,2,3,1,2,1,1,0,4,1,5,2,6,3,3,1,1,2,3,1,2,1,1,0]
\end{codex}
This can be seen as a hash key providing a lossy approximation of the tree
structure with leaves removed. Note that this operation is not total on HFS
but it is total on HFF,HFP,HFM,HFPM.

\section{Hereditary base-k representations and Goodstein sequences}

\begin{df}
Hereditary base-k representation of a number x is obtained by representing x as
a sum of powers of k followed by expression of each of the exponents with
nonzero coeficients as a sum of powers of k, recursively.
\end{df}
First we express a single step of this transformation to/from a polynomial in
base {\tt k} as a pair of bijections:
\begin{code}
nat2kpoly k n = filter (\p->0/=fst p) ps where 
  ns=to_base k n
  l=genericLength ns
  is=[0..l-1]
  ps=zip ns is 

kpoly2nat k ps = sum (map (\(d,e)->d*k^e) ps)
\end{code}
The transformation works as follows:
\begin{codex}
*ISO> nat2kpoly 3 2009
[(2,0),(1,2),(2,3),(2,5),(2,6)]
*ISO> kpoly2nat 3 it
2009
\end{codex}
The recursive process generates a tree, with coeficients of each
expansion labeling nodes. We can host this expansion in the data type {\tt HB}:
\begin{code}
data HB a = HB a [HB a]  deriving (Eq,Ord,Show,Read)
\end{code}
We will define, for each base k, two isomorphisms {\tt nat2hb k} and {\tt
hb2nat k} between natural numbers and polynomials:
\begin{code}
nat2hb :: N->N->[HB N]

nat2hb _k 0 = [] 
nat2hb k n | n<k = [HB n []]
nat2hb k n = gs where 
  ps'=nat2kpoly k n
  gs=map (nat2hb1 k) ps'
  nat2hb1 k (d,e) = HB d (nat2hb k e)
 
hb2nat :: N -> [HB N] -> N
 
hb2nat k [] = 0
hb2nat k ts = kpoly2nat k ps where
  ps=map (hb2nat1 k) ts
  hb2nat1 k (HB d ts) = (d,hb2nat k ts)
\end{code}
We can now define a family of {\tt Encoders}, one for each base {\tt k}, as
follows:
\begin{code}
hb :: N->Encoder [HB N]
hb k = compose (Iso (hb2nat k) (nat2hb k)) nat
\end{code}
The other new concept here is working with a parametric family of Encoders. With
a small adaptation, the syntax of the {\tt as} combinator scales up naturally:
\begin{codex}
*ISO> as  (hb 3) nat 42
[HB 2 [HB 1 []],HB 1 [HB 2 []],HB 1 [HB 1 [HB 1 []]]]
*ISO> as nat (hb 3) it
42
\end{codex}
Fig. \ref{isohb} shows a graph representation of the expansion of {\tt 2009}
in hereditary base {\tt 3}, the nodes labeled with the exponents and the
eges labeled with the coefiecients in range [0..2].
\FIG{isohb}{Expansion of 2009 in hereditary base 3}{0.60}{isohb.pdf}

Note that the base does not occur as such in the hereditary base-k
expression obtained with the Encoder {\tt hb}. This property can be used to
obtain {\tt Goodstein sequences} by {\em bumping the base} from {\tt k} to
{\tt k+1} i.e. interpreting a {\tt (hb k)} expression as a {\tt (hb (k+1))}
expression and then subtracting 1 from the result, i.e:
\begin{code}
goodsteinStep k n = (hb2nat (k+1) (nat2hb k n)) - 1

goodsteinSeq _ 0 = []
goodsteinSeq k n = n:(goodsteinSeq (k+1) m) where 
  m=goodsteinStep k n
  
goodstein m = goodsteinSeq 2 m
\end{code}
Fig. \ref{isohb1} shows a graph representation of the expansion of {\tt
139793}, obtained by applying the function {\tt goodsteinStep 3 2009}, in
hereditary base {\tt 4=3+1}. As previously, the nodes are labeled with the
exponents and the edges are labeled with the coefiecients, this time in range
[0..3].
\FIG{isohb1}{Expansion of 139793 in hereditary base 4}{0.60}{isohb1.pdf}
As the following examples indicate, Goodstein sequences might grow fast
for most values, until eventually reverse course end descend to 0.
\begin{codex}
*ISO> goodsteinStep 3 2009
139793
*ISO> goodsteinStep 4 it
19693775
*ISO> goodstein 3
[3,3,3,2,1]
*ISO> take 12 (goodstein 4)
[4,26,41,60,83,109,139,173,211,253,299,348]
*ISO> take 2 (goodstein 19)
[19,7625597484990]
\end{codex}
Goodstein's Theorem (only provable in second order arithmetics) states that this
sequence always terminates at 0. The remarkable thing about it is that it is 
an example of an undecidable statement in first order Peano arithmetics, that in
contrast to G\"{o}del's therorem, involves only ``conventional'' numerical relations.
Comparing Fig. \ref{isohb} and Fig. \ref{isohb1} helps with the intuition for
why the sequence eventually starts descending: the shape of the graph
remains the same despite of the increase of the exponents - so in the resulting
{\em Hydra game} the predecessor function ``cutting one head of the Hydra'' will
eventually win over the bumping up of the base ``growing new heads''.

\section{Generalizing Systems of Numeration}

We have seen that factoradic numbers have helped ranking permutations and that
Goodstein numbers have been obtained by applying a given construction
principle recursively over exponents.  

We will now introduce a
generalization of numeration systems parameterized 
by a function $f$ and a base $b$.

Converting $n$ to base $(f,b)$ starts by generating a sequence of
iterates of function $f$ starting with $b$, up to $n$, in decreasing order:
\begin{code}
iterates f b n = reverse (takeWhile (<=n) (iterate f b))
\end{code}
For instace if $f$ is the squaring operation and the base is $2$ we obtain:
\begin{codex}
*ISO> iterates (^2) 2 100000
[65536,256,16,4,2]
\end{codex}
Such a sequence will provide the sequence of divisors to be used as in the
conventional conversion algorithm:
\begin{code}
to_fbase f b n | b>0 = reverse (spread (iterates f b n) n) -- where
spread [] n=[n]
spread (d:ds) n = q:spread ds r where (q,r)=quotRem n d
\end{code}
To convert back, one computes the value of the resulting representation with
digits seen as multipliers:
\begin{code}    
from_fbase f b ns | b>0 = sum (zipWith (*) ns (1:iterate f b))
\end{code}
The two sides of the conversion work as follows:
\begin{codex}
*ISO> to_fbase (^2) 2 2009
[1,0,2,13,7]
*ISO> from_fbase (^2) 2 it
2009
\end{codex}
as $2009=1+2*4+13*16+7*256$.
We can now instantianate the conversion mechanism by fixing $f$ or $b$ or
both. An interesting instance is:
\begin{code}
to_sqbase b n | b>1 = to_fbase (^2) b n
from_sqbase b ns | b>1 = from_fbase (^2) b ns
\end{code}
that we will call ``square-base'' representation.
The expansion of $2009$, based on the equality $2009=5+4*6+19*6^2+1*{(6^2)}^2$
gives:
\begin{codex}
*ISO> to_sqbase 6 2009
[5,4,19,1]
*ISO> from_sqbase 6 it
2009
\end{codex}
The same in ``square-base'' 2:
\begin{codex}
*ISO> to_sqbase 2 2009
[1,0,2,13,7]
*ISO> from_sqbase 2 it
2009
\end{codex}
%to_b1 b n = to_fbase (\x->pair (b,x)) b n
%pairSeq f b n = iterate (\x->f (b,x)) n
Like with hereditary base-k, one can recurse over the expansions.
Fig. \ref{isosqbase} shows a graph obtained as a result of this process.
\FIG{isosqbase}
{Recursive expansion of 2009 in ``square-base'' 2}
{0.60}{isosqbase.pdf}

\section{Encoding Strings}
As strings can be seen just as a notational equivalent
of lists of natural numbers 
we obtain an Encoder immediately as: 
\begin{code}
string :: Encoder String
string = compose (Iso string2nat nat2string) nat

base = 1+ord '~'- ord ' '
chr2ord c | c>=' ' && c<='~' = ord c - ord ' '

ord2chr o | o>=0 && o<base = chr (ord ' '+o)

string2nat cs = from_bbase 
  (fromIntegral base) 
  (map (fromIntegral . chr2ord) cs)

nat2string n = map 
  (ord2chr . fromIntegral) 
  (to_bbase (fromIntegral base) n)
\end{code}
We have assumed here ASCII encoding - but changing {\tt string\_base} to
appropriate values can accommodate a richer character set.
\begin{codex}
*ISO> as set string "hello"
[0,1,4,5,6,8,9,10,12,16,18,19,20,22,27,31,32]
*ISO> as string set it
"hello"
\end{codex}
Note also that we are using {\tt to\_bbase} and {\tt from\_bbase} that proovide
bijective base-k encodings (see \ref{bijnat}) and therefore ensure a unique
representation of our strings as numbers in a given {\tt base}.

\section{Pairing/Unpairing} \label{pairings}

A {\em pairing} function is an isomorphism $f:\mathbb{N} \times \mathbb{N}
\rightarrow \mathbb{N}$. Its inverse is called {\em unpairing}.

\subsection{The Pepis-Kalmar-Robinson Pairing Function} \label{pepispair}
A classic pairing function is {\bf pepis\_J}, together with its left and right
unpairing companions {\bf pepis\_K} and {\bf pepis\_L} that have been used, by Pepis, Kalmar and Robinson 
together with Cantor's functions, in some fundamental work on recursion theory, 
decidability and Hilbert's Tenth Problem in
\cite{pepis,kalmar1,kalmar2,kalmar3,robinson50,robinson55,robinson68a,robinsons68b,robinson67}.
The function {\bf pepis\_J}
combines two numbers reversibly by multiplying
a power of 2 derived from the first and
an odd number derived from the second:
\begin{equation}
f(x,y)=2^x(2y+1)-1
\end{equation}
Its Haskell implementation, together with its inverse is:
\begin{code}
pepis_J x y  = pred ((2^x)*(succ (2*y)))

pepis_K n = two_s (succ n)

pepis_L n = (pred (no_two_s (succ n))) `div` 2
 
two_s n | even n = succ (two_s (n `div` 2))
two_s _ = 0

no_two_s n = n `div` (2^(two_s n))
\end{code}
% a<b => j a b < j b a
This pairing function (slower in the second argument) works as follows:
\begin{codex}
pepis_J 1 10
  41
pepis_J 10 1
  3071
[pepis_J i j|i<-[0..3],j<-[0..3]]
  [0,2,4,6,1,5,9,13,3,11,19,27,7,23,39,55]
\end{codex}
As Haskell provides a built-in ordered pair, it is convenient to regroup the
functions {\tt J, K, L} (given in Julia Robinson's original notation) as
mappings to/from built-in ordered pairs:
\begin{code}
pepis_pair (x,y) = pepis_J x y
pepis_unpair n = (pepis_K n,pepis_L n)
\end{code}
Observing that the number of {\tt 0}s in front of the
representation of a natural number {\tt n} as a sequence 
equals {\tt pepis\_K n}, an alternative
implementation could be:
\begin{code}
pepis_pair' (x,y) = (fun2nat (x:(nat2fun y)))-1

pepis_unpair' n = (x,fun2nat ns) where 
  (x:ns)=nat2fun (n+1) 
\end{code} 
Note also that {\tt pepis\_unpair} is ``asymmetrical'' in the sense that its
first component grows much slower than the second, when applied to {\tt [0..]}.
Sometimes it is more useful to have the opposite behavior
\begin{code}
rpepis_pair (x,y) = pepis_pair (y,x)
rpepis_unpair n = (y,x) where (x,y)=pepis_unpair n
\end{code}
After defining
\begin{code}
type N2 = (N,N)
\end{code}
we obtain the encoder
\begin{code}
pnat2 :: Encoder N2
pnat2 = compose (Iso pepis_pair pepis_unpair) nat

rpnat2 :: Encoder N2
rpnat2 = compose (Iso rpepis_pair rpepis_unpair) nat
\end{code}

\subsection{Deriving pairing/unpairing operations from hereditarily finite
function trees}
One can derive a pairing/unpairing function by combining/decomposing
the tree representation provided by the Encoder {\tt hff} as follows:
\begin{code}
hpair (x,y) = z-1 where 
  hx=as hff nat x
  H hs =as hff nat y
  hz= H (hx:hs)
  z=as nat hff hz
    
hunpair z = (x,y) where
  H (hx:hs) = as hff nat (z+1)
  x=as nat hff hx
  y=as nat hff (H hs)
\end{code}
Interestingly enough, {\tt hpair/hunpair} turns out to be identical to
{\tt pepis\_pair/pepis\_unpair}, as well. One can notice that this is the case
because it applies the same transformation as {\tt pepis\_pair'/pepis\_unpair'}.

\subsection{A Bitwise Pairing/Unpairing Function}
We will now introduce an unusually simple pairing function 
(also mentioned in \cite{pigeon}, p.142).

The function {\tt bitpair} works by splitting a 
number's big endian bitstring
representation into odd and even bits, 
while its inverse {\tt bitunpair}
blends the odd and even bits back together.

\begin{code}
bitpair ::  N2 -> N
bitpair (i,j) = 
  set2nat ((evens i) ++ (odds j)) where
    evens x = map (2*) (nat2set x)
    odds y = map succ (evens y)

bitunpair :: N->N2  
bitunpair n = (f xs,f ys) where 
  (xs,ys) = partition even (nat2set n)
  f = set2nat . (map (`div` 2))
\end{code}

The transformation of the bitlists
is shown in the following example 
with bitstrings aligned:
\begin{codex}
*ISO> bitunpair 2008
  (60,26)

-- 2008:[0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1]
--   60:[0,    0,    1,    1,    1,    1]
--   26:[   0,    1,    0,    1,    1   ]
\end{codex}

We can derive the following Encoder:
\begin{code}
nat2 :: Encoder N2
nat2 = compose (Iso bitpair bitunpair) nat
\end{code}
working as follows:
\begin{codex}
*ISO> as nat2 nat 2008
(60,26)
*ISO> as nat nat2 (60,26)
2008
\end{codex}

In a way similar to hereditarily finite trees generated by unfoldings one can
apply strictly decreasing\footnote{except for 0 and 1, typically} unpairing
functions recursively. Figures \ref{iso2008p} and \ref{iso2008b} show the
directed graphs describing recursive application of {\tt bitunpair} and {\tt
pepis\_unpair}.

\FIG{iso2008p}{Graph obtained by recursive application of {\tt pepis\_unpair}
for 2008}{0.40}{iso2008p.pdf}

\FIG{iso2008b}{Graph obtained by recursive application of {\tt bitunpair}
for 2008}{0.40}{iso2008b.pdf}

Given that unpairing functions are bijections from $\mathbb{N}$ to $\mathbb{N} \times \mathbb{N}$
they will progressively cover all points having natural number coordinates in
their range in the plane. Figures \ref{isounpair1}, \ref{isounpair2} 
show the curves generated by {\tt bitunpair} and {\tt pepis\_unpair}.

\FIG{isounpair1}
{2D curve connecting values of {\tt bitunpair n} for $n \in [0..2^{10}-1]$}
{0.40}{isounpair1.pdf}

\FIG{isounpair2}
{2D curve connecting values of {\tt pepis\_unpair n} for $n \in [0..2^{10}-1]$}
{0.40}{isounpair2.pdf}

Fig. \ref{f6} shows the action of the pairing function {\tt bitpair}
on its two arguments arguments in [0..63].

\FIG{f6}{Values of bitpair x y with x,y in [0..63]}{0.40}{isof6.pdf}

\subsection{Encoding Unordered Pairs}
To derive an encoding of unordered pairs, i.e. 2 element sets, one
can combine pairing/unpairing with conversion between sequences and
sets:
\begin{code}
pair2unord_pair (x,y) = fun2set [x,y]
unord_pair2pair [a,b] = (x,y) where 
  [x,y]=set2fun [a,b]   

unord_unpair = pair2unord_pair . bitunpair
unord_pair = bitpair . unord_pair2pair
\end{code}
We can derive the following equivalent Encoders:
\begin{code}
set2 :: Encoder [N]
set2 = compose (Iso unord_pair2pair pair2unord_pair) nat2
\end{code}
that goes through {\tt nat2}, working as follows:
\begin{codex}
*ISO> as set2 nat 2008
[60,87]
*ISO> as nat set2 it
2008
\end{codex}
and
\begin{code}
set2' :: Encoder [N]
set2' = compose (Iso unord_pair unord_unpair) nat
\end{code}
that goes through {\tt nat}, working as follows:
\begin{codex}
*ISO> as set2' nat 2008
[60,87]
*ISO> as nat set2' [60,87]
2008
*ISO> as nat set2' [87,60]
2008
\end{codex}

\subsection{Encodings Multiset Pairs}
To derive an encoding of 2 element multisets, one
can combine pairing/unpairing with conversion between sequences and
multisets:
\begin{code}
pair2mset_pair (x,y) = (a,b) where [a,b]=fun2mset [x,y]
mset_unpair2pair (a,b) = (x,y) where [x,y]=mset2fun [a,b]

mset_unpair = pair2mset_pair . bitunpair
mset_pair = bitpair . mset_unpair2pair
\end{code}
We can derive the following Encoder:
\begin{code}
mset2 :: Encoder N2
mset2 = compose (Iso mset_unpair2pair pair2mset_pair) nat2
\end{code}
working as follows:
\begin{codex}
*ISO> as mset2 nat 2008
(60,86)
*ISO> as nat mset2 it
2008
\end{codex}

Figure \ref{isounpair3} shows the curve generated by {\tt mset\_unpair}
covering the lattice of points in its range.

\FIG{isounpair3}
{2D curve connecting values of {\tt mset\_unpair n} for $n \in [0..2^{10}-1]$}
{0.40}{isounpair3.pdf}

\subsection{Extending Pairing/Unpairing to Signed Integers}
Given the bijection from $nat$ to $z$ one can easily extend pairing/unpairing
operations to signed integers. We obtain the Encoder:
\begin{code}
type Z2 = (Z,Z)

z2 :: Encoder Z2
z2 = compose (Iso zpair zunpair) nat

zpair (x,y) = (nat2z . bitpair) (z2nat x,z2nat y)
zunpair z = (nat2z n,nat2z m) where (n,m)= (bitunpair . z2nat) z
\end{code}
working as follows:
\begin{codex}
*ISO> map zunpair [-5..5]
[(-1,1),(-2,-1),(-2,0),(-1,-1),(-1,0),(0,0),(0,-1),(1,0),(1,-1),(0,1),(0,-2)]
*ISO> map zpair it
[-5,-4,-3,-2,-1,0,1,2,3,4,5]

*ISO> as z2 z (-2008)
(63,-26)
*ISO> as z z2 it
-2008
\end{codex}
Figure \ref{isozunpair} shows the curve covering the lattice of integer
coordinates generated by the function {\tt zunpair}.

\FIG{isozunpair}
{Curve generated by unpairing function on signed integers}
{0.40}{isozunpair.pdf}

The same construction can be extended to multiset pairing functions:
\begin{code}
mz2 :: Encoder Z2
mz2 = compose (Iso mzpair mzunpair) nat

mzpair (x,y) = (nat2z . mset_pair) (z2nat x,z2nat y)
mzunpair z = (nat2z n,nat2z m) where (n,m)= (mset_unpair . z2nat) z
\end{code}
working as follows:
\begin{codex}
*ISO> as mz2 z (-42)
(1,-8)
*ISO> as z mz2 it
-42
\end{codex}

\subsection{Gauss Integers and Pairing Functions}
Visualizing complex variable functions requires 4 dimensions even for
1-variable functions. This is usually handled by associating a color/hue value
to the {\em phase} while representing the {\em modulus} along the z-axis.
However, for 2-argument complex functions as simple as the sum, difference and
the product 6 dimensions would be needed.
Let us start shapeshifting operations on Gauss Integers
(pairs of integers with a real and imaginary part) in combination with a
mapping to ordinary integers using the  (commutative!) multiset
pairing/unpairing isomorphism provided by the Encoder {\tt mz2}:
\begin{code}
gauss_sum (ab,cd) = mzpair (a+b,c+d) where
  (a,b)=mzunpair ab
  (c,d)=mzunpair cd

gauss_dif (ab,cd) = mzpair (a-b,c-d) where
  (a,b)=mzunpair ab
  (c,d)=mzunpair cd
  
gauss_prod (ab,cd) = mzpair (a*c-b*d,b*c+a*d) where
  (a,b)=mzunpair ab
  (c,d)=mzunpair cd
\end{code}
Clearly one can now fit these operations in 3-dimensions as shown
in Figures \ref{isogsum}, \ref{isogdif}, \ref{isogprod} visualizing
sums, differences and products of Gauss Integers obtained by
unpairing integers in $[-2^4..2^4-1]$.

\FIG{isogsum}
{Sums of Gauss Integers visualized with Pairing functions}
{0.40}{isogsum.pdf}

\FIG{isogdif}
{Differences of Gauss Integers visualized with Pairing functions}
{0.40}{isogdif.pdf}

\FIG{isogprod}
{Products of Gauss Integers visualized with Pairing functions}
{0.40}{isogprod.pdf}

\subsection{Some algebraic properties of pairing functions}
The following propositions state some simple
algebraic identities between pairing operations acting on ordered, unordered and multiset pairs.

\begin{prop}
Given the function definitions:
\begin{code}
bitlift x = bitpair (x,0)
bitlift' = (from_base 4) . (to_base 2)

bitclip = fst . bitunpair
bitclip' = (from_base 2) . (map (`div` 2)) . (to_base 4) . (*2)

bitpair' (x,y) = (bitpair (x,0))   +   (bitpair(0,y))
xbitpair (x,y) = (bitpair (x,0)) `xor` (bitpair (0,y))
obitpair (x,y) = (bitpair (x,0))  .|.  (bitpair (0,y))

pair_product (x,y) = a+b where
  x'=bitpair (x,0)
  y'=bitpair (0,y)
  ab=x'*y'
  (a,b)=bitunpair ab
\end{code}
the following identities hold:
\begin{equation}
bitlift \equiv bitlift'
\end{equation}
\begin{equation}
bitclip \equiv bitclip'
\end{equation}
\begin{equation}
bitclip \circ bitlift \equiv id 
\end{equation}
\begin{equation}
bitpair (0,n) \equiv 2*bitpair(n,0)
\end{equation}
\begin{equation}
bitpair (0,n) \equiv 2*(bitlift~n)
\end{equation}
\begin{equation}
bitpair (n,n) \equiv 3*(bitlift~n)
\end{equation}
\begin{equation}  \label{bitpow}
bitpair (2^n,0) \equiv  ({2^n})^2
\end{equation}
\begin{equation}  \label{biteq}
bitpair (2^{2^n}+1,0) \equiv 2^{2^{n+1}}+1
\end{equation}
\begin{equation}
bitpair' \equiv bitpair \equiv xbitpair \equiv obitpair
\end{equation}
\begin{equation}
bitpair (x,y) \equiv (bitlift~x)+2*(bitlift~y) 
\end{equation}
\begin{equation}
pair\_product \equiv *
\end{equation}
\end{prop}

\begin{prop}
Given the function definitions
\begin{code}
bitpair'' (x,y) = mset_pair (min x y,x+y) 

bitpair''' (x,y) = unord_pair [min x y,x+y+1]

mset_pair' (a,b) = bitpair (min a b, (max a b) - (min a b)) 

mset_pair'' (a,b) = unord_pair [min a b, (max a b)+1]

unord_pair' [a,b] = bitpair (min a b, (max a b) - (min a b) -1) 

unord_pair'' [a,b] = mset_pair (min a b, (max a b)-1)
\end{code}
the following identities hold:
\begin{equation}
bitpair \equiv bitpair'' \equiv bitpair '''
\end{equation}
\begin{equation} \label{mseteq}
mset\_pair \equiv mset\_pair' \equiv mset\_pair ''
\end{equation}
\begin{equation}
unord\_pair \equiv unord\_pair' \equiv unord\_pair ''
\end{equation}
\end{prop}

\section{Cons-Lists with Pairing/Unpairing}

The simplest application of pairing/unpairing operations is encoding
of cons-lists of natural numbers, defined as the data type:
\begin{code}
data CList = Atom N | Cons CList CList 
  deriving (Eq,Ord,Show,Read)
\end{code}

First, to provide an infinite supply of atoms, we encode them
as even numbers:
\begin{code}
to_atom n = 2*n
from_atom a | is_atom a = a `div` 2
is_atom n = even n  && n>=0
\end{code}
Next, as we want atoms and cons cells disjoint, we will encode the later as
odd numbers:
\begin{code}
is_cons n = odd n && n>0
decons z | is_cons z = pepis_unpair ((z-1) `div` 2)
conscell x y = 2*(pepis_pair (x,y))+1
\end{code}
We can deconstruct a natural number by recursing over
applications of the unpairing-based {\tt decons} combinator:
\begin{code}
nat2cons n | is_atom n = Atom (from_atom n)
nat2cons n | is_cons n = 
  Cons (nat2cons hd) 
       (nat2cons tl) where
    (hd,tl) = decons n     
\end{code}
We can reverse this process by recursing with the {\tt conscell} combinator
on the CList data type:
\begin{code}
cons2nat (Atom a) =  to_atom a
cons2nat (Cons h t) = conscell (cons2nat h) (cons2nat t)
\end{code}
The following example shows both transformations as inverses.
\begin{codex}
*ISO> cons2nat (Cons (Atom 0) (Cons (Atom 1) (Cons (Atom 2) (Atom 3))))
26589
*ISO> nat2cons 26589
Cons (Atom 0) (Cons (Atom 1) (Cons (Atom 2) (Atom 3)))
\end{codex}
We obtain the Encoder:
\begin{code}
clist :: Encoder CList
clist = compose (Iso cons2nat nat2cons) nat
\end{code}
The Encoder works as follows:
\begin{codex}
*ISO> as clist nat 101
Cons (Atom 0) (Cons (Atom 0) (Atom 3))
\end{codex}
and can be used to generate random LISP-like data and code skeletons
from natural numbers.


\section{Designing an efficient bijective G\"odel numbering scheme}
With all the building blocks in place, we can now proceed with the design of
a compact bijective G\"odel numbering algorithm.

\subsection{Term Algebras}

Term algebras are {\em free magmas} induced by a a set of variables and a
set of function symbols of various arities (0 included), called {\tt signature}, that
are closed under the operation of inserting terms as an arguments of function
symbols. In various logic formalisms a term algebra is called a Herbrand
Universe.

We will represent function arguments as
lists and assume their arity is implicitly given as the length of the
the lists:

\begin{code}
data Term var const = 
   Var var | 
   Fun const [Term var const] 
   deriving (Eq,Ord,Show,Read)
\end{code}


\subsection{Encoding in a term algebra with function symbols represented as
natural numbers}

Let's first instantiate the term algebra {\tt Term var const} as:
\begin{code}
type NTerm = Term N N
\end{code}

We will also instantiate our representation of finite sequences as:
\begin{code}
nats = fun'
\end{code}

First, we will have to separate encodings of variable and function
symbols. We can map them, respectively, to even and odd numbers.
To deal with function arguments, we will use the bijective encoding of sequences
recursively.

\begin{code}
nterm2code :: Term N N -> N

nterm2code (Var i) = 2*i
nterm2code (Fun cName args) = code where
  cs=map nterm2code args
  fc=as nat nats (cName:cs)
  code = 2*fc-1
\end{code}
The inverse is computed as follows:
\begin{code}
code2nterm :: N -> Term N N

code2nterm n | even n = Var (n `div` 2) 
code2nterm n = Fun cName args where
  k = (n+1) `div` 2
  cName:cs = as nats nat k
  args = map code2nterm cs
\end{code}

\begin{codex}
*ISO> as nterm nat 55
Fun 1 [Fun 0 [],Var 0]
*ISO> as nat nterm it
55
\end{codex}
We can encapsulate our transformers as the Encoder:
\begin{code}
nterm :: Encoder NTerm
nterm = compose (Iso nterm2code code2nterm) nat
\end{code}

We shall extend this encoding for the case of more realistic term
algebras where function symbols are encoded as strings.

\subsection{Encoding in a term algebra with function symbols represented as
strings}

We can now instantiate our term algebra to have function symbols range over
strings.
\begin{code}
type STerm = Term N String
\end{code}
The only change from the {\tt nterm} encoder is applying encoding/decoding to
strings.
\begin{code}
sterm2code :: Term N String -> N

sterm2code (Var i) = 2*i
sterm2code (Fun name args) = code where
  cName=as nat string name
  cs=map sterm2code args
  fc=as nat nats (cName:cs)
  code=2*fc-1
\end{code}
The inverse is computed as follows:
\begin{code}
code2sterm :: N -> Term N String

code2sterm n | even n = Var (n `div` 2) 
code2sterm n = Fun name args where
  k = (n+1) `div` 2
  cName:cs = as nats nat k
  name = as string nat cName
  args = map code2sterm cs
\end{code}

We can encapsulate our transformers as the Encoder:
\begin{code}
sterm :: Encoder STerm
sterm = compose (Iso sterm2code code2sterm) nat
\end{code}

\begin{codex}
*ISO> as sterm nat 1234567
Fun "%" [Var 28,Var 7]
*ISO> as nat sterm it
1234567
*ISO> as nat sterm (Fun "forall" [Var 0, Fun "f" [Var 0]])
2659186161101533958880112589475979847
*ISO> as sterm nat it
Fun "forall" [Var 0,Fun "f" [Var 0]]
\end{codex}

\subsection{Mapping terms to arbitrary bitstrings}

Term algebras are free magmas generated through fairly complex
substitution operations. Their underlying data representations involve ordered
trees. Can we design a bijective mapping to, arguably, the simplest possible free
magma - the set of strings on $\{0,1\}$?  The answer is affirmative, provided
that we use a mapping from {\em arbitrary} bitstrings to natural numbers, as
provided by the Encoder {\tt bits}.

Using the {\tt as} combinator we obtain:

\begin{code}
nterm2bits = as bits nterm
bits2nterm = as nterm bits

sterm2bits = as bits sterm
bits2sterm = as sterm bits
\end{code}

\begin{codex}
*ISO> as nterm bits 
  [0,0,0,1,0,1,0,0,1,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,
   0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
Fun 0 [Fun 1 [Var 0,Fun 1 [Var 0]],Var 1]
*ISO> as bits nterm 
    (Fun 0 [Fun 1 [Var 0,Fun 1 [Var 0]],Var 1])
[0,0,0,1,0,1,0,0,1,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1,
 0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
\end{codex}

The following is a consequence of the fact that each of the encoding steps are
linear in the bitsize of their input and run in linear time and preserve
syntactic validity by structural induction.
\begin{prop}
The G\"odel numbering algorithms implemented by the encoders {\tt nterm} and
{\tt sterm} are bijective
and work in linear time and space linear in the bitsize of their input.
Moreover, all natural numbers decode to syntactically valid terms.
\end{prop}

\subsection{Deriving representations of finite sequences from one-solution
Diophantic equations} \label{dio}
Let's first observe that
\begin{prop}
$\forall z \in \mathbb{N}-\{0\}$ the diophantic equation
\begin{equation}
2^x(2y+1)=z
\end{equation}
has exactly one solution $x,y \in \mathbb{N}$.
\end{prop}
This follows immediately from the unicity of the decomposition of a natural
number as a multiset of prime factors. 

This equation justifies the fact that the {\tt cons, hd, tl} functions
can be used to uncover a list structure
inside natural numbers. The mechanism can be generalized to obtain a family of
finite sequence encoders by choosing an arbitrary base {\tt b} instead of {\tt
2}. Care should be taken in this case to {\em rebase} i.e. switch from/to base
{\tt b-1} to ensure that we obtain a bijection. 
Such rebasing operations are similar to those used in generating the sequences
used in Goodstein's theorem \cite{goodstein}.
First we implement the head and tail operations {\tt xhd} and {\tt xtl} as
follows:
\begin{code}
xhd :: N->N->N
xhd b n | b>1 && n>0 = 
  if n `mod` b > 0 then 0 else 1+xhd b (n `div` b)

xtl :: N->N->N
xtl b n = y-1 where
  y'= n `div` b^(xhd b n)
  y=rebase b (b-1) y'

rebase fromBase toBase n =  toBase*q + r where
  (q,r)=n `quotRem` fromBase
    
\end{code}
The {\tt xcons} operation aggregates back the head and tail:
\begin{code}
xcons :: N->N->N->N
xcons b x y | b>1 = (b^x)*(y'+1) where
  y'=rebase (b-1) b y
\end{code}
The following examples show the operations for base {\tt 3}:
\begin{codex}
*ISO> xcons 3 10 20
1830519
*ISO> xhd 3 1830519
10
*ISO> xtl 3 1830519
20
\end{codex}
We can extend the mechanism to derive {\em pairing/unpairing} functions as
follows:
\begin{code}
xunpair b n = (xhd b n',xtl b n') where n'=n+1

xpair b (x,y) = (xcons b x y)-1
\end{code}
One can see that we obtain a family of bijections  
$f_b: \mathbb{N} \times \mathbb{N} \rightarrow \mathbb{N}$ for every
base $b$.
\begin{codex}
*ISO> map (xunpair 3) [0..7]
[(0,0),(0,1),(1,0),(0,2),(0,3),(1,1),(0,4),(0,5)]
*ISO> map (xpair 3) it
[0,1,2,3,4,5,6,7]
\end{codex}
For each base {\tt b>1} one obtains a pair of mappings:
\begin{code}
xsplit _ 0 = []
xsplit b x = xhd b x : xsplit b (xtl b x)
 
xfuse _ [] = 0
xfuse b (x:xs) = xcons b x (xfuse b xs)
\end{code}
working as follows:
\begin{codex}
*ISO> xsplit 3 2009
[0,0,0,3,0,2]
*ISO> xfuse 3 it
2009
\end{codex}
For each pair $l,k \in \mathbb{N}$ one can generate a family of bijections
$\mathbb{N}\rightarrow \mathbb{N}$ by combining a {\tt split} and a {\tt fuse}
\begin{code}
xbij k l n = xfuse l (xsplit k n) 
\end{code}
working as follows:
\begin{codex}
*Main> map (xbij 2 3) [0..31]
[0,1,3,2,9,5,6,4,27,14,15,8,18,10,12,7,81,41,42,
 22,45,23,24,13,54,28,30,16,36,19,21,11]
*Main> map (xbij 3 2) [0..31]
[0,1,3,2,7,5,6,15,11,4,13,31,14,23,9,10,27,63,
 12,29,47,30,19,21,22,55,127,8,25,59,26,95]
\end{codex}
It is easy th see that the following holds:
\begin{prop}
\begin{equation}
(xbij~k~l) \circ (xbij~l~k) \equiv id
\end{equation}
\end{prop}
This might have applications to cryptography, provided that a
method is devised to generate ``interesting'' pairs k,l defining the encoding.

More complex encodings can be obtained with:
\begin{code}
ybij m | m>3 = (xbij 3 m) . (xbij m 2)
\end{code}
\begin{codex}
*ISO> map (ybij 4) [0..31]
[0,1,4,5,2,24,6,25,8,7,80,13,22,33,230,64,3,23,34,
 356,44,65,16,70,11,107,362,26,115,196,17,99]
\end{codex}

\section{Revisiting Multiset Encodings}
We will now use pairing/unpairing functions, in combination with mappings to
sequences and sets to design an efficient encoding of multisets.

The function {\tt fmset2nat} starts by grouping the elements of a multiset. The
lengths of the groups (decremented by 1), as well as an element of each are then
collected in 2 lists. Then the second list is morphed
from a set to a sequence, as this provides a more compact representation without
changing the length of the list. The first list, seen as a sequence is then
paired element by element with the second list. 
Finally, the resulting numbers, seen as a sequence, are then fused together. 
\begin{code}
fmset2nat pairingf ms = m where  
  mss= group (sort ms) 
  xs=map (pred . genericLength) mss
  zs=map head mss
  ys=set2fun zs
  ps=zip xs ys
  ns=map pairingf ps 
  m=fun2nat ns
\end{code}
The function {\tt fnat2mset} reverses the process step by step:
\begin{code}
fnat2mset unpairingf m = rs where
   ns=nat2fun m
   ps=map unpairingf ns
   (xs,ys)=unzip ps
   xs'=map succ xs
   zs=fun2set ys
   f k x = genericTake k (repeat x) 
   rs = concat (zipWith f xs' zs)
\end{code}
After instantiating these generic functions to interesting pairing/unpairing
functions
\begin{code}
bmset2nat = fmset2nat bitpair
nat2bmset = fnat2mset bitunpair

bmset2nat' = fmset2nat pepis_pair
nat2bmset' = fnat2mset pepis_unpair
\end{code}
We obtain the Encoders:
\begin{code}
bmset :: Encoder [N]
bmset = compose (Iso bmset2nat nat2bmset) nat

bmset' :: Encoder [N]
bmset' = compose (Iso bmset2nat' nat2bmset') nat
\end{code}
working as follows:
\begin{codex}
ISO> as bmset nat 2008
[1,1,2,3,3,4,5,6,7]
*ISO> as nat bmset it
2008
*ISO> map (as bmset nat) [0..7]
[[],[0],[0,0],[0,1],[1],[0,1,1],[0,0,1],[0,1,2]]
*ISO> as bmset' nat 2008
[0,0,0,1,2,2,3,4,5,6]
\end{codex}
Note that, in contrast to the intractable prime number based multiset encoding
{\tt pmset}, this time we obtain an encoding, linear in the
bitsize of the natural numbers involved, as in the case of {\tt mset}.
Note also that the construction is generic in the sense that it works with any
pairing / unpairing function.
Like in the case of {\tt mset} and {\tt pmset} multiset encodings we can extend
these encodings to a hylomorphism {\tt hfbm}:
\begin{code}
nat_bmset = Iso nat2bmset bmset2nat

hfbm :: Encoder T
hfbm = compose (hylo nat_bmset) nat

nat_bmset' = Iso nat2bmset' bmset2nat'

hfbm' :: Encoder T
hfbm' = compose (hylo nat_bmset') nat
\end{code}
working as follows:
\begin{codex}
*ISO> as hfbm nat 42
H [H [],H [],H [H []],H [H []],H [H [],H []],H [H [],H []]]
*ISO> as nat hfbm it
42
*ISO> as hfbm' nat 2008
H [H [],H [],H [],H [H []],H [H [],H []],
   H [H [],H []],H [H [],H [H []]],H [H [H []]],
   H [H [],H [H []],H [H []]],H [H [],H [],H [H []]]]
*ISO> as nat hfbm' it
2008   
\end{codex}

\section{Pairing Functions and Encodings of Binary Decision Diagrams}
\label{encbdd}
As a variation on the theme of pairing/unpairing functions, we will show in this
section that a Binary Decision Diagram ($BDD$) 
representing the same logic function as an $n$-variable $2^n$ bit truth
table can be obtained by applying {\tt bitunpair} recursively to {\tt tt}.
More precisely, we will show that applying this {\em unfolding} operation
results in a complete binary tree of depth $n$ representing
a $BDD$ that returns {\tt tt} when evaluated applying
its boolean operations.

The binary tree type {\tt BT} has the constants {\tt
B0} and {\tt B1} as leaves representing the boolean values $0$ and $1$.
Internal nodes (that will represent {\tt if-then-else} decision points), 
will be marked with the constructor {\tt D}. 
We will also add integers to represent logic
variables, ordered identically in each
branch, as first arguments of {\tt D}. 
The two other arguments will be subtrees 
that represent {\tt THEN} 
and {\tt ELSE} branches:
\begin{code}
data BT a = B0 | B1 | D a (BT a) (BT a) 
             deriving (Eq,Ord,Read,Show)
\end{code}

The constructor {\tt BDD} wraps together a 
tree of type {\tt BT} and the number of logic
variables occurring in it.
\begin{code}
data BDD a = BDD a (BT a) deriving (Eq,Ord,Read,Show)
\end{code}

\subsection{Unfolding natural numbers to binary trees}
The following functions apply {\tt bitunpair} recursively, 
on a Natural Number {\tt tt}, 
seen as an $n$-variable $2^n$ bit truth table, 
to build a complete binary tree of depth $n$, 
that we will represent using the {\tt BDD} data type. 
\begin{code}
unfold_bdd :: N2 -> BDD N
unfold_bdd (n,tt) = BDD n bt where 
  bt=if tt<max then split_with bitunpair n tt
     else error 
       ("unfold_bdd: last arg "++ (show tt)++
       " should be < " ++ (show max))
     where max = 2^2^n

split_with _ 0 0 =  B0
split_with _ 0 1 =  B1
split_with f n tt | n>0 = 
   D k (split_with f k tt1) 
       (split_with f k tt2) where
    k=pred n
    (tt1,tt2)=f tt
\end{code}
The following examples 
show results returned by {\tt unfold\_bdd} 
for the $2^{2^n}$ truth tables associated to $n$ variables,
for $n=2$:
\begin{codex}
 BDD 2 (D 1 (D 0 B0 B0) (D 0 B0 B0))
 BDD 2 (D 1 (D 0 B1 B0) (D 0 B0 B0))
 BDD 2 (D 1 (D 0 B0 B0) (D 0 B1 B0))
 ...
 BDD 2 (D 1 (D 0 B1 B1) (D 0 B1 B1))
\end{codex}
Note that no boolean operations have been performed so far
and that we still have to prove that such
trees actually represent BDDs associated to truth tables.

\subsection{Folding binary trees to natural numbers}
One can ``evaluate back'' the binary tree of data type BDD,
by using the pairing function {\tt bitpair}.  
The inverse of {\tt unfold\_bdd} is implemented as follows:
\begin{code}
fold_bdd :: BDD N -> N2
fold_bdd (BDD n bt) = 
  (n,fuse_with bitpair bt) where
    fuse_with rf B0 = 0
    fuse_with rf B1 = 1
    fuse_with rf (D _ l r) = 
      rf (fuse_with rf l,fuse_with rf r)
\end{code}
Note that this is a purely structural operation
and that integers in first argument position
of the constructor {\tt D} are actually ignored.

The two bijections work as follows:
\begin{codex}
*ISO>unfold_bdd (3,42)
  BDD 3 
    (D 2 
      (D 1 (D 0 B0 B0) 
           (D 0 B0 B0)) 
      (D 1 (D 0 B1 B1) 
           (D 0 B1 B0)))

*ISO>fold_bdd it
  42
\end{codex}

\subsection{Boolean Evaluation of BDDs}
Practical uses of BDDs involve reducing them by
sharing nodes and eliminating identical
branches \cite{bryant86graphbased}.
Note that in this case {\tt bdd2nat} 
might give a different result as it computes
different pairing operations. 
Fortunately,
we can try to fold the binary tree 
back to a natural number
by evaluating it as a boolean
function.

The function {\tt eval\_bdd} describes the $BDD$ evaluator:
\begin{code}
eval_bdd (BDD n bt) = eval_with_mask (bigone n) n bt
 
eval_with_mask m _ B0 = 0 
eval_with_mask m _ B1 = m
eval_with_mask m n (D x l r) = 
  ite_ (var_mn m n x) 
         (eval_with_mask m n l) 
         (eval_with_mask m n r)
         
var_mn mask n k = mask `div` (2^(2^(n-k-1))+1)
bigone nvars = 2^2^nvars - 1         
\end{code}

The {\em projection functions} {\tt var\_mn}
can be combined with the usual bitwise integer operators, 
to obtain new bitstring truth tables, 
encoding all possible value combinations of their arguments, 
as shown in \cite{knuth06draft}.
Note that the constant $0$ evaluates to $0$ while the constant $1$
is evaluated as $2^{2^n}-1$ by the function {\tt bigone}.

The function {\tt ite\_} used in {\tt eval\_with\_mask} 
implements the boolean function  {\tt if x then t else e}
using arbitrary length bitvector operations:
\begin{code}
ite_ x t e = ((t `xor` e).&.x) `xor` e
\end{code}

\noindent {\em 
As the following example shows, it turns out that
boolean evaluation {\tt eval\_bdd}
faithfully emulates {\tt fold\_bdd}!
}

\begin{codex}
*ISO> unfold_bdd (3,42)
BDD 3 (D 2 (D 1 (D 0 B0 B0) (D 0 B0 B0)) 
           (D 1 (D 0 B1 B1) (D 0 B1 B0)))
*ISO> eval_bdd it
42
\end{codex}

\subsection{The Equivalence} \label{equiv}
We will now state the surprising (and new!) result
that boolean evaluation and structural transformation with
repeated application of
{\em pairing}
produce the same result:

\begin{prop} \label{tt}
The complete binary tree of depth $n$, obtained by recursive 
applications of {\tt bitunpair} on a truth table $tt$
computes an (unreduced) BDD, that, when evaluated, 
returns the truth table, i.e.
\begin{equation}
fold\_bdd \circ unfold\_bdd \equiv id
\end{equation}

\begin{equation}
eval\_bdd \circ unfold\_bdd \equiv id
\end{equation}
\end{prop}
\begin{proof} The function {\tt unfold\_bdd} builds a
binary tree by splitting the bitstring $tt \in [0..2^n-1]$ up to depth $n$. 
Observe that this corresponds to the Shannon expansion \cite{shannon_all} of the
formula associated to the truth table, using variable order $[n-1,...,0]$.
Observe that the effect of {\tt bitunpair} is the same as
\begin{itemize}
  \item the effect of {\tt var\_mn m n (n-1)} 
     acting as a mask selecting the left branch, and
\item 
     the effect of its complement, acting as a mask selecting the right
     branch.
\end{itemize}
Given that $2^n$ is the double of $2^{n-1}$, the same invariant holds at each
step, as the bitstring length of the truth table reduces to half. 
\end{proof}
We can thus assume from now on, that the BDD data type defined in
section \ref{encbdd} actually represents BDDs mapped one-to-one to truth tables
given as natural numbers.
An interesting application of this result would
be to investigate practical uses of 
{\tt bitpair}/{\tt bitunpair} operations in actual circuit design.

\section{Ranking and Unranking of BDDs} \label{rank}

One more step is needed to extend the mapping between $BDDs$ with $n$
variables to a bijective mapping from/to $\mathbb{N}$: 
we will have to ``shift towards infinity'' 
the starting point of each new block\footnote{defined by the same number of
variables} of BDDs in $\mathbb{N}$ as BDDs of larger and larger sizes are enumerated.

First, we need to know by how much - so we will count the number
of boolean functions with up to $n$ variables.
\begin{code}
bsum 0 = 0
bsum n | n>0 = bsum1 (n-1)

bsum1 0 = 2
bsum1 n | n>0 = bsum1 (n-1)+ 2^2^n
\end{code}
The stream of all such sums can now be generated as usual\footnote{{\tt bsums}
is sequence A060803 in The On-Line Encyclopedia of Integer
Sequences, \url{http://www.research.att.com/~njas/sequences}}:
\begin{code}
bsums = map bsum [0..]
\end{code}
\begin{codex}
*ISO> genericTake 7 bsums
  [0,2,6,22,278,65814,4295033110]
\end{codex}

What we are really interested into, is decomposing {\tt n} into
the distance {\tt n-m} to the
last {\tt bsum} {\tt m} smaller than {\tt n},
and the index that generates the sum, {\tt k}.
\begin{code}
to_bsum n = (k,n-m) where 
  k=pred (head [x|x<-[0..],bsum x>n])
  m=bsum k
\end{code}
{\em Unranking} of an arbitrary BDD is now easy - the index {\tt k}
determines the number of variables and {\tt n-m} determines
the rank. Together they select the right BDD
with {\tt unfold\_bdd} and {\tt bdd}.
\begin{code}
nat2bdd n = unfold_bdd (k,n_m) where (k,n_m)=to_bsum n
\end{code}
{\em Ranking} of a BDD is even easier: we shift its rank
within the set of BDDs with {\tt nv} 
variables, by the value {\tt (bsum nv)} that
counts the ranks previously assigned.
\begin{code}
bdd2nat bdd@(BDD nv _) = (bsum nv)+tt where
  (_,tt) =fold_bdd bdd
\end{code}
As the following example shows
{\tt bdd2nat}
implements the inverse of
{\tt nat2bdd}.
\begin{codex}
*ISO> nat2bdd 42
BDD 3 (D 2 (D 1 (D 0 B0 B1) (D 0 B1 B0)) 
           (D 1 (D 0 B0 B0) (D 0 B0 B0)))
*ISO> bdd2nat it
42
\end{codex}

% plain bdds
This provides the Encoder:
\begin{code}
pbdd :: Encoder (BDD N)
pbdd = compose (Iso bdd2nat nat2bdd) nat
\end{code}
working as follows:
\begin{codex}
*ISO> as pbdd nat 2008
BDD 4 (D 3 (D 2 B0 (D 1 (D 0 B0 B1) B1)) 
      (D 2 (D 1 (D 0 B1 B1) B0) (D 1 B0 B1)))
*ISO> as nat pbdd it
2008
\end{codex}

We can now repeat the {\em ranking} function construction for {\tt eval\_bdd}:
\begin{code}
ev_bdd2nat bdd@(BDD nv _) = (bsum nv)+(eval_bdd bdd)
\end{code}
We can confirm that {\tt ev\_bdd2nat} also acts as an inverse to
{\tt nat2bdd}:
\begin{codex}
*ISO> ev_bdd2nat (nat2bdd 2008)
2008
\end{codex}

We obtain the Encoder:
\begin{code}
bdd :: Encoder (BDD N)
bdd = compose (Iso ev_bdd2nat nat2bdd) nat
\end{code}
working as follows:
\begin{codex}
*ISO> as bdd nat 2008
BDD 4 (D 3 (D 2 (D 1 (D 0 B0 B0) (D 0 B0 B0)) 
                (D 1 (D 0 B0 B1) (D 0 B1 B0))) 
           (D 2 (D 1 (D 0 B1 B1) (D 0 B0 B0)) 
                (D 1 (D 0 B0 B0) (D0 B1 B0))))
*ISO> as nat bdd it
2008
\end{codex}
This result can be seen as an intriguing isomorphism between
boolean, arithmetic and symbolic computations.

\subsection{Reducing the $BDDs$}
We will sketch here a simplified reduction mechanism for BDDs
eliminating identical branches. As nodes of a BDD are mapped
bijectively to unique natural numbers we will omit
the (trivial) implementation of node sharing, with the
implicit assumption that subtrees having the same encoding
are shared.

The function {\tt bdd\_reduce} reduces a $BDD$ by collapsing identical 
left and right subtrees, and the function {\tt bdd} 
associates this reduced form to $n \in \mathbb{N}$.
\begin{code}
bdd_reduce (BDD n bt) = BDD n (reduce bt) where
  reduce B0 = B0
  reduce B1 = B1
  reduce (D _ l r) | l == r = reduce l
  reduce (D v l r) = D v (reduce l) (reduce r)

unfold_rbdd = bdd_reduce . unfold_bdd  
\end{code}

The results returned by {\tt unfold\_rbdd} for {\tt n=2} are:
\begin{codex}
  BDD 2 (C 0)
  BDD 2 (D 1 (D 0 (C 1) (C 0)) (C 0))
  BDD 2 (D 1 (C 0) (D 0 (C 1) (C 0)))
  BDD 2 (D 0 (C 1) (C 0))
  ...
  BDD 2 (D 1 (D 0 (C 0) (C 1)) (C 1))
  BDD 2 (C 1)
\end{codex}
We can now define the {\em unranking} operation on reduced BDDs
\begin{code}
nat2rbdd = bdd_reduce . nat2bdd 
\end{code}
and obtain the Encoder
\begin{code}
rbdd :: Encoder (BDD N)
rbdd = compose (Iso ev_bdd2nat nat2rbdd) nat
\end{code}
working as follows
\begin{codex}
*ISO> as rbdd nat 2008
BDD 4 (D 3 (D 2 B0 (D 1 (D 0 B0 B1) (D 0 B1 B0))) 
           (D 2 (D 1 B1 B0) (D 1 B0 (D 0 B1 B0))))
*ISO> as nat rbdd it
2008
\end{codex}

To be able to compare its space complexity
with other representations we will define 
a size operation on a BDD as follows:
\begin{code}
bdd_size (BDD _ t) = 1+(size t) where
  size B0 = 1
  size B1 = 1
  size (D _ l r) = 1+(size l)+(size r)
\end{code}
This measures the size of the BDD or reduced BDD as an expression tree.
To take into account sharing (as present in a standard ROBDD implementation)
one can simply eliminate duplicated subtrees:
\begin{code}
robdd_size (BDD _ t) = 1+(rsize t) where
  rsize = genericLength . nub . rbdd_nodes
  rbdd_nodes B0 = [B0]
  rbdd_nodes B1 = [B1]
  rbdd_nodes (D v l r) = 
    [(D v l r)] ++ (rbdd_nodes l) ++ (rbdd_nodes r)
\end{code}

\section{Generalizing BDD ranking/unranking functions}

\subsection{Encoding BDDs with Arbitrary Variable Order}
While the encoding built around the equivalence described in Prop. \ref{tt}
between bitwise pairing/unpairing operations and boolean decomposition
is arguably as simple and elegant as possible, it is useful
to parametrize BDD generation with respect to an arbitrary
variable order. This is of particular importance when using
BDDs for circuit minimization, as different variable orders
can make circuit sizes flip from linear to exponential in
the number of variables \cite{bryant86graphbased}.

Given a permutation of $n$ variables represented as
natural numbers in $[0..n-1]$ and a truth table
$tt \in [0..2^{2^n}-1]$ we can define: 
\begin{code}
to_bdd vs tt | 0<=tt && tt <= m = 
  BDD n (to_bdd_mn vs tt m n) where
    n=genericLength vs
    m=bigone n
to_bdd _ tt = error 
   ("bad arg in to_bdd=>" ++ (show tt)) 
\end{code}
where the function {\tt to\_bdd\_mn} recurses over
the list of variables {\tt vs} and applies
Shannon expansion \cite{shannon_all},
expressed as bitvector operations. This computes
branches $f1$ and $f0$, to be used as {\tt then} and {\tt else}
parts, when evaluating back the BDD to a truth table
with if-the-else functions.
\begin{code}
to_bdd_mn []      0 _ _ = B0
to_bdd_mn []      _ _ _ = B1
to_bdd_mn (v:vs) tt m n = D v l r where
  (f1,f0)=unpair_mn v m n tt
  l=to_bdd_mn vs f1 m n
  r=to_bdd_mn vs f0 m n
  
unpair_mn v m n tt = (f1,f0) where
  cond=var_mn m n v
  f0= (m `xor` cond) .&. tt
  f1= cond .&. tt
\end{code}
\begin{prop}
The function {\tt to\_bdd} builds an (unreduced) BDD corresponding
to a truth table {\tt tt} for variable order {\tt vs} that returns
{\tt tt} when evaluated as a boolean function.
\end{prop}
We can reduce the resulting BDDs, and convert back from BDDs and reduced BDDs to
truth tables with boolean evaluation: 
\begin{code}
to_rbdd vs tt = bdd_reduce (to_bdd vs tt)
from_bdd bdd = eval_bdd bdd
\end{code}
We can obtain BDDs and reduced BDDs of various sizes as follows:
\begin{codex}
*ISO> as perm nat 5
[0,2,1]
*ISO> to_bdd (as perm nat 5) 42
BDD 3 (D 0 (D 2 (D 1 B0 B0) (D 1 B1 B1)) 
           (D 2 (D 1 B0 B0) (D 1 B1 B0)))
*ISO> to_rbdd (as perm nat 5) 42
BDD 3 (D 0 (D 2 B0 B1) (D 2 B0 (D 1 B1 B0)))
*ISO> to_rbdd (as perm nat 8) 42
BDD 3 (D 2 B0 (D 0 B1 (D 1 B1 B0)))
ISO> from_bdd it
42
\end{codex}
Two interesting instances are worth pointing out. After defining
\begin{code}
nat2bdd0 n = b where 
  b=to_bdd (reverse [0..k-1]) m_n
  (k,m_n)=to_bsum n
\end{code}
the following holds:
\begin{prop}
nat2bdd0 $\equiv$ nat2bdd
\end{prop}
After defining
\begin{code}
nat2bddn n = b where 
  b=to_bdd [0..k-1] m_n
  (k,m_n)=to_bsum n

bddn :: Encoder (BDD N)
bddn = compose (Iso ev_bdd2nat nat2bddn) nat
\end{code}
we observe that {\tt bddn} works in reverse variable order compared to {\tt
bdd}.
\begin{codex}
*ISO> as bdd nat 42
BDD 3 (D 2 (D 1 (D 0 B0 B1) (D 0 B1 B0)) (D 1 (D 0 B0 B0) (D 0 B0 B0)))
*ISO> as bddn nat 42
BDD 3 (D 0 (D 1 (D 2 B0 B0) (D 2 B1 B0)) (D 1 (D 2 B1 B0) (D 2 B0 B0)))
*ISO> as nat bddn it
42
\end{codex}

Finally, we can, obtain a minimal BDD expressing a logic function of $n$
variables given as a truth table as follows:
\begin{code}
to_min_bdd n t = search_bdd min n t

search_bdd f n tt = snd $ foldl1 f 
 (map (sized_rbdd tt) (all_permutations n)) where
    sized_rbdd tt vs = (robdd_size b,b) where 
      b=to_rbdd vs tt
 
all_permutations n = if n==0 then [[]] else
  [nth2perm (n,i)|i<-[0..(factorial n)-1]] where
     factorial n=foldl1 (*) [1..n]
\end{code}
%$
As the following examples show, this can provide an effective 
multilevel boolean formula minimization up to functions with
6-7 arguments.
\begin{codex}
*ISO> to_min_bdd 3 42
BDD 3 (D 0 (D 2 B0 B1) (D 1 (D 2 B0 B1) B0))
*ISO> to_min_bdd 4 2008
BDD 4 (D 3 (D 1 (D 0 B0 B1) (D 0 B1 B0)) 
      (D 2 (D 1 (D 0 B0 B1) B0) (D 0 B1 B0)))
*ISO> to_min_bdd 7 2008
BDD 7 (D 0 (D 1 (D 2 (D 6 
                     (D 4 (D 3 B0 B1) (D 3 B1 B0)) 
      (D 5 (D 4 (D 3 B0 B1) B0) 
                (D 3 B1 B0))) B0) B0) B0)
*ISO> robdd_size it
12
\end{codex}

\subsection{Multi-Terminal Binary Decision Diagrams (MTBDD)} \label{multi}
MTBDDs \cite{DBLP:journals/fmsd/FujitaMY97,CBGP08} are a natural generalization
of BDDs allowing non-binary values as leaves.
Such values are typically 
bitstrings representing the outputs
of a multi-terminal boolean function,
encoded as unsigned integers.

We shall now describe an encoding of $MTBDDs$
that can be extended to ranking/unranking functions,
in a way similar to $BDDs$ as shown in section \ref{rank}.

Our {\tt MTBDD} data type is a binary tree like the one used for $BDDs$,
parameterized by two integers {\tt m} and {\tt n}, indicating
that an MTBDD represents a function from $[0..n-1]$ to $[0..m-1]$,
or equivalently, an $n$-input/$m$-output boolean function.

\begin{code}   
data MT a = Lf a | M a (MT a) (MT a) deriving (Eq,Ord,Read,Show)
data MTBDD a = MTBDD a a (MT a) deriving (Show,Eq)
\end{code}

The function  {\tt to\_mtbdd} creates,
from a natural number tt representing a truth table,
an MTBDD representing
functions of type $N \rightarrow M$ with $M=[0..2^m-1], N=[0..2^n-1]$.
Similarly to a BDD, it is represented as binary tree 
of $n$ levels, except that its leaves are in $[0..{2^m}-1]$.
\begin{code}
to_mtbdd m n tt = MTBDD m n r where 
  mlimit=2^m
  nlimit=2^n
  ttlimit=mlimit^nlimit
  r=if tt<ttlimit 
    then (to_mtbdd_ mlimit n tt)
    else error 
      ("bt: last arg "++ (show tt)++
      " should be < " ++ (show ttlimit))
\end{code}
Given that correctness of the range of
{\tt tt} has been checked, the function {\tt to\_mtbdd\_} 
applies {\tt bitmerge\_unpair} 
recursively up to depth $n$, where
leaves in range $[0..mlimit-1]$ are created.
\begin{code}  
to_mtbdd_ mlimit n tt|(n<1)&&(tt<mlimit) = Lf tt
to_mtbdd_ mlimit n tt = (M k l r) where 
   (x,y)=bitunpair tt
   k=pred n
   l=to_mtbdd_ mlimit k x
   r=to_mtbdd_ mlimit k y
\end{code}
Converting back from $MTBDDs$ to natural numbers is
basically the same thing as for $BDDs$, except that
assertions about the range of leaf data are enforced.
\begin{code}
from_mtbdd (MTBDD m n b) = from_mtbdd_ (2^m) n b

from_mtbdd_ mlimit n (Lf tt)|(n<1)&&(tt<mlimit)=tt
from_mtbdd_ mlimit n (M _ l r) = tt where 
   k=pred n
   x=from_mtbdd_ mlimit k l
   y=from_mtbdd_ mlimit k r
   tt=bitpair (x,y)
\end{code}
The following examples show that {\tt to\_mtbdd} and {\tt from\_mtbdd}
are indeed inverses values in $[0..2^n-1] \times [0..2^m-1]$. 
\begin{codex}
>to_mtbdd 3 3 2008
  MTBDD 3 3 
    (M 2 
      (M 1 
         (M 0 (Lf 2) (Lf 1)) 
         (M 0 (Lf 2) (Lf 1))) 
      (M 1 
         (M 0 (Lf 2) (Lf 0)) 
         (M 0 (Lf 1) (Lf 1))))

>from_mtbdd it
2008

>mprint (to_mtbdd 2 2) [0..3]
  MTBDD 2 2 
    (M 1 (M 0 (Lf 0) (Lf 0)) (M 0 (Lf 0) (Lf 0)))
  MTBDD 2 2 
    (M 1 (M 0 (Lf 1) (Lf 0)) (M 0 (Lf 0) (Lf 0)))
  MTBDD 2 2 
    (M 1 (M 0 (Lf 0) (Lf 0)) (M 0 (Lf 1) (Lf 0)))
  MTBDD 2 2 
    (M 1 (M 0 (Lf 1) (Lf 0)) (M 0 (Lf 1) (Lf 0)))
\end{codex}

\subsection{Encoding Powerlists}

Powerlists \cite{Misra94powerlist:a} are lists of length $2^n$ on which a
merge operation (called {\tt zip}) and a concatenation operation (called {\tt
tie}) are defined. They are important for specifying/implementing parallel 
operations and efficient arithmetic operation hardware. 
In \cite{Bird99programoptimisation} a data type {\tt Plist} is given that enforces
the $2^n$ length using a Peano arithmetic successor to describe depth while
recursing on pairs, but as we will see our BDD representation does the same
without using successor arithmetics.

We will also describe here ranking/unranking operations on powerlists and their
relation to our BDD types.

We start with a linear list specification of their merge and concatenation
operations (assuming informally that their length is a power of two
and that they are nonempty):
\begin{code}
lTie xs ys = xs ++ ys

lZip [] [] = []
lZip (x:xs) (y:ys) = x:y:(lZip xs ys)
\end{code}
working as follows
\begin{codex}
*ISO> lZip (lTie [0] [1]) (lTie [2] [3])
[0,2,1,3]
\end{codex}
We can convert a BDD to a linear representation of a powerlist with binary
scalars enforcing the constraints on length, simply by collecting its leaves:
\begin{code}
bdd2plist (BDD _ b) = bt2plist b where
  bt2plist B0 = [0]
  bt2plist B1 = [1]
  bt2plist (D _ l r) = (bt2plist l) ++ (bt2plist r)  
\end{code}
{\em
Depending on the variable order used to build a BDD we obtain different
powerlists. As we will see later, of particular interest are the cases when the
Encoders {\tt bdd} and {\tt bddn} are used.}
\begin{codex}
*ISO> bdd2plist (as bdd nat 42)
[0,1,1,0,0,0,0,0]
*ISO> bdd2plist (as bddn nat 42)
[0,0,1,0,1,0,0,0]
\end{codex}
Let us define a tree representation that describes powerlists as 
a combination of {\tt Tie} and {\tt Zip} operations.
\begin{code}
data PL a =  S a | Tie (PL a) (PL a) | Zip (PL a) (PL a) 
  deriving (Eq,Show,Read)
\end{code}
We first design converters from BDDs:
\begin{code}
bdd2pl f (BDD _ b) = bt2pl f b where
  bt2pl _ B0 = S 0
  bt2pl _ B1 = S 1
  bt2pl f (D _ l r) = f (bt2pl f l) (bt2pl f r)
  
bdd2zip b = bdd2pl Zip b

bdd2tie b = bdd2pl Tie b
\end{code}
We can flatten a powerlist to a linear list representation:
\begin{code}
flattenPL (S a)= [a]
flattenPL (Tie x y) = lTie (flattenPL x) (flattenPL y)
flattenPL (Zip x y) = lZip (flattenPL x) (flattenPL y)
\end{code}
We can compute the depth of a powelist, knowing that all leaves are at the same
distance from the root.
\begin{code}
depthPL (S _)= 0
depthPL (Tie x _) = 1+(depthPL x)
depthPL (Zip x _) = 1+(depthPL x)
\end{code}
We are now ready to define two encoders:
\begin{code}
powerZip :: Encoder (PL N)
powerZip = compose (Iso pl2nat nat2zip) nat

powerTie :: Encoder (PL N)
powerTie = compose (Iso pl2nat nat2tie) nat

nat2zip n = bdd2pl Zip (as bdd nat n)
nat2tie n = bdd2pl Tie (as bddn nat n)

pl2nat pl = bsum (depthPL pl)+(as nat bits1 (flattenPL pl))
\end{code}
that provide Zip and Tie based representations of a natural number
as a powerlist. Note that {\tt pl2nat} is generically used to
rank both {\tt Zip} and {\tt Tie} based powerlists while
{\tt nat2zip} and {\tt nat2tie} respectively unrank a natural number to 
a {\tt Zip} or {\tt Tie} based powerlist. 
As in the case of BDDs note the use of {\tt bsum} (see section \ref{rank}))
computing the number of boolean functions up to $n$ variables, needed
to ensure that the encoding is a bijection.
Also note, that, as it is known from powerlist algebra
\cite{Misra94powerlist:a}, the same powerlist can be 
expressed indeed in two alternative forms in terms of {\tt Zip} 
or {\tt Tie}:
\begin{codex}
*ISO> as powerZip nat 42
Zip (Zip (Zip (S 0) (S 1)) (Zip (S 1) (S 0))) 
    (Zip (Zip (S 0) (S 0)) (Zip (S 0) (S 0)))
*ISO> as powerTie powerZip it
Tie (Tie (Tie (S 0) (S 0)) (Tie (S 1) (S 0))) 
    (Tie (Tie (S 1) (S 0)) (Tie (S 0) (S 0)))
*ISO> as nat powerTie it
42
\end{codex}
As the example suggests, we obtain as ``free algorithms'' converters between
Zip and Tie representation of powerlists as follows:
\begin{code}
zip2tie = as powerTie powerZip
tie2zip = as powerZip powerTie
\end{code}
The crux of these equivalences results is the use of the Encoders
{\tt bdd} and {\tt bddn} to obtain isomorphic BDD representions derived
from two different variable orders, $[0..n-1]$ and $[n-1..0]$ for the same
natural number in $[0..{2^{2^n}}-1]$ seen as truth table.

An interesting application is that automorphism on powerlists
induce automorphisms on natural numbers. As in 
\cite{Misra94powerlist:a}) one can define a reverse operation on powerlists:
\begin{code}
rev (S x) = S x
rev (Tie x y) = Tie (rev y) (rev x)
rev (Zip x y) = Zip (rev y) (rev x)
\end{code}
we obtain
\begin{codex}
*ISO> borrow_from powerTie rev nat 42
62
*ISO> borrow_from powerTie rev nat 62
42
\end{codex}
After defining
\begin{code}
tierev = borrow_from powerTie rev nat
ziprev = borrow_from powerZip rev nat
\end{code}
we observe that
\begin{codex}
*ISO> map tierev [0..15]
[0,1,2,4,3,5,6,14,10,18,8,16,12,20,7,15]
*ISO> map tierev it
[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]
*ISO> map ziprev [0..15]
[0,1,2,4,3,5,6,14,10,18,8,16,12,20,7,15]
*ISO> map ziprev it
[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]
*ISO> 
\end{codex}
indicating that this is indeed an automorphism on the set of natural numbers.

Alternatively, operations borrowed from natural numbers can enrich the powerlist
algebra with new operations
\begin{code}
tieSucc = borrow_from nat succ powerTie
tiePred = borrow_from nat pred powerTie
tieSum = borrow_from2 nat (+) powerTie

zipSucc = borrow_from nat succ powerZip
zipPred = borrow_from nat pred powerZip
zipSum = borrow_from2 nat (+) powerZip
\end{code}
working as follows:
\begin{codex}
*ISO> tieSucc (S 0)
S 1
*ISO> tieSucc (tieSucc (S 0))
Tie (S 0) (S 0)
*ISO> tiePred (tiePred it)
S 0
*ISO> zipSum (Zip (S 0) (S 0)) (S 1)
Zip (S 1) (S 0)
*ISO> tieSum (Tie (S 0) (S 0)) (S 1)
Tie (S 1) (S 0)
\end{codex}
As powerlist representation are well suited for parallel processing it looks
like an interesting avenue to explore if they can actually provide hardware
support for high performance parallel arithmetic operations on arbitrary size
integers.

%% TODO - explain in more detail

\section{Revisiting Encodings of Finite Functions} \label{tfun}
We will now generalize the {\tt bitpair} pairing function to $k$-tuples and then we will 
derive an alternative encoding for finite functions. 

\subsection{Tuple Encodings as Generalized Bitpair} \label{tuple}
The function {\tt to\_tuple:} $\mathbb{N} \rightarrow \mathbb{N}^k$ converts a natural 
number to a $k$-tuple by splitting its bit representation into $k$ groups, 
from which the $k$ members in the tuple are finally rebuilt. This operation 
can be seen as a transposition of a bit matrix obtained by expanding 
the number in base $2^k$:
\begin{code}  
to_tuple k n = map (from_base 2) (
    transpose (
      map (to_maxbits k) (
        to_base (2^k) n
      )
    )
  )
\end{code}
To convert a $k$-tuple back to a natural number we will merge their 
bits, $k$ at a time. This operation uses the transposition of a bit 
matrix obtained from the tuple, seen as a number in base $2^k$, 
with help from bit crunching functions given in APPENDIX:
\begin{code}
from_tuple ns = from_base (2^k) (
    map (from_base 2) (
      transpose (
        map (to_maxbits l) ns
      )
    )
  ) where 
      k=genericLength ns
      l=max_bitcount ns
\end{code}
The following example shows the decoding of {\tt 42}, its decomposition 
in bits (right to left), the formation of a $3$-tuple and the encoding 
of the tuple back to {\tt 42}.
\begin{codex}
*ISO> to_base 2 42
[0,1,0,1,0,1]
*ISO> to_tuple 3 42
[2,1,2]
*ISO> to_base 2 2
[0,1]
*ISO> to_base 2 1
[1]
*ISO> from_tuple [2,1,2]
42
\end{codex}
Fig. \ref{3tuple} shows multiple steps of the same decomposition, 
with shared nodes collected in a DAG. 
\VFIGS{3tuple}{Repeated 3-tuple expansions}{42}{2008}{isot42.pdf}{isot2008.pdf}

\subsection{Encoding Finite Functions as Tuples}

As finite sets can be put in a bijection with an initial segment 
of $\mathbb{N}$,
a {\tt finite function} can be seen as a function defined from an
initial segment of $\mathbb{N}$ to $\mathbb{N}$.
We can encode and decode a finite function from $[0..k-1]$ to $\mathbb{N}$ 
(seen as the list of its values), as a natural number:
\begin{code} 
ftuple2nat [] = 0
ftuple2nat ns = succ (pepis_pair (pred k,t)) where
  k=genericLength ns 
  t=from_tuple ns

nat2ftuple 0 = []
nat2ftuple kf = to_tuple (succ k) f where 
  (k,f)=pepis_unpair (pred kf)
\end{code}
As the length of the tuple, {\tt k}, is usually smaller than the number 
obtained by merging the bits of the {\tt k}-tuple, we have picked the 
Pepis pairing function, exponential in its first argument and linear 
in its second, to embed the length of the tuple needed for the decoding. 
This suggest the following alternative Encoder for finite functions:
\begin{code}
fun' :: Encoder [N]
fun' = compose (Iso ftuple2nat nat2ftuple) nat
\end{code}
as well as the related alternative hylomorphism:
\begin{code}
nat_fun' = Iso nat2ftuple ftuple2nat

hff' :: Encoder T
hff' = compose (hylo nat_fun') nat
\end{code}

The encoding/decoding and the hylomorphism work as follows:
\begin{codex}
*ISO> as fun' nat 2008
[3,2,3,1]
*ISO> as nat fun' it
2008

*ISO> as hff' nat 2008
H [H [H [H []]],H [H [],H []],H [H [H []]],H [H []]]
*ISO> as nat hff' it
2008
\end{codex}
Given this alternative enecoding for finite functions, one can derive from it
new Encoders for multisets and sets as follows:
\begin{code}
mset2nat' = ftuple2nat . mset2fun
nat2mset' = fun2mset . nat2ftuple

nat_mset' = Iso nat2mset' mset2nat' 

mset' :: Encoder [N]
mset' = compose (invert nat_mset') nat

set2nat' = ftuple2nat . set2fun
nat2set' = fun2set . nat2ftuple 

nat_set' = Iso nat2set' set2nat' 

set' :: Encoder [N]
set' = compose (invert nat_set') nat
\end{code}
working as follows:
\begin{codex}
*ISO> set2nat [7,22,45]
35184376283264
*ISO> set2nat' [7,22,45]
143308
*ISO> nat2set' 143308
[7,22,45]
*ISO> mset2nat [7,22,22,45,45]
844424955297920
*ISO> mset2nat' [7,22,22,45,45]
270904688
*ISO> nat2mset' 270904688
[7,22,22,45,45]
\end{codex}

We can define new Encoders lifting these operations to hereditarily
finite structures:
\begin{code}

hfs' :: Encoder T
hfs' = compose (hylo nat_set') nat

hfm' :: Encoder T
hfm' = compose (hylo nat_mset') nat
\end{code}

We can also define alternative {\tt hd, tl, cons} and pairing/unpairing
operations:
\begin{code}
hd' = head . nat2ftuple
tl' = ftuple2nat . tail . nat2ftuple
cons' h t  = ftuple2nat (h:(nat2ftuple t))

pair' (x,y) = (cons' x y)-1
unpair' z = (hd' z', tl' z') where z'=z+1
\end{code}

Fig. \ref{pairprim3} shows the values of {\tt z=pair' (x,y)} for $x,y \in
[0..2^{6}-1]$.
\FIG{pairprim3}{Values of z=pair' (x,y)}{0.35}{pairprim3.pdf}

An unusual thing about this pairing function is that it reaches very
large values strictly when its both arguments are powers of 2, for
instance:
\begin{codex}
*ISO> pair' (4,4)
4103
*ISO> pair' (3,4)
279
*ISO> pair' (4,3)
73
\end{codex}

Also, the bit splitting mechanism used in {\tt bitpair/bitunpair} can be
generalized using tuples, by allowing an arbitrary division in {\tt k+l} groups
with {\tt k} aggregating into the first element and {\tt l} aggregating as the second element of the pair as follows:
\begin{code}
pairKL k l (x,y) = from_tuple (xs ++ ys) where
   xs = to_tuple k x
   ys = to_tuple l y
   
unpairKL k l z = (x,y) where 
  zs=to_tuple (k+l) z
  xs=genericTake k zs
  ys=genericDrop k zs
  x=from_tuple xs
  y=from_tuple ys
\end{code}

Fig. \ref{klp32} shows the values of {\tt z=pairKL 3 2 n} for $n \in
[0..2^{6}-1]$.
\FIG{klp32}{Values of pairKL}{0.25}{klp32.pdf}

Fig. \ref{uklp238} shows the path obtained by connecting pairs
{\tt (x,y) = unpairKL 2 3} for $n \in [0..15]$.
\FIG{uklp238}{Path connecting unpairKL}{0.25}{uklp238.pdf}

\section{Directed Graphs, DAGs, Undirected graphs, Multigraphs and Hypergraphs}
We will now show that more complex data types like digraphs, DAGs and
hypergraphs have extremely simple encoders. This shows once more the importance
of compositionality in the design of our embedded transformation
language.

\subsection{Encoding Directed Graphs} \label{digraphs}
We can find a bijection from 
directed graphs (with no isolated vertices, corresponding to their
 view as binary relations), to finite sets by fusing their list
 of ordered pair representation into finite sets with a pairing
 function:
\begin{code}
digraph2set ps = map bitpair ps
set2digraph ns = map bitunpair ns
\end{code}
The resulting Encoder is:
\begin{code}
digraph :: Encoder [N2]
digraph = compose (Iso digraph2set set2digraph) set
\end{code}
working as follows:
\begin{codex}
*ISO> as digraph nat 2008
[(1,1),(2,0),(2,1),(3,1),(0,2),(1,2),(0,3)]
*ISO> as nat digraph it
2008
*ISO> as digraph nat 17
[(0,0),(2,0)]
*ISO> as nat digraph it
17
\end{codex}
Fig. \ref{f5} shows the digraph associated to {\tt 2008}.
\FIG{f5}{2008 as a digraph}{0.60}{isof5.pdf}

Fig. \ref{isopviz17} shows the digraph associated to {\tt 17}.
\FIG{isopviz17}{17 as a digraph with isolated vertex
ignored}{0.60}{isopviz17.pdf} 
Note that in this figure (and in the subsequent ones) isolated vertices are
will not be drawn, but implicetely assumed present as shown in Fig.
\ref{isoeviz17}.
\FIG{isoeviz17}{17 as a digraph with isolated vertex
shown}{0.60}{isoeviz17.pdf} 

Note also that this encoding is parameterized by the pairing/unpairing functions
used, i.e. an alternative encoding can be obtained as:
\begin{code}
digraph2set' ps = map pepis_pair ps
set2digraph' ns = map pepis_unpair ns
\end{code}
The resulting Encoder is:
\begin{code}
digraph' :: Encoder [N2]
digraph' = compose (Iso digraph2set' set2digraph') set
\end{code}
Fig. \ref{isopepisg2008} shows this alternative digraph associated to {\tt 2008}.
\FIG{isopepisg2008}{2008 as a different digraph}{0.60}{isopepisg2008.pdf}

\subsection{Encoding Undirected Graphs} \label{ugraphs}
We can find a bijection from 
undirected graphs to finite sets by fusing their list
 of unordered pair representation into finite sets with a pairing
 function on multiset pairs:
\begin{code}
graph2mset ps = map mset_pair ps
mset2graph ns = map mset_unpair ns
\end{code}
The resulting Encoder is:
\begin{code}
graph :: Encoder [N2]
graph = compose (Iso graph2mset mset2graph) set
\end{code}
working as follows:
\begin{codex}
*ISO> as graph nat 2008
[(1,2),(2,2),(2,3),(3,4),(0,2),(1,3),(0,3)]
*ISO> as nat graph it
2008
\end{codex}
Note that, as expected, the result is invariant to changing the order of
elements in pairs like {\tt (1,2)} and {\tt (3,4)} to {\tt (2,1)} and
{\tt (4,3)}.

\subsection{Encoding Directed Multigraphs} \label{mdigraphs}
We can find a bijection from 
directed multigraphs (directed graphs with multiple edges between pairs of
vertices, alos called {\em multi-digraphs} or {\em quivers}) to finite sequences
by fusing their list of ordered pair representation into finite sequences 
with a pairing function:

The resulting Encoder is:
\begin{code}
mdigraph :: Encoder [N2]
mdigraph = compose (Iso digraph2set set2digraph) fun
\end{code}
working as follows:
\begin{codex}
*ISO> as mdigraph  nat 1234567890
[(1,0),(0,1),(1,0),(0,0),(1,0),(3,1),(0,0),(1,0),(0,1),(0,0),(0,1),(0,1)]
\end{codex}
Note that the only change to the {\tt digraph} Encoder is replacing
the composition with {\tt set} by a composition with {\tt fun}.

Fig. \ref{isomdigraph} depicts the directed multi-digraph associated to
1234567890. Note that position in the sequence of pairs provides the (unique) label marking
each edge.
\FIG{isomdigraph}{1234567890 as a directed multigraph}{0.60}{isomdigraph.pdf} 
 
\subsection{Encoding Undirected Multigraphs} \label{mgraphs}
We can find a bijection from 
undirected multigraphs (undirected graphs with multiple edges between 
unordered pairs of
vertices) to finite sequences by fusing their list of pair
representation into finite sequences with a 
pairing function on unordered pairs:

The resulting Encoder is:
\begin{code}
mgraph :: Encoder [N2]
mgraph = compose (Iso graph2mset mset2graph) fun
\end{code}
working as follows:
\begin{codex}
*ISO> as mgraph nat 2008
[(1,2),(0,0),(1,1),(0,0),(0,0),(0,0),(0,0)]
*ISO> as nat mgraph it
2008
\end{codex}
Note that the only change to the {\tt graph} Encoder is replacing
the composition with {\tt set} by a composition with {\tt fun}.
 
\subsection{Encoding Hypergraphs}
\begin{df}
A hypergraph (also called {\em set system}) is a pair $H=(X,E)$ where
$X$ is a set and $E$ is a set of non-empty subsets of $X$.
\end{df}
We can easily
derive a bijective encoding of {\em hypergraphs}, 
represented as sets of sets:
\begin{code}
set2hypergraph = map (nat2set . succ)
hypergraph2set = map (pred . set2nat)
\end{code}
The resulting Encoder is:
\begin{code}
hypergraph :: Encoder [[N]]
hypergraph = compose (Iso hypergraph2set set2hypergraph) set
\end{code}
working as follows
\begin{codex}
*ISO> as hypergraph nat 2009
[[0],[2],[0,2],[0,1,2],[3],[0,3],[1,3],[0,1,3]]
*ISO> as nat hypergraph it
2009
\end{codex}
Assuming that vertex numbers are liftd to even integers and hyperedge labels are
odd integers derived from their position in the sequence,
we can define the {\em bipartite graph} uniquely associated to a hypergraph as:

\begin{code}
bipartite :: Encoder [N2]
bipartite = compose (Iso bipartite2hyper hyper2bipartite) hypergraph
 
hyper2bipartite xss = xs where
  l=genericLength xss
  xs=[(fromIntegral (2*i+1),fromIntegral (2*x))|i<-[0..l-1],x<-xss!!i]

bipartite2hyper xs = xss where
  pss = groupBy (\x y->fst x== fst y)  xs
  xss = map (map (hf . snd)) pss
  hf x = x `div` 2
\end{code}
working as follows:
\begin{codex}
[(1,0),(3,4),(5,0),(5,4),(7,0),(7,2),(7,4),(9,6),(11,0),
 (11,6),(13,2),(13,6),(15,0),(15,2),(15,6)]
*ISO> as nat bipartite it
2009
\end{codex}
Fig. \ref{isobi} shows the bipartite graph derived from the hypergraph
associated to {\tt 2009}.
\FIG{isobi}{2009 as a bipartite graph}{0.60}{isobi.pdf}

We can define the dual of a bipartite graph as follows:
\begin{code}
bidual ps = sort (map (\(x,y)->(succ y,pred x)) ps)
\end{code}
and derive involutions on natural numbers and hypergraphs with
\begin{code}
borrow_bidual = borrow_from bipartite bidual
nbidual = borrow_bidual nat
hbidual = borrow_bidual hypergraph
\end{code}

\begin{codex}

\end{codex}

An interesting  graph is the {\em intersection graph} associated to the
hypergraph, connecting distinct hyperedges with non-empty intersections:
\begin{code}
to_igraph xss= gs where  
  l=genericLength xss
  crosses xs ys = []/=intersect xs ys
  gs=[(fromIntegral i,fromIntegral j)|
     i<-[0..l-1],j<-[i+1..l-1],crosses (xss!!i) (xss!!j)]
\end{code}
working as follows:
\begin{codex}
*ISO> as hypergraph nat 2009
[[0],[2],[0,2],[0,1,2],[3],[0,3],[1,3],[0,1,3]]
*ISO> as nat hypergraph it
2009
*ISO> to_igraph it
[(0,2),(0,3),(0,5),(0,7),(1,2),(1,3),(2,3),(2,5),(2,7),
 (3,5),(3,6),(3,7),(4,5),(4,6),(4,7),(5,6),(5,7),(6,7)]
\end{codex}
Note that a canonical representation of an intersection graph is obtained by
relabeling hyperedges with integers given by their position in the list of
hyperedges as shown in Fig. \ref{isoigraph}, where only edges 
smaller vertices to larger ones are drawn.

\FIG{isoigraph}{Intersection graph derived from the hypergraph associated to
2009 }{0.40}{isoigraph.pdf}

One can map this operation to an endomorphism $\mathbb{N} \to \mathbb{N}$
\begin{code} 
to_ngraph n = as nat dag gs where 
  xss=as hypergraph nat n
  gs=to_igraph xss
\end{code}
working as follows:
\begin{codex}
*ISO>  map to_ngraph [0..63]
[0,0,0,0,0,1,1,6,0,0,0,0,0,1,1,6,0,1,0,4,1,7,3,278,1,6,2,272,
 6,281,25,1126,0,0,1,2,1,3,7,30,1,2,6,24,6,25,281,614,1,3,6,
 28,7,31,283,886,7,30,282,880,286,889,1657,72934]
\end{codex}
The k-iterate of {\tt to\_ngraph} can be definied as
\begin{code}
to_kngraph n 0 = n
to_kngraph n k = to_ngraph (to_kngraph n (k-1))
\end{code}
working as follows:
\begin{codex}
*ISO> map (\x->to_kngraph x 2) [0..31]
[0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,6,0,27,0,1,0,1,1,278,6,1919]
*ISO> to_kngraph 2009 1
1172544926110
*ISO> to_kngraph 2009 2
115792089237316195423571084873248901019948333048860797797852576952869307017369
\end{codex}

\subsection{Encoding DAGs}
One can derive an encoders for directed acyclic graphs (DAGs) from the encoding
of digraphs under the assumption that they are canonically represented by pairs
of edges such that the first element of the pair is strictly smaller.

After defining:
\begin{code}
digraph2dag = map f where f (x,y) = (x,y+x+1)

dag2digraph = map f where f (x,y) | y>x = (x,y-x-1)
\end{code}
we obtain the Encoder:
\begin{code}
dag :: Encoder [N2]
dag = compose (Iso dag2digraph digraph2dag ) digraph
\end{code}
working as follows:
\begin{codex}
*ISO> as nat dag [(0,1),(1,2),(0,2),(1,3),(2,3),(3,4),(4,5),(1,6)]
8590000191
*ISO> as dag nat it
[(0,1),(1,2),(0,2),(1,3),(2,3),(3,4),(4,5),(1,6)]
*ISO> as digraph nat 2009
[(0,0),(1,1),(2,0),(2,1),(3,1),(0,2),(1,2),(0,3)]
*ISO> as nat digraph it
2009
*ISO> as dag nat 2009
[(0,1),(1,3),(2,3),(2,4),(3,5),(0,3),(1,4),(0,4)]
*ISO> as nat dag it
2009
\end{codex}
Fig. \ref{digdag} shows the digraph and DAG associated to 2009. Note that they
have the same number of edges. It looks interesting to explore in detail how
properties of the two graphs are related.
\HFIGS{digdag}
{Digraph and DAG associated to 2009}
{Digraph}{DAG}{isodigraph.pdf}{isodag.pdf}
Clearly, we can state that:
\begin{prop}
There's a bijection between the set of finite digraphs and finite DAGs that
preserves the number of edges.
\end{prop}
Note that there's an obvious mapping between DAGs and unordered graphs,
without self-loops, obtained by always directing edges from vertices with lower
indices to vertices with strictly higher indices.

As DAGs are digraphs, applying the digraph to DAG transformation
to a DAG generates a new digraph. One can iterate this 
\begin{code}
kdag :: N->Encoder [N2]->Encoder [N2]
kdag k t = compose (Iso (dig2dag k) (dag2dig k)) t

dig2dag 0 g = g
dig2dag k g | k>0 = dag2digraph (dig2dag (k-1) g)

dag2dig 0 g = g
dag2dig k g | k>0 = digraph2dag (dag2dig (k-1) g)
\end{code}
Using and alternative digraph mapping gives rise to a
different DAG encoding. We can obtain an alternative Encoder simply as:
\begin{code}
dag' :: Encoder [N2]
dag' = compose (Iso dag2digraph digraph2dag ) digraph'
\end{code}
Note also the use of the parameterized {\em Encoder transformer} {\tt kdag},
working as follows:
\begin{codex}
*ISO> as (kdag 3 digraph) nat 2009
[(0,3),(1,7),(2,9),(2,10),(3,13),(0,5),(1,8),(0,6)]
*ISO> as (kdag 3 digraph') nat 2009
[(0,3),(2,9),(0,5),(0,6),(3,12),(0,7),(1,8),(0,8)]
\end{codex}
Interestingly, after a few steps, while vertex codes increase, the resulting
DAGs reach a fixpoint in the sense that they remain isomorphic to the DAGs
obtain at the previous iteration up to a relabeling of their vertices.
Figs. \ref{kdag12} and \ref{kdag34} show the DAGs associated to 2009 after 1
and 2 iterations, and 3 and 4 iterations, respectively.
\HFIGS{kdag12}
{k-DAGs associated to 2009}
{k=1}{k=2}{isodag.pdf}{isokdag2.pdf}

\VFIGS{kdag34}
{k-DAGs associated to 2009}
{k=3}{k=4}{isokdag3.pdf}{isokdag4.pdf}


\subsection{Acyclic multi-digraphs}

In a way similar to digraphs, we obtain the Encoder:
\begin{code}
mdag :: Encoder [N2]
mdag = compose (Iso dag2digraph digraph2dag ) mdigraph
\end{code}
working as follows:
\begin{codex}
*ISO> as mdag nat 1234567890
[(1,2),(0,2),(1,2),(0,1),(1,2),(3,5),(0,1),(1,2),(0,2),(0,1),(0,2),(0,2)]
*ISO> as nat  mdag it
1234567890
\end{codex}
Note that as in the case of the multi-digraph encoding, position of an edge
defines it's unique label.

Fig. \ref{isomdag} depicts the acyclic multi-digraph associated to 1234567890.

\FIG{isomdag}{1234567890 as a directed multigraph}{0.60}{isomdag.pdf} 
 

\subsection{Using graphs as data transformers}

Let's first define a set of simple data transformation operations working on
sequences:
\begin{code}
ins xs at val = ys where
  fi (hs,ts) = hs ++ (val:ts) 
  ys=fi (genericSplitAt at xs)
 
del xs at = ys where
  fd (hs,(_:ts)) = hs ++ ts 
  ys=fd (genericSplitAt at xs)

subst xs at with = ins (del xs at) at with
\end{code}
Each edge in a graph can be seen as specifying a transposition {\tt (i,j)}
operating on a sequence {\tt ms}:
\begin{code}
gswap ms (i,j) = transp ms (2*i,2*j+1)

transp ms (i,j) = ms' where
  x=ms!!(fromIntegral i)
  y=ms!!(fromIntegral j)
  ms'=subst (subst ms i y) j x
\end{code}
We will use an infinite tape {\tt newMem} with {\tt 0}s in even positions and
{\tt 1}s in odd positions:
\begin{code}
newMem = 0:1:newMem
\end{code}
A graph, seen as a list of pairs indicating transpositions can now operate on
the tape {\tt ms} and derive arbitrary boolean functions / sets represented as
bitstrings.
\begin{code}
applyPairs _ [] ms = ms
applyPairs sf (p:ps) ms = applyPairs sf ps (sf ms p)
\end{code}
One can extract the initial segment of the infinite tape after the computation:
\begin{codex}
*ISO> take 12 (applyPairs gswap [] newMem)
[0,1,0,1,0,1,0,1,0,1,0,1]
*ISO> take 12 (applyPairs gswap [(0,1)] newMem)
[1,1,0,0,0,1,0,1,0,1,0,1]
*ISO> take 12 (applyPairs gswap [(0,1),(1,2)] newMem)
[1,1,1,0,0,0,0,1,0,1,0,1]
\end{codex}
An interesting property of this computation is {\em reversibility}. Applying
the transposed graph restores the original tape.

An simple computation performed by a list of
pairs can be defined as:
\begin{code}
bitcompute graphType =  (as nat bits) . runPairs . (as graphType nat)

runPairs ps=rs where  
  qs=applyPairs gswap ps newMem 
  rs=genericTake (genericLength ps) qs
\end{code}
working as follows:
\begin{codex}
*ISO> bitcompute digraph 2009
420
*ISO> bitcompute dag 2009
498
\end{codex}
An interesting operation is application of a digraph or dag to a
bitstring representing a hereditarily finite structure.
\begin{code}
encodeTransformer n = pepis_pair (l,as nat dag t) where
  (l,t) = induceTransformer n

induceTransformer n = ((hf l)-(genericLength ps)-1,ps) where
  ps=map f qs
  (l,qs)=induceTransps n
  hf n = n `div` 2
  f (x,y) = (hf (x-1),hf y)
  
induceTransps n = (l,qs) where
   bs= as hff_pars nat n
   l=genericLength bs
   ps=zip [0..l-1] bs
   ls=filter (\(i,b)->(odd i) && (0==b))  ps
   rs=filter (\(i,b)->(even i) && (1==b)) ps
   qs=zipWith f ls rs where
     f (i,_) (j,_) = (i,j)
\end{code}
working as follows:
\begin{codex}
*ISO> induceTransformer 2009
(2,[(0,1),(1,3),(2,4),(4,5),(5,7),(7,8),(8,9),(9,10),(10,11)])
*ISO> encodeTransformer 2009
2803905099203873342027
\end{codex}

\begin{comment}
undoTransps (l,qs) = as nat bits (applyTransps qs bs) where
  bs=genericTake l newMem
   
applyTransps qs xs = applyPairs transp qs xs

decodeTransformer x = bs where -- as nat hff_pars bs where
  (l,t)=pepis_unpair x
  db x=2*x
  ps=as dag nat t
  l'=(db l)+(genericLength ps)+1
  bs=genericTake l' (applyTransps ps newMem)
  

ttest n = mapM_ print [(bs,ts),(bs',ts')] where
  (_,t)=induceTransps n
  bs=as hff_pars nat n
  ts=applyTransps t bs
  bs'=applyTransps t ts
  ts'=applyTransps t bs'
\end{comment}

\subsection{Encoding Finite Transducers}
One can derive encoders for finite transducers (consuming and generating
bits) from the encoding of a digraph, by borrowing a bit from each end of
an edge.

After defining:
\begin{code}
digraph2transducer = map f where
  f (x,y) = ((x',y'),(bx,by)) where
     ht z=quotRem z 2
     (x',bx)=ht x
     (y',by)=ht y
       
transducer2digraph = map g where
  g ((x',y'),(bx,by))=(x,y) where
    c b z = b+2*z
    x = c bx x'
    y = c by y'
\end{code}

we obtain the Encoder:
\begin{code}
transducer :: Encoder [(N2,N2)]
transducer = compose (Iso transducer2digraph digraph2transducer) digraph
\end{code}
working as follows:
\begin{codex}
*ISO> as transducer nat 123456789
[((0,0),(0,0)),((0,0),(0,1)),((1,0),(0,0)),((0,1),(0,0)),((0,1),(0,1)),
 ((0,1),(1,1)),((1,1),(0,1)),((1,1),(1,1)),((2,0),(0,0)),((2,0),(1,0)),
 ((2,0),(1,1)),((3,0),(0,0)),((3,0),(0,1)),((2,1),(0,0)),((2,1),(1,0)),
 ((2,1),(0,1))] 
*ISO> as nat transducer it
123456789
\end{codex}

\section{Encoding SAT problems}
Boolean Satisfiability (SAT) problems are encoded as lists of lists representing
conjunctions of disjunctions of positive or negative propositional symbols.

After defining:
\begin{code}
set2sat = map (set2disj . nat2set) where
  shift0 z = if (z<0) then z else z+1
  set2disj = map (shift0. nat2z)
  
sat2set = map (set2nat . disj2set) where
  shiftback0 z = if(z<0) then z else z-1
  disj2set = map (z2nat . shiftback0)
\end{code}
we obtain the Encoder
\begin{code}
sat :: Encoder [[Z]]
sat = compose (Iso sat2set set2sat) set
\end{code}
working as follows:
\begin{codex}
*ISO> as sat nat 2008
[[1,-1],[2],[-1,2],[1,-1,2],[-2],[1,-2],[-1,-2]]
*ISO> as nat sat it
2008
\end{codex}
Clearly this encoding can be used to generate random SAT problems out of
easier to generate random natural numbers.

\section{Solving the SAT problems}
One can actually try out the generated SAT problems by interfacing them
with a SAT solver like David Bueno's {\tt Funsat.Solver}.

First, we map our encoding to the CNF form required by the solver:
\begin{code}
toCNF :: [[Z]] -> CNF
toCNF xss = CNF nvars ncls (fromList cls) where
  xs = concat xss
  nvars = toInt (foldl max 0 (map abs xs))
  ncls = length xss
  cls = map toCls xss
  toCls = map (L . toInt)

toInt :: Z->Int
toInt x = fromIntegral x
\end{code}
The we define the function ssolve that works directly on our {\tt sat} type:
\begin{code}
ssolve :: [[Z]] -> Solution
ssolve xss = s where
  (s,_,_) = solve1 (toCNF xss)
\end{code}
Finally, using our encoder we can define a solver  working on a natural number
{\tt n} - and similarly by using an isomorphism from any other data
representation.
\begin{code}
nsolve k  = (xss,s) where
  xss=(as sat nat k)
  s=ssolve xss
\end{code}
The following examples show the associated SAT problem as well as a model
found by the solver, when the problem is satisfiable.
\begin{codex}
*ISO> nsolve 123456
([[-1,2],[1,-2],[1,2,-2],[-1,2,-2],[1,-1,2,-2],[3]],satisfiable: 1 2 3)
*ISO> nsolve 1234567
([[],[1],[-1],[1,-1,2],[1,-2],[-1,-2],[2,-2],[-1,2,-2],[1,-1,2,-2],[1,3],[2,3]],unsatisfiable)
\end{codex}
The predicates isSAT and isUNSAT can be used to test satisfiability directly on
a natural number encoding of a SAT problem:
\begin{code}
isSAT = found . snd . nsolve

isUNSAT = not . isSAT
  
found (Sat _) = True
found (Unsat _) = False
\end{code}
They can be used to collect statistics on solvability of SAT problems in
various ranges:
\begin{code}
sats xs = [x|x<-xs, isSAT x]

unsats xs = [x|x<-xs, isUNSAT x]

satStats xs = (s,u) where 
  s=genericLength (sats xs)
  u=genericLength (unsats xs)
\end{code}
On can try to sample sat/unsat statistics as follows:
\begin{codex}
*ISO> satStats [2000..3000]
(440,561)
*ISO> satStats [10000..11000]
(433,568)
*ISO> satStats [100000..101000]
(399,602)
\end{codex}

\section{An Encoder for Graph Models}
Graph models \cite{bucciarelli,berline} provide a semantics of
$\lambda$-calculus (Y-combinator included) in terms of sets of finite sets of natural numbers.
Following \cite{bucciarelli}  a {\em graph model} is a
pair $(D,p)$ where D is an infinite set and $p:D^{*}\times D \rightarrow D$ is
an injective total function. We will strengthen this to be a bijection, for the
case $D=\mathbb{N}$ as follows.
\begin{code}
gmodel2nat (set,m) = pred (fun2nat (m : (set2fun set)))
nat2gmodel n = (fun2set xs,m) where (m:xs) = nat2fun (succ n)
\end{code}
This provides the Encoder:
\begin{code}
type Gdomain= ([N],N)
gmodel :: Encoder Gdomain
gmodel = compose (Iso gmodel2nat nat2gmodel) nat
\end{code}
working as follows:
\begin{codex}
*ISO> as gmodel nat 42
([0,2,4],0)
*ISO> as nat gmodel it
42
\end{codex}
The interests of such models is that they provide an accurate
set theoretic semantics for untyped lambda calculus describing
key computational mechanisms like $\beta$-conversion and fixpoint
combinators.

\section{A mapping to a dense set: Dyadic Rationals in $[0,1)$}
So far our isomorphisms have focused on natural numbers,
finite sets and other 
discrete data types.
Dyadic rationals are fractions with denominators 
restricted to be exponents of 2.
They are a {\em dense} set in $\mathcal{R}$ i.e. they provide arbitrarily
close approximations for any real number. An interesting isomorphism to
such a set would allow borrowing things like distance or average
functions that could have interesting interpretations in symbolic or boolean
domains. It also makes sense to pick a bounded subdomain of the dyadic
rationals that can be meaningful as the range of
probabilistic boolean functions or fuzzy sets.
We will build an Encoder for Dyadic Rationals in $[0,1)$ by
providing a bijection from finite sets of natural numbers
seen this time as {\em negative} exponents of 2.
\begin{code}
dyadic :: Encoder (Ratio N)
dyadic = compose (Iso dyadic2set set2dyadic) set
\end{code}
The function {\tt set2dyadic} mimics {\tt set2nat} defined in subsection
\ref{natset}, except for the use of negative exponents and computation on
rationals.
\begin{code}
set2dyadic :: [N] -> Ratio N
set2dyadic ns = rsum (map nexp2 ns) where
  nexp2 0 = 1%2
  nexp2 n = (nexp2 (n-1))*(1%2)

  rsum [] = 0%1
  rsum (x:xs) = x+(rsum xs)
\end{code}
The function {\tt dyadic2set} extracts negative exponents of two from
a dyadic rational and it is modeled after {\tt nat2set} defined in subsection
\ref{natset}.
\begin{code}
dyadic2set :: Ratio N -> [N]
dyadic2set n | good_dyadic n = dyadic2exps n 0 where
  dyadic2exps 0 _ = []
  dyadic2exps n x = 
    if (d<1) then xs else (x:xs) where
      d = 2*n
      m = if d<1 then d else (pred d)
      xs=dyadic2exps m (succ x)
dyadic2set _ =  
  error  "dyadic2set: argument not a dyadic rational"
\end{code}
As not all rational numbers are dyadics in $[0,1)$, the predicate {\tt
good\_dyadic} is needed validate the input of {\tt dyadic2set}. 
This also ensures that {\tt dyadic2set} always terminates returning
a finite set.
\begin{code}
good_dyadic kn = (k==0 && n==1) 
  || ((kn>0%1) && (kn<1%1) && (is_exp2 n)) where 
    k=numerator kn
    n=denominator kn

    is_exp2 1 = True
    is_exp2 n | even n = is_exp2 (n `div` 2)
    is_exp2 n = False
\end{code}

Some examples of borrow/lend operations are:
\begin{code}
dyadic_dist x y = abs (x-y)

dist_for t x y =  as dyadic t 
  (borrow2 (with dyadic t) dyadic_dist x y)
dsucc = borrow (with nat dyadic) succ
dplus = borrow2 (with nat dyadic) (+)

dconcat = lend2 dyadic (++)
\end{code}
\begin{codex}
*ISO> dist_for nat  6 7
1%2
*ISO> dist_for set [1,2,3] [3,4,5]
21%64
*ISO> dsucc (3%8)
7%8
\end{codex}
Fig. \ref{f7} shows the dyadic rationals associated
to natural numbers in [0..255].

\FIG{f7}{Dyadic rationals associated to n in [0..255]}{0.40}{isof7.pdf}

\section{Encoding a Parenthesis Language}

An encoder for a parenthesis language is obtained by
combining a parser and writer. As Hereditarily Finite Functions
naturally map one-to-one to a parenthesis expression
we will choose them as target of the transformers.
\begin{code}
pars :: Encoder [Char]
pars = compose (Iso pars2hff hff2pars) hff
\end{code}

The parser recurses over a string and builds a {\tt HFF} as follows:
\begin{code}
pars2hff cs = parse_pars '(' ')' cs

parse_pars l r cs | newcs == [] = t where
  (t,newcs)=pars_expr l r cs

pars_expr l r (c:cs) | c==l = ((H ts),newcs) where 
  (ts,newcs) = pars_list l r cs
     
  pars_list l r (c:cs) | c==r = ([],cs)
  pars_list l r (c:cs) = ((t:ts),cs2) where 
    (t,cs1)=pars_expr l r (c:cs)
    (ts,cs2)=pars_list l r cs1
\end{code}
The writer recurses over a {\tt HFF} and collects
matching parenthesis pairs:
\begin{code}
hff2pars = collect_pars '(' ')'

collect_pars l r (H ns) =
  [l]++ 
    (concatMap (collect_pars l r) ns)
  ++[r] 
\end{code}
The transformations of {\tt 42} look as follows:
\begin{codex}
*ISO> as pars nat 42
"((())(())(()))"
*ISO> as hff pars it
H [H [H []],H [H []],H [H []]]
*ISO> as nat hff it
42
\end{codex}
Alternatively, by using a {\tt 0} and {\tt 1} as left and right parenthesis we
can define:
\begin{code}
bitpars2hff cs = parse_pars 0 1 cs
hff2bitpars = collect_pars 0 1

hff_pars :: Encoder [N]
hff_pars = compose (Iso bitpars2hff hff2bitpars) hff
\end{code}
working as follows:
\begin{codex}
*ISO> as hff_pars nat 2008
[0,0,0,1,0,1,1,0,1,0,0,1,1,0,1,0,1,0,1,0,1,1]
*ISO> as nat hff_pars it
2008
*ISO> as nat bits (as hff_pars nat 2008)
7690599
\end{codex}
As the last example shows, the information density of
a parenthesis representation is lower. This is expected,
given that order is constrained by balancing and content is
constrained by having the same number of {\tt 0s} and {\tt 1s}.
The following example
\begin{codex}
*ISO> map ((as nat bits) .  (as hff_pars nat)) [0..7]
[5,27,119,115,495,483,471,467]
\end{codex}
shows that this application is injective only.
Therefore a succinct representation of an abstract tree
structure can be obtained by encoding it as a
natural number as in:
\begin{codex}
*ISO> as nat pars "((()())()(())()()()())"
2008
\end{codex}
Note however, that
\begin{codex}
*ISO> as nat bits (as hff_pars nat (2^2^16))
32639
\end{codex}
while the conventional representation of the same number would
have a few thousand digits. This suggest defining:
\begin{code}
nat2parnat n = as nat bits (as hff_pars nat n)

parnat2nat n = as nat hff_pars (as bits nat n)
\end{code}
and find out that
\begin{codex}
*ISO> [x|x<-[0..2^16],nat2parnat x<x]
[8192,16384,32768,32769,49152,65536]
\end{codex}
One can see that more compact representations only happen
for a few numbers that are powers of two or ``sparse'' sums of
powers of two.
A good way to evaluate ``information density'' for an arbitrary
data type that is isomorphic to {\tt N} through one of our encoders
is to compute the total bitsize of its actual encoding over an
interval like $[0..2^{n-1}]$. For instance,
\begin{code}
hff_bitsize n= sum (map hff_bsize [0..2^n-1])

hff_bsize k=genericLength (as bits nat (nat2parnat k)) 
\end{code}
Knowing that the optimal bit representation of all numbers in $[0..2^{n-1}]$
totals $n*2^n$ ($2^n$ of them, $n$ bits each), we can define a measure of
information density for a bit-encoded parenthesis language seen as a
representation for {\tt HFF} as:
\begin{code}
info_density_hff n = (n*2^n)%(hff_bitsize n)
\end{code}
One can see that information density progressively increases to converge
to a value above half of the ``perfect'' value of {\tt 1}:
\begin{codex}
*ISO> map info_density_hff [0..12]
[0%1,1%3,4%9,12%25,1%2,80%157,16%31,112%215,
    32%61,48%91,1024%1933,2816%5297,2048%3841]
*ISO> map fromRational it
[0.0,0.3333333333333333,0.4444444444444444,0.48,0.5,
 0.5095541401273885,0.5161290322580645,0.5209302325581395,
 0.5245901639344263,0.5274725274725275,0.5297465080186239,
 0.5316216726448934,0.5331944806040094]    
\end{codex}
To compare this with the information density of hereditarily finite sets,
multisets and permutations, we can also map their structure to a bit-represented
parenthesis language by defining the encoder:
\begin{code}
pars_hf=Iso bitpars2hff hff2bitpars

hff_pars' :: Encoder [N]
hff_pars' = compose pars_hf hff'

hfs_pars :: Encoder [N]
hfs_pars = compose pars_hf hfs

hfpm_pars :: Encoder [N]
hfpm_pars = compose pars_hf hfpm

hfm_pars :: Encoder [N]
hfm_pars = compose pars_hf hfm

bhfm_pars :: Encoder [N]
bhfm_pars = compose pars_hf hfbm

bhfm_pars' :: Encoder [N]
bhfm_pars' = compose pars_hf hfbm'

hfp_pars :: Encoder [N]
hfp_pars = compose pars_hf hfp
\end{code}
and then defining:
\begin{code}
parsize_as t n = genericLength (hff2bitpars (as t nat n))

parsizes_as t m = map (parsize_as t) [0..2^m-1]
 
nat2hfsnat n = as nat bits (as hfs_pars nat n)

hfs_bitsize n= sum (map hfs_bsize [0..2^n-1])

hfs_bsize k=genericLength (as bits nat (nat2hfsnat k)) 
  
info_density_hfs n = (n*2^n)%(hfs_bitsize n)
\end{code}
The intuition that hereditarily finite functions have higher information
density than hereditarily finite sets can now be conjectured:
\begin{codex}
*ISO> map info_density_hfs [0..12]
[0%1,1%3,2%5,3%8,1%3,5%16,2%7,7%27,4%17,3%13,2%9,11%52,1%5]
*ISO> map fromRational it
[0.0,0.3333333333333333,0.4,0.375,0.3333333333333333,
 0.3125,0.2857142857142857,0.25925925925925924,0.23529411764705882,
 0.23076923076923078,0.2222222222222222,0.21153846153846154,0.2]
\end{codex}
Contrary to the case of bit-encoded HFFs, in this case
information density is decreasing for larger values - an observation
that can help with finding a simple proof for the conjecture.
More generally, such techniques suggest applications to
experimental mathematics.

Another interesting way to visualize the balanced bitstring expressions
associated to the HFF, HFM, HFS and HFP trees is to represent them as
``hills'':
\begin{code}
to_hill =scanr (\x y->y+(if 0==x then -1 else 1)) 0 

hill t n = to_hill (as t nat n)
\end{code}
\begin{codex}
*ISO> hill hff_pars 42
[0,1,2,3,2,1,2,3,2,1,2,3,2,1,0]
*ISO> hill hfm_pars 42
[0,1,2,3,2,1,2,3,4,3,2,1,2,3,2,3,2,1,0]
*ISO> hill hfs_pars 42
[0,1,2,3,2,1,2,3,2,3,4,3,2,1,2,3,2,3,4,5,4,3,2,1,0]
*ISO> hill hfp_pars 42
[0,1,2,1,2,3,2,3,4,3,2,1,2,3,4,3,2,3,2,1,2,
 3,2,1,2,3,2,3,4,3,2,3,4,3,4,5,4,3,2,1,0]
\end{codex}
Figs. \ref{hills1} and \ref{hills2} show the hills associated to {\tt 2009}.
\VFIGS{hills1}
{Hills associated to 2009}
{HFF hill}{HFM hill}{hffHill.pdf}{hfmHill.pdf}
\VFIGS{hills2}
{Hills associated to 2009}
{HFS hill}{HFP hill}{hfsHill.pdf}{hfpHill.pdf}

\section{Self-delimiting codes} \label{selfdelim}
A more precise estimate of the actual size of various bitstring representations
requires also counting the overhead for ``delimiting'' their components.
An asymptotically optimal mechanism for this is the use of a {\em universal
self-delimiting code} for instance, the {\em Elias omega code}.
To implement it, the encoder proceeds by recursively encoding length of the
string, the length of the length of the strings etc.

\begin{code}
to_elias :: N -> [N]
to_elias n = (to_eliasx (succ n))++[0]

to_eliasx 1 = []
to_eliasx n = xs where
  bs=to_lbits n
  l=(genericLength bs)-1
  xs = if l<2 then bs else (to_eliasx l)++bs
\end{code}
The decoder first rebuilds recursively the
sequence of lengths and then the actual bitstring.
It makes sense to design the decoder to extract the number
represented by the self-delimiting code from a sequence/stream 
of bits and also return what is left after the extraction.
\begin{code}
from_elias :: [N] -> (N, [N])
from_elias bs = (pred n,cs) where (n,cs)=from_eliasx 1 bs

from_eliasx n (0:bs) = (n,bs)
from_eliasx n (1:bs) = r where 
  hs=genericTake n bs
  ts=genericDrop n bs
  n'=from_lbits (1:hs)
  r=from_eliasx n' ts 

to_lbits = reverse . (to_base 2)

from_lbits = (from_base 2) . reverse
\end{code}
We obtain the Encoder:
\begin{code}
elias :: Encoder [N]
elias = compose (Iso (fst . from_elias) to_elias) nat
\end{code}
working as follows:
\begin{codex}
*ISO> as elias nat 42
[1,0,1,0,1,1,0,1,0,1,1,0]
*ISO> as nat elias it
42
*ISO> as elias nat 2008
[1,1,1,0,1,0,1,1,1,1,1,0,1,1,0,0,1,0]
*ISO> as nat elias it
2008
\end{codex}
Note that self-delimiting codes are not {\em onto} the regular language
$\{0,1\}^*$, therefore this Encoder cannot be used to map arbitrary bitstrings
to numbers.


\section{Automorphisms as Encoder transformers}

An {\em automorphism} is an isomorphism for which the source and target 
are the same. Clearly, by applying an automorphism before or after an
isomorphism we obtain a similarly typed new isomorphism i.e. we can define:
\begin{code}
after2 i j t = compose (Iso i j) t
after i t = after2 i i t
\end{code}
working as follows:
\begin{codex}
*ISO> as (after id bits) nat 2009
[0,1,0,1,1,0,1,1,1,1]
*ISO> as (after dual bits) nat 2009
[1,0,1,0,0,1,0,0,0,0]
*ISO> as (after reverse bits) nat 2009
[1,1,1,1,0,1,1,0,1,0]
*ISO> as perm nat 2009
[1,4,3,2,0,6,5]
*ISO> as (after invertPerm perm) nat 2009
[4,0,3,2,1,6,5]
\end{codex}
Dually, automorphisms can be borrowed (as one argument functions) form a
data type and used as automorphisms on another data type:
\begin{codex}
*ISO> borrow_from perm invertPerm nat 2009
3809
*ISO> borrow_from perm invertPerm nat 3809
2009
*ISO> borrow_from nat succ perm [0,1,2,3]
[0,1,3,2]
*ISO> borrow_from nat pred perm [0,1,3,2]
[0,1,2,3]
*ISO> borrow_from bits dual nat 2009
1060
*ISO> borrow_from bits dual nat 1060
2009
*ISO> borrow_from bits dual set [1,3,4,7]
[0,1,5,6,7]
*ISO> borrow_from bits dual set [0,1,5,6,7]
[1,3,4,7]
\end{codex}
Of particular interest are automorphism of $\mathbb{N}$ obtained by borrowing
from other data types, with potential applications to cryptography and data
compression. An interesting case is when such automorphisms are involutions
i.e. such the $f \circ f=id$.

Fig. \ref{isoInvert} depicts the involution on $\mathbb{N}$ obtained by
borrowing {\tt invertPerm} from {\tt perm} i.e.
\begin{code}
natInvert = borrow_from perm invertPerm nat
\end{code}

\FIG{isoInvert}{Automorphism on $\mathbb{N}$ borrowd from inverted
permutations}{0.40}{isoInvert.pdf}


Fig. \ref{isoDual} depicts the involution on $\mathbb{N}$ obtained by
borrowing {\tt dual} from {\tt bits} i.e.
\begin{code}
natDual = borrow_from bits dual nat
\end{code}

\FIG{isoDual}{Automorphism on $\mathbb{N}$ borrowd from 0-1 flipped
bitstrings}{0.40}{isoDual.pdf}

Note that automorphisms can be borrowed from any connected data type and
fairly complex transformations likely to have good {\em diffusion} and {\em
confusion} properties can be generated by their iterated compositions.

Interesting automorphisms can also be generated by combining alternative
encodings that share the same data representation. We can define
\begin{code}
auto t s = (as nat s) . (as t nat) 

autoS = auto fun fun'

autoS' = auto fun' fun

autoP = auto mset pmset

autoP' = auto pmset mset

autoH = auto hff hff'

autoH'= auto hff' hff

autoM = auto hfm hfpm

autoM' = auto hfpm hfm
\end{code}
working as follows
\begin{codex}
*ISO> map autoS [0..31]
[0,1,3,2,5,10,6,4,7,34,14,36,18,20,12,8,9,42,38,260,
 26,52,44,136,22,132,28,72,68,40,24,16]
*ISO> map autoS' [0..31]
[0,1,3,2,7,4,6,8,15,16,5,32,14,64,10,128,31,256,12,
 512,13,1024,24,2048,30,4096,20,8192,26,16384,40,32768] 
*ISO> (autoS . autoS') 2009
2009
*ISO> (autoS' . autoS) 2009
2009
*ISO> map autoH [0..31]
[0,1,3,2,7,10,6,4,5,42,14,36,22,20,12,8,15,34,46,292,30,52,
 44,136,18,148,28,72,76,40,24,16]
*ISO> map autoH' [0..31]
[0,1,3,2,7,8,6,4,15,128,5,256,14,64,10,16,31,32768,24,
 340282366920938463463374607431768211456,13,32,12,
 115792089237316195423570985008687907853269984665640564039457584007913129639936,
 30,16384,40,18446744073709551616,26,1024,20,65536]
 *ISO> (autoH . autoH') 2009
2009
*ISO> (autoH' . autoH) 2009
2009
*ISO> map autoM [0..31]
[0,1,2,3,4,5,8,7,6,9,14,11,24,17,26,15,10,
 13,20,19,34,29,44,23,48,49,74,35,124,53,80,31]
*ISO> map autoM' [0..31]
[0,1,2,3,4,5,8,7,6,9,16,11,32,17,10,15,256,13,128,19,
 18,33,64,23,12,65,14,35,512,21,65536,31]
 *ISO> (autoM . autoM') 2009
2009
*ISO> (autoM' . autoM) 2009
2009
*ISO> map autoP [0..15]
[0,1,2,3,4,5,8,7,6,9,14,11,24,17,26,15]
*ISO> map autoP' [0..15]
[0,1,2,3,4,5,8,7,6,9,16,11,32,17,10,15]
*ISO> (autoP . autoP') 2009
2009
*ISO> (autoP' . autoP) 2009
2009
\end{codex}
Given that these are automorphisms, one can expect that some values
are below and some are above the identitity function.
\begin{code}
autoLess t s m = filter (\i->auto t s i<i) [0..2^m-1] 
\end{code}
This is indeed the case
\begin{codex}
*ISO> autoLess fun' fun 6
[3,5,10,14,18,20,26,28,34,36,38,40,42,44,46,50,52,60]
*ISO> autoLess fun fun' 6
[3,7,8,14,15,16,24,30,31,32,40,58,62,63]
*ISO> autoLess hff hff' 5
[3,7,8,14,15,16,24,30,31]
*ISO> autoLess hff' hff 5
[3,7,10,14,20,22,28,30]
\end{codex}

\subsection{Using permutations as encoders}

One can define a simple encoder/decoder using a permutation associated to a
natural number as follows:
\begin{code}
pencode = pcode id
pdecode = pcode invertPerm

pcode f k n = n' where
  ps=as perm nat k
  ps'=f ps
  l=genericLength ps'
  ns=to_tuple l n
  ns'=applyPerm ps' ns
  n'=from_tuple ns'
  
applyPerm ps xs = [xs!!(fromIntegral p)|p<-ps]

invertPerm ps = snd (unzip (sort (zip ps [0..])))
\end{code}
working as follows:
\begin{codex}
*ISO> pencode 1234 567890 
599366
*ISO> pdecode 1234 it
567890
\end{codex}
Note also that the decoder and encoder can trade roles:
\begin{codex}
*ISO> pdecode 1234 567890
795992
*ISO> pencode 1234 it
567890
\end{codex}
and that they can be cascaded as in:
\begin{codex}
*ISO> ((pencode 123) . (pencode 345))  10203040
19455458
*ISO> ((pdecode 345) . (pdecode 123))  it
10203040
\end{codex}
It would be interesting to see if these operations can be used as building
blocks for applications to cryptography.

Injective endomporphisms from $\mathbb{N} \to \mathbb{N}$ are common inhabitants
of the mathematics ontology.
An interesting fast growing injective endomporphism is obtained from the
permutations induced by gray codes.
\begin{code}
grayPerm n = p where 
  ps=map (as gray nat) [0..2^n-1]
  p=as nat perm ps
\end{code}
\begin{codex}
*ISO> map gray2perm [0..5]
[1,2,11,6056,1407956705291,8506124708021000379449747639735336]
\end{codex}

\subsection{Deriving automorphisms on hereditarily finite structures}

Given an automorphism  $\mathbb{N} \to \mathbb{N}$ one can derive
hylomorphisms similar to {\tt hff, hfm etc.} We obtain the encoders:

\begin{code}
ghff :: Encoder T
ghff = compose (hylo gray) gray

gray2fun = nat2fun . gray2nat
fun2gray = nat2gray . fun2nat 

gray_fun = Iso gray2fun fun2gray

ghff' :: Encoder T
ghff' = compose (hylo gray_fun) gray

gray2set = nat2set . gray2nat
set2gray = nat2gray . set2nat 

gray_set = Iso gray2set set2gray

ghfs :: Encoder T
ghfs = compose (hylo gray_set) gray
\end{code}
working as follows
\begin{codex}
*ISO> as ghff nat 2009
H [H [],H [H [],H []],H [],H [H []],H [],H [],H [],H []]
*ISO> as ghff' nat 2009
H [H [],H [],H [H []],H [H [],H []],H [H [],H []],H []]
*ISO> as ghfs nat 2009
H [H [],H [H []],H [H [H []]],H [H [H [],
   H [H []]]],H [H [H []],H [H [],H [H []]],H [H [H []]]],
   H [H [H [],H [H []]],H [H [H []]]]]
*ISO> as nat ghfs it
2009
\end{codex}

\subsection{Passkey Induced Automorphisms}

Automorphisms on {\tt string} can be used as ``boxes'' for 
cryptographic algorithms, provided that they exhibit good diffusion and
confusion properties.

\begin{code}
pkencode auto passkey plaintext = cyphertext where
  k=as nat string passkey
  p=as nat string plaintext
  c=auto k p
  cyphertext=as string nat c

simpleEncode k p = k `xor` (as gray nat p)
simpleDecode k q = as nat gray (k `xor` q)
\end{code}

\begin{codex}
*ISO> pkencode simpleEncode "Alice" "Bob likes beer"
"Mc%&WlFx|QN^yV"
*ISO> pkencode simpleDecode "Alice" it
"Bob likes beer"
\end{codex}

\section{Encoding DNA}
We have covered so far encodings for ``artificial entities'' used in various
fields. We will now add an encoding of ``natural origin'', DNA bases and
strands. While it is an (utterly) simplified model of the real thing, it captures
some essential algebraic properties of DNA bases and strands.

We start with a DNA data type, following \cite{algDNA,haskellDNA}:
\begin{code}
data Base = Adenine | Cytosine | Guanine | Thymine 
  deriving(Eq,Ord,Show,Read)

type DNA = [Base]
\end{code}
We will encode/decode the DNA base alphabet as follows:
\begin{code}
alphabet2code Adenine = 0
alphabet2code Cytosine = 1
alphabet2code Guanine = 2 
alphabet2code Thymine = 3

code2alphabet 0 = Adenine
code2alphabet 1 = Cytosine
code2alphabet 2 = Guanine 
code2alphabet 3 = Thymine
\end{code}
The mapping is simply a symbolic variant of conversion to/from base 4:
\begin{code}
dna2nat  = (from_base 4) . (map alphabet2code)

nat2dna = (map code2alphabet) . (to_base 4)
\end{code}
We can now define a decoder for base sequences as follows:
\begin{code}
dna :: Encoder DNA
dna = compose (Iso dna2nat nat2dna)  nat
\end{code}

A first set of DNA operations act on base sequences.
The transformation between complements looks as follows:  
\begin{code}
dna_complement :: DNA -> DNA
dna_complement = map to_compl where
  to_compl Adenine = Thymine
  to_compl Cytosine = Guanine
  to_compl Guanine = Cytosine
  to_compl Thymine = Adenine
\end{code}
Reversing is just list reversal.
\begin{code}
dna_reverse :: DNA -> DNA
dna_reverse = reverse
\end{code}
As reversal and complement are independent operations
their composition is commutative - we can pick
reversing first and then complementing:
\begin{code}
dna_comprev :: DNA -> DNA
dna_comprev = dna_complement . dna_reverse
\end{code}
The following examples show interaction of DNA codes
with other data types and their operations:
\begin{codex}
*ISO> as dna nat 2008
[Adenine,Guanine,Cytosine,Thymine,Thymine,Cytosine]
*ISO> borrow (with dna nat) dna_reverse 42
42
*ISO> borrow (with dna nat) dna_reverse 2008
637
*ISO> borrow (with dna nat) dna_complement 2008
2087
*ISO> borrow (with dna nat) dna_comprev 2008
3458
*ISO> borrow (with dna bits) 
        dna_comprev [1,0,1,0,1,1,0,1,0,1]
[1,1,1,0,1,0,0,0,0,1,1]
\end{codex}
Note that each of these DNA operations induces
a bijection $\mathbb{N} \rightarrow \mathbb{N}$.

Like signed integers, DNA strands have ``polarity'' - their direction matters:
\begin{code}
data Polarity =  P3x5 | P5x3 
  deriving(Eq,Ord,Show,Read)

data DNAstrand = DNAstrand Polarity DNA 
  deriving(Eq,Ord,Show,Read)
\end{code}
Polarity can be easily encoded as parity even/odd:
\begin{code}
strand2nat (DNAstrand polarity strand) = 
  add_polarity polarity (dna2nat strand) where 
    add_polarity P3x5 x = 2*x
    add_polarity P5x3 x = 2*x-1
    
nat2strand n =
  if even n 
     then DNAstrand P3x5 (nat2dna (n `div` 2))
     else DNAstrand P5x3 (nat2dna ((n+1) `div` 2))
\end{code}
We can now define an Encoder for DNA strands:
\begin{code}
dnaStrand :: Encoder DNAstrand
dnaStrand = compose (Iso strand2nat nat2strand) nat
\end{code}
Two additional operations lift DNA sequences to strands with polarities:
\begin{code}
dna_down :: DNA -> DNAstrand
dna_down = (DNAstrand P3x5) . dna_complement

dna_up :: DNA -> DNAstrand
dna_up = DNAstrand P5x3
\end{code}
We can now lend or borrow operations as follows:
\begin{codex}
*ISO> as dnaStrand nat 1234
DNA P3x5 [Cytosine,Guanine,Guanine,Cytosine,Guanine]
*ISO> lend (with dnaStrand nat) succ 
   (DNAstrand P5x3 [Adenine,Cytosine,Guanine,Thymine])
DNAstrand P5x3 [Cytosine,Cytosine,Guanine,Thymine]
\end{codex}

The DoubleHelix is a stable combination of two complementary
strands. This built-in redundancy protects against unwanted
mutations.
\begin{code}
data DoubleHelix = DoubleHelix DNAstrand DNAstrand
   deriving(Eq,Ord,Show,Read)

dna_double_helix :: DNA -> DoubleHelix
dna_double_helix s = 
  DoubleHelix (dna_up s) (dna_down s)
\end{code}
We can now generate a double helix from a natural number:
\begin{codex}
*ISO> dna_double_helix (nat2dna 33)
DoubleHelix 
  (DNAstrand P5x3 [Cytosine,Adenine,Guanine])
  (DNAstrand P3x5 [Guanine,Thymine,Cytosine])
\end{codex}
This can be used for generating random instances of double helixes
by reusing a random generator for natural numbers.

\section{Testing It All}
We will now describe
a random testing mechanism
to validate our Encoders.

While QuickCheck 
\cite{DBLP:journals/sigplan/ClaessenH02}
provides an elegant general purpose
random tester, it would require
writing a specific adaptor for each isomorphism.
We will describe here a shortcut through
a few higher order combinators.

First, we build a simple random generator for $nat$
\begin{code}
rannat = rand (2^50)

rand :: N->N->N
rand max seed = n where 
  (n,g)=randomR (0,max) (mkStdGen (fromIntegral seed))   
\end{code}

We can now design a generic random test for {\em any}
Encoder as follows:
\begin{code}
rantest :: Encoder t->Bool
rantest t = and (map (rantest1 t) [0..255])

rantest1 t n = x==(visit_as t x) where  x=rannat n

visit_as t = (to nat) . (from t) . (to t) . (from nat) 
\end{code}
Note that in {\tt rantest1}, {\tt visit\_at} starts
with a random natural number from which it generates
its test data of a given type. After testing the encoder,
the result is brought back as a natural number that
should be the same as the original random number.

We can now implement our tester {\tt isotest} that in a few
seconds goes over of thousands of test cases and aggregates the result
with a final {\tt and}:
\begin{code}
isotest = and (map rt [0..25])

rt 0 = rantest nat
rt 1 = rantest fun
rt 2 = rantest set
rt 3 = rantest bits
rt 4 = rantest funbits
rt 5 = rantest hfs
rt 6 = rantest hff
rt 7 = rantest uhfs
rt 8 = rantest uhff
rt 9 = rantest perm
rt 10 = rantest hfp
rt 11 = rantest nat2
rt 12 = rantest set2
rt 13 = rantest clist
rt 14 = rantest pbdd
rt 15 = rantest bdd
rt 16 = rantest rbdd
rt 17 = rantest digraph
rt 18 = rantest graph
rt 19 = rantest mdigraph
rt 20 = rantest mgraph
rt 21 = rantest hypergraph
rt 22 = rantest dyadic
rt 23 = rantest string
rt 24 = rantest pars
rt 25 = rantest dna
\end{code}
The empirical correctness test of the ``whole enchilada'' follows:
\begin{codex}
*ISO> isotest
True
\end{codex}
suggesting that the probability of having errors in
the code described so far is extremely small.

\section{Applications}
Besides their utility as a uniform basis for a general purpose
data conversion library, let us point out
some specific applications of our isomorphisms.

\subsection{Combinatorial Generation}
A free combinatorial generation algorithm (providing
a constructive proof of recursive enumerability)
for a given structure is obtained simply through
an isomorphism from $nat$:
\begin{code}
nth thing = as thing nat
nths thing = map (nth thing)
stream_of thing = nths thing [0..]
\end{code}
\begin{codex}
*ISO> nth set 42
[1,3,5]

*ISO> nth bits 42
[1,1,0,1,0]

*ISO> take 3 (stream_of hfs)
[H [],H [H []],H [H [H []]]]

*ISO> take 3 (stream_of bdd)
[BDD 0 B0,BDD 0 B1,BDD 1 (D 0 B0 B0)]
\end{codex}

\subsection{Random Generation}
Combining {\tt nth} with a random generator for $nat$
provides free algorithms for random generation of
complex objects of customizable size:
\begin{code}
ran thing seed largest = head (random_gen thing seed largest 1)

random_gen thing seed largest n = genericTake n
  (nths thing (rans seed largest))
  
rans seed largest = 
    randomRs (0,largest) (mkStdGen seed)
\end{code}
For instance
\begin{codex}
*ISO> random_gen set 11 999 3
[[0,2,5],[0,5,9],[0,1,5,6]]
\end{codex}
generates a list of 3 random sets.

For instance
\begin{codex}
*ISO>ran digraph 5 (2^31)
[(1,0),(0,1),(2,1),(1,3),(2,2),(3,2),(4,0),(4,1),
 (5,1),(6,0),(6,1),(7,1),(5,3),(6,2),(6,3)]
 
*ISO> ran hfs 7 30
H [H [],H [H [],H [H []]],H [H [H [H []]]]]
*ISO> ran dnaStrand 1 123456789

DNAstrand P5x3 [Guanine,Thymine,Guanine,Cytosine,
  Cytosine,Thymine,Thymine,Thymine,Thymine,
  Adenine,Thymine,Cytosine,Cytosine]
\end{codex}
generate a random digraph, a hereditarily finite set and a DNA strand.

Random generator for various data types are useful for further automating
test generators in tools like QuickCheck 
\cite{DBLP:journals/sigplan/ClaessenH02}
by generating customized random tests.

An interesting other application is generating random problems or programs of a
given type and size.
For instance
\begin{codex}
*ISO> ran sat 8 (2^31)
[[-1],[1,-1],[-1,2],[1,-1,2],[-2],[1,-2],[-1,-2],[1,-1,-2],
[2,-2],[1,2,-2],[-1,2,-2],[3],[1,-1,3],[1,-1,2,3],[1,-2,3],
[-1,-2,3],[2,-2,3],[1,2,-2,3],[-1,2,-2,3]]
 
*ISO> ran clist 8 12345
Cons (Atom 0) (Cons (Cons (Atom 0) (Atom 0)) (Atom 100))
\end{codex}
generate, respectively, a random SAT-problem and a random {\tt Cons}-list.

\subsection{Succinct Representations}
Depending on the information theoretical density of
various data representations as well as on the
constant factors involved in various data structures,
significant data compression can be achieved by
choosing an alternate isomorphic representation,
as shown in the following examples:

\begin{codex}
*ISO> as hff hfs (H [H [H []],H [H [],
        H [H []]],H [H [],H [H [H []]]]])
H [H [H []],H [H []],H [H []]]
*ISO> as nat hff (H [H [H []],H [H []],H [H []]])
42
*ISO> as fun bits [0,1,0,0,0,0,0,0,0,0,0]
[0,10]
*ISO> as rbdd hfs (H [H [],H [H [],H [H []]],
                      H [H [H []],H [H [H []]]]])
BDD 3 (D 1 B1 B0)
*ISO> as hff bdd (BDD 3 (D 2 
        (D 1 (D 0 B1 B0) (D 0 B0 B1)) 
        (D 1 (D 0 B1 B1) (D 0 B1 B1))))
H [H [],H [H [],H [],H []]]

\end{codex}

In particular, mapping to efficient arbitrary length
integer implementations (usually C-based
libraries), can provide more compact
representations or improved performance
for isomorphic higher level 
data representations. Alternatively,
lazy representations as provided by
functional binary numbers or BDDs,
for very large
integers encapsulating results of some
computations might turn out to be more
effective space-wise or time-wise.

We can compare representations sharing
a common datatype to conjecture about their
asymptotic information density.

\subsection{Experimental Mathematics}

\subsubsection{Comparing compactness of representations}

For instance, after defining:
\begin{code}
length_as t = fit genericLength (with nat t)
sum_as t = fit sum (with nat t)
size_as t = fit tsize (with nat t)
\end{code}
one can conjecture that finite functions are more compact than
permutations which are more compact than sets asymptotically
\begin{codex}
*ISO> length_as set 123456789012345678901234567890
54
*ISO> length_as perm 123456789012345678901234567890
28
*ISO> length_as fun 123456789012345678901234567890
54
*ISO> sum_as set 123456789012345678901234567890
2690
*ISO> sum_as perm 123456789012345678901234567890
378
*ISO> sum_as fun 123456789012345678901234567890
43
\end{codex}
One might observe that the same trend applies also
to their hereditarily finite derivatives:
\begin{codex}
*ISO> size_as hfs 123456789012345678901234567890
627
*ISO> size_as hfp 123456789012345678901234567890
276
*ISO> size_as hff 123456789012345678901234567890
91
\end{codex}
While confirming or refuting this conjecture is beyond the
scope of this paper, the affirmative case would imply,
interestingly, that ``order'' (permutations) has
asymptotically higher information density than ``content'' (sets),
and explain why finite functions (that involve both) dominate
data representations in various computing fields. 

Based on the same experiment, reduced BDDs
(especially if one implements sharing, as computed by {\tt robdd\_size})
also provide relatively compact representations:
\begin{codex}
*ISO> bdd_size $ as bdd 
        nat 123456789012345678901234567890
256
*ISO> bdd_size $ as rbdd 
        nat 123456789012345678901234567890
144
*ISO> robdd_size $ as rbdd 
         nat 123456789012345678901234567890
39
\end{codex}
%$
Figures \ref{f8}, \ref{f9}, \ref{f10} compare the sizes of bitstring,
BDD, HFF, HFS, HFP representations, 
first with the most succinct ones  (bitstring, BDDs, HFF) grouped
together in Fig. \ref{f8}, 
then the less succinct ones (HFS and HFP) in Fig. \ref{f9} 
and finally all representations together for
{\tt n} in the larger interval $[0..2^{16}-1]$.

\FIG{f8}{Comparison of curve1=Bit, curve2=BDD and curve3=HFF sizes}
{0.40}{isof8.pdf}

\FIG{f9}{Comparison of curve1=HFS and curve1=HFP sizes}{0.40}{isof9.pdf}

\FIG{f10}
{Comparison of all representation sizes at a larger scale}
{0.40}{isof10.pdf}

It is also interesting to observe the ability of some representations to
express huge numbers that normally overflow computer memory 
but which are genuinely ``low complexity'' as a result
of a small numbers of simple computational steps 
that generate them. 

For instance,
\begin{codex}
 *ISO> map (as nat pars) 
     [ "()","(())","((()))","(((())))", "((((()))))","(((((())))))"]
 [0,1,2,4,16,65536]
*ISO> as hff pars "((()))"
H [H [H []]]
\end{codex}
shows that parenthesis sequences (structurally isomorphic to hereditarily finite
functions) can represent succinctly the fast growing but low complexity series
$a_n=2^{2^n}$. Clearly, terms of the series would exhaust computer memory quite
quickly using a conventional bitvector based arbitrary size integer
representation! This suggest the usefulness of a {\em universal}
possibly lazy ``shapeshifting'' algorithm, that can decide on 
the most efficient data representation
automatically, using size estimates, at the time when
data is actually constructed.

\subsubsection{Sparseness criteria}

As a first step, one can introduce a ``sparseness criteria'' by comparing
the size of a representation {\tt f} with the size of the self-delimiting
Elias omega code.

One can obtain an encoding of such sequences by encoding its length and then
encoding each term, parametrized by a function $f:\mathbb{N} \rightarrow [\mathbb{N}]$:
\begin{code}
nat2self f n = (to_elias l) ++ concatMap to_elias ns where
  ns = f n
  l=genericLength ns
  
nat2sfun n = nat2self (as fun nat) n   
\end{code}
This function is injective (but not onto!) and its action can be reversed
by first decoding the length $l$ and then extracting self delimited sequences 
$l$ times.
\begin{code}
self2nat g ts = (g xs,ts') where 
  (l,ns) = from_elias ts
  (xs,ts')=take_from_elias l ns

  take_from_elias 0 ns = ([],ns) 
  take_from_elias k ns = ((x:xs),ns'') where
     (x,ns')=from_elias ns
     (xs,ns'')=take_from_elias (k-1) ns'
  
sfun2nat ns = xs where
  (xs,[])=self2nat (as nat fun) ns
\end{code}
We obtain the Encoder:
\begin{code}
sfun :: Encoder [N]
sfun = compose (Iso sfun2nat nat2sfun) nat
\end{code}
working as follows:
\begin{codex}
*ISO> as sfun nat 42
[1,0,1,0,0,0,1,0,0,1,0,0,1,0,0]
*ISO> as nat sfun it
42
\end{codex}

A simple concept of sparseness is derived by comparing the size of a
self-delimiting code for a number {\tt n} vs. the size of its
self-delimiting representation as a finite sequence, finite set or  finite
permutation as shown in Fig. \ref{f11a}, computed as follows:
\begin{code}
linear_sparseness_pair t n = 
  (genericLength (to_elias n),genericLength (nat2self (as t nat) n))

linear_sparseness f n = x/y where (x,y)=linear_sparseness_pair f n 
\end{code}

\FIG{f11a}
{Sparseness measures with curve1=fun, curve2=set, curve3=perm up to $2^7$} 
{0.40}{isof11a.pdf}

We can also extend this comparison the hereditarily finite representations,
which, as a pleasant surprise,  turn out to provide self-delimiting codes.
\begin{code}
sparseness_pair f n = 
  (genericLength (to_elias n),genericLength (as f nat n))

sparseness f n = x/y where (x,y)=sparseness_pair f n 
\end{code}

One can then compare (self-delimiting) parenthesis language representations for
hereditarily finite encoders provided by HFF, HFS, HFP and discover the
``peaks'' of sparseness as shown in Fig. \ref{f11} and \ref{f12}.

\FIG{f11}
{Sparseness measures with curve1=HFF, curve2=HFS, curve3=HFP up to $2^8$} 
{0.40}{isof11.pdf}

\FIG{f12}
{Sparseness measures with curve1=HFF curve2=HFS, curve3=HFP up to $2^{14}$} 
{0.40}{isof12.pdf}
 
\subsubsection{A new self-delimiting code}

While the HFF representation is generally less compact than Elias omega code,
its simplicity suggest it as a possibly useful self-delimiting code,
especially interesting for streams of ``sparse'' values, as shown in Fig.
\ref{f14}.

\FIG{f14}
{Comparison of codes: curve1=Undelimited curve2=Elias, curve3=HFF up to $2^{7}$} 
{0.40}{isof14.pdf}
One can collect values that have smaller HFF codes than Elias omega codes i.e.
``sparse numbers'' with:
\begin{code}
sparses_to m = [n|n<-[0..m-1],
  (genericLength (as hff_pars nat n)) 
  <
  (genericLength (as elias nat n))]
\end{code}
working as follows
\begin{codex}
ISO> sparses_to (2^11)
[15,16,17,24,32,64,65,96,128,129,192,256,257,258,259,320,384,
 385,448,512,513,514,515,516,517,518,519,520,544,576,640,641,704,768,
 769,770,771,832,896,897,960,1024,1025,1026,1027,1028,1029,1030,1031,
 1032,1088,1152,1280,1281,1408,1536,1537,1538,1539,1664,1792,1793,1920]
\end{codex}
and notice that the list collects an unusually large number of various popular
memory chip and computer screen sizes. Figure \ref{f15} shows distribution of
``sparse numbers'' in $[0..2^{18}]$.

\FIG{f15}
{Sparse numbers in $[0..2^{18}]$, x=nth sparse number, y=its value} 
{0.40}{isof15.pdf}


\subsubsection{Primes and Pairing Functions}
Products of two prime numbers have the interesting property that they are
special a case where no information is lost by multiplication in the sense of
\cite{DBLP:journals/tit/Pippenger05}. Indeed, in this case multiplication is
reversible, i.e. the two factors can be recovered given the product. 
As the product is comparatively easy to compute, while in case of large primes
factoring is believed intractable, this property has well-known uses in
cryptography.
Given the isomorphism between natural numbers and primes mapping a prime to its
position in the sequence of primes, one can transport pairing/unpairing
operations to prime numbers
\begin{code}
ppair pairingf (p1,p2) | is_prime p1 && is_prime p2 = 
  from_pos_in ps (pairingf (to_pos_in ps p1,to_pos_in ps p2)) where 
    ps = primes
 
punpair unpairingf p | is_prime p = (from_pos_in ps n1,from_pos_in ps n2) where 
  ps=primes
  (n1,n2)=unpairingf (to_pos_in ps p)
\end{code}
working as follows:
\begin{codex}
*ISO> ppair bitpair (11,17)
269
*ISO> punpair bitunpair it
(11,17)
\end{codex}
Clearly, this defines a bijection $f : Primes \times Primes \rightarrow Primes$
that is tempting to compare with the product of two primes. 
Figs. \ref{isoppairs} and \ref{isomsetprimes} shows the surfaces
generated by products and multiset pairings of primes. While both commutative
operations are reversible and likely to be asymptotically equivalent in
terms of information density, one can notice the much smoother transition in the case
of lossless multiplication.
\FIG{isoppairs}
{Lossless multiplication of primes}
{0.40}{isoppairs.pdf}

\FIG{isomsetprimes}
{Lossless multiset pairing of primes}
{0.40}{isomsetprimes.pdf}

We have seen that recursive application of the unpairing function {\tt
bitunpair} provided an isomorphism between natural numbers and BDDs. 
Given an {\em unpairing function} {$u:\mathbb{N} \rightarrow \mathbb{N} \times \mathbb{N}$} and a
predicate {\tt p(n)} over the set of natural numbers, it makes sense to
investigate subsets of $\mathbb{N}$ such that if {\tt p} holds for {\tt n} then it also
holds after applying the unpairing function {\tt u} to {\tt n}. More
interestingly, one can look at subsets for which this property holds recursively.

Assuming a prime recognizer {\tt is\_prime} and a generator {\tt primes} 
for the stream of prime numbers (see Appendix), we can define:
\begin{code}
hyper_primes u = [n|n<-primes, all_are_primes (uparts u n)] where
  all_are_primes ns = and (map is_prime ns)
  
uparts u = sort . nub . tail . (split_with u) where
    split_with _ 0 = []
    split_with _ 1 = []
    split_with u n = n:(split_with u n0)++(split_with u n1) where
      (n0,n1)=u n  
\end{code}
working as follows:
\begin{codex}
*ISO> take 20 (hyper_primes bitunpair)
[2,3,5,7,11,13,17,19,23,29,31,43,47,59,71,79,83,89,103,139]
*ISO> take 20 (hyper_primes pepis_unpair)
[2,3,5,7,11,13,19,23,29,31,43,53,59,107,127,173,223,251,311,347]
\end{codex}
This leads to the following conjectures, in increasing order of
generality:
\begin{conj}
The sets generated by (hyper\_primes bitpair) and (hyper\_primes pepis\_unpair)
are infinite.
\end{conj}

\begin{conj}
If {\tt u} is a bijection from  $u:\mathbb{N} \rightarrow \mathbb{N} \times \mathbb{N}$ such that:
\begin{enumerate}
\item if $n>1$ and $u~n = (n_0,n_1)$ then $n_0 < n$ and $n_1<n$
\item  {\tt p} is a
predicate on $\mathbb{N}$ such that $P=\{n:p(n)\}$ is infinite
\end{enumerate}
then the set $P \cap \{n : {uparts}~u~n\}$ is also infinite.
\end{conj}

Figure \ref{isop12} % and \ref{isop2} 
shows the complete unpairing graph for two
hyper-primes obtained with {\tt bitunpair}.

%\FIG{isop1}{Unpairing graph for hyper-prime 1783}{0.60}{isop1.pdf}
%\FIG{isop2}{Unpairing graph for hyper-prime 2109167}{0.60}{isop2.pdf}

\VFIGS{isop12}
{{\tt mset\_unpair} hyper-primes}
{1783}{2109167}{isop1.pdf}{isop2.pdf}

It is interesting to compare the action of a pairing function on natural
numbers with its action on primes and
hyper-primes with products. Clearly products are not reversible, except when numbers are primes,
while pairing functions are always reversible. To factor in the fact that
products commute while pairing functions do not, we have considered $2xy$
instead of $xy$.

Figures %\ref{isopairs}, 
\ref{isoprimes} and \ref{isohypers} show this
comparison.

%\FIG{isopairs}{Pairing vs. 2xy}{0.40}{isopairs.pdf}
\FIG{isoprimes}{Pairing of primes vs. 2xy}{0.40}{isoprimes.pdf}
\FIG{isohypers}{Pairing of hyper-primes vs. 2xy}{0.40}{isohypers.pdf}

\clearpage

\subsubsection{Hyper-primes and Fermat primes}
One could expect to model more closely the behavior of primes and products by
focusing on commutative functions like the multiset pairing function
{\tt mset\_pair}:
\begin{codex}
*ISO> take 16 (hyper_primes mset_unpair)
[2,3,5,13,17,113,173,257,10753,17489,34897,34961,43633,43777,65537,142781101]
\end{codex}
We remind that:
\begin{df}
A Fermat-prime is a prime of the form $2^{2^n}+1$ with $n>0$.
\end{df}
Fig. \ref{fermat} shows a hyper-prime that is also a Fermat prime
and a hyper-prime that is not a Fermat prime.

\VFIGS{fermat}
{{\tt mset\_unpair} hyper-primes}
{Fermat prime}{Non-Fermat prime}{isofermat.pdf}{isonfermat.pdf}

%\FIG{isofermat}{A Fermat hyper-prime}{0.40}{isofermat.pdf}
%\FIG{isonfermat}
%{A hyper-prime that is not a Fermat prime}
%{0.40}{isonfermat.pdf}

This time a more interesting conjecture emerges.
We can now state that:
\begin{conj}
All Fermat primes are {\tt mset\_unpair} induced hyper-primes.
\end{conj}
We will just observe that this would follow from
the widely believed conjecture that there the only Fermat primes are
[3,5,17,257,65537] as these 5 primes are indeed on our list of
{\tt mset\_unpair} hyperprimes.

In the event of the alternative, we will now state:
\begin{prop} \label{pfermat}
If there are Fermat primes other than [3,5,17,257,65537] then there are
Fermat primes that are not  {\tt mset\_unpair} hyper-primes.
\end{prop}
To prove Prop. \ref{pfermat} we need a few additional results.
First, the following known fact, implying that we only need to prove that there
are primes of the form $2^{2^n}+1$ that are not hyper-primes.
\begin{lem}
If $n>0$ and $2^n+1$ is prime then $n$ is a power of $2$. 
\end{lem}
It is easy to prove, from the definition of {\tt mset\_pair} that:
\begin{lem}
\begin{equation}
mset\_pair~(2^{2^n}+1,2^{2^n}+1) \equiv 2^{2^{n+1}}+1
\end{equation}
\end{lem}
Indeed, from the identity \ref{mseteq} we obtain
\begin{equation}
mset\_pair (a,a) \equiv bitpair (a,0)
\end{equation}
and then observe that from \ref{biteq} it follows that
\begin{equation}
bitpair (2^{2^n}+1,0) \equiv 2^{2^{n+1}}+1
\end{equation}
We can now prove Prop. \ref{fermat}.
If $2^{2^{n+1}}+1$ is a Fermat prime that is also a
hyper-prime, then $2^{2^{n}}+1$ would be also a Fermat prime that is hyper-prime.
This would form a descending sequence of consecutive Fermat primes - a
contradiction, given that it has been proven (by Leonhard Euler in 1732) that
for instance, $2^{32}+1 = 641 * 6,700,417$ is not a prime.

\subsection{A surprising ``free algorithm'': strange\_sort}
A simple isomorphism like
{\tt nat\_set} can exhibit
interesting properties as a building block of more intricate mappings
like Ackermann's encoding, but let's also note a (surprising to us)
``free algorithm'' -- sorting a list of distinct elements without
explicit use of comparison operations:
\begin{code}
strange_sort = (from nat_set) . (to nat_set)
\end{code}
\begin{codex}
*ISO> strange_sort [2,9,3,1,5,0,7,4,8,6]
[0,1,2,3,4,5,6,7,8,9]
\end{codex}
This algorithm emerges as a consequence of the commutativity of
addition and the unicity of the decomposition of
a natural number as a sum of powers of $2$.
The cognoscenti might notice that
such surprises are not totally unexpected
in the world of functional programming.
In a different context, they
go back as early as 
Wadler's Free Theorems \cite{wadler:theor}.
In a similar way, to sort sequences with repeated elements one can write
\begin{code}
strange_sort' = (to mset) . (from mset)
strange_sort'' = (as mset nat) . (as nat mset)
\end{code}
\begin{codex}
*ISO> strange_sort' [2,4,1,1,0,3,17,1.4]
[0,1,1,1,2,3,4,4,17]
*ISO> strange_sort'' [2,4,1,1,0,3,17,1,4]
[0,1,1,1,2,3,4,4,17]
\end{codex}

\subsection{Circuit Minimization}
Let us consider the classic problem of synthesizing a half adder, composed
of an XOR (\verb~^~) and an AND  (\verb~*~) function. We can combine
the two functions with an if-then-else with selector variable A to
obtain: \verb~ITE(A,B^C,B*C)~ with the following truth table:
\begin{codex}
[0,0,0]:0
[0,0,1]:0
[0,1,0]:0
[0,1,1]:1
[1,0,0]:0
[1,0,1]:1
[1,1,0]:1
[1,1,1]:0
\end{codex}
Note that this {\tt 3} argument single output function (encoded as
the natural number {\tt 22} by reading its value column in binary), fuses the
two operations with the upper half of the truth table representing 
the {\tt AND} and the lower half representing the {\tt XOR}.
When running {\tt to\_min\_bdd} on this function we obtain:
\begin{codex}
ISO> from_base 2 [0,1,1,0, 1,0,0,0]
22
*ISO> to_min_bdd 3 22
BDD 3 (D 0 
  (D 1 (D 2 B0 B1) (D 2 B1 B0)) 
              (D 1 (D 2 B1 B0) B0))
\end{codex}



\subsection{Other Applications}
A fairly large number of useful algorithms in fields 
ranging from data compression, coding theory and cryptography 
to compilers, circuit design and computational complexity
involve bijective functions between heterogeneous data
types. Their systematic encapsulation in a generic API
that coexists well with strong typing can bring 
significant simplifications to various software modules
with the added benefits of reliability and easier 
maintenance.
In a Genetic Programming context \cite{koza92} the use 
of isomorphisms between bitvectors/natural numbers 
on one side, and trees/graphs representing HFSs, HFFs on the other side, 
looks like a promising phenotype-genotype connection.
Mutations and crossovers in a data type close to the problem
domain are transparently mapped to numerical domains
where evaluation functions can be computed easily.
In particular, ``biological proven'' encodings like 
DNA strands are likely to provide interesting 
genotypes implementations. 
In the context of Software Transaction Memory implementations
(like Haskell's STM \cite{DBLP:journals/cacm/HarrisMJH08}),
encodings through isomorphisms are subject to efficient
shortcuts, as undo operations in case of transaction failure
can be performed by applying inverse transformations without
the need to save the intermediate chain of
data structures involved.


\begin{comment}
\section{Limitations and Open Problems}
At a first look, it may seem that we can tweak the pairing/unpairing-based
encoder for finite digraphs to encode finite categories.
In the case of the free category generated by a digraph
there's actually nothing to do. Given that morphisms are
freely generated as finite paths between vertices,
the category can be succinctly encoded
without requiring any additional information
beyond the encoding of its digraph generator.

However, to encode arbitrary finite categories
one should be able to distinguish
morphisms that can exist between two objects
while keeping in mind that the encoding of morphisms
should reflect associativity and existence of and
identity morphism for each object.

As finite posets and finite topologies are instances of
finite categories, it looks like finding a natural number
encoding for them could be comparable to
the enumeration problem for finite posets or finite topologies,
for which only values for small $n$ and
asymptotic results are known at this time.

We will sketch here a weaker solution that only provides
a ``G\"{o}del numbering'' for categories, i.e.
an injective???? only function to {\tt N}.
We will represent morphisms as sequences of
natural numbers, with the assumption that
the morphism's unique identity is given by
its position in the sequence. Identical
values in different positions indicate
different morphisms between the same objects.
We will use unpairing to split a morphism's
code into objects representing its source
and target.
First, we can define morphism compositions for
finite digraphs as:
\begin{code}
pcompose (s1,t1) (s2,t2) | t1==s2 = (s1,t2)
pcompose _ _ = error "pcompose: bad morphisms"

is_pcomposable (s1,t1) (s2,t2) | t1==s2 = True
is_pcomposable _ _ = False
\end{code}

\begin{prop}
The composition of morphisms is associative and for every object {\tt o}, {\tt P
o o} acts as an identity morphism.
\end{prop}

Assuming morphisms are given by their positions {\tt m1} and {\tt m2} in the
multidigraph (sequence of pairs) representing the category {\tt c} encoded by
natural number {\tt n} we can define:
\begin{code}
ncompose n m1 m2 = as nat nat2 m where 
  c=as mdigraph nat n
  m=pcompose (c!!m1) (c!!m2)
\end{code}
which works as follows:
\begin{codex}
*ISO> as mdigraph nat 1234567890
[(1,0),(0,1),(1,0),(0,0),(1,0),(3,1),
 (0,0),(1,0),(0,1),(0,0),(0,1),(0,1)]
*ISO> pcompose (3,1) (1,0)
(3,0)
*ISO> ncompose 1234567890 5 2
5
*ISO> ncompose 1234567890 2 5
*** Exception: pcompose: bad morphisms
\end{codex}
The function {\tt trans} computes the irreflexive transitive closure of a
digraph while {\tt rtrans} adds identity pairs to it.
\begin{code}
rtrans ps = (ids ps) ++ (trans ps)

trans ps = sort $ nub $ trans2 ps where

  trans1 ps = nub [q|q<-qs,not (is_id q)] where
     is_id (x,y) = x==y 
     qs=ps++[pcompose p q|p<-ps,q<-ps,is_pcomposable p q]

  trans2 ps = if (l==l1) then ps else (trans2 ps1) where
    l=genericLength ps 
    ps1=trans1 ps
    l1=genericLength ps1
\end{code}
It works as follows:
\begin{codex}
*ISO> trans [(0,1),(1,2),(2,3)]
[(0,1),(0,2),(0,3),(1,2),(1,3),(2,3)]
*ISO> trans [(0,1),(1,2),(2,0)]
[(0,1),(0,2),(1,0),(1,2),(2,0),(2,1)]
*ISO> rtrans [(0,1),(1,2)]
[(0,0),(1,1),(2,2),(0,1),(0,2),(1,2)]
\end{codex}

\begin{code}
to_trans n = trans $ as digraph nat n

ntrans n = as nat digraph $ to_trans n

vertset ps = sort $ nub [z|(x,y)<-ps,z<-[x,y]]

ids ps = [(x,x)|x<-vertset ps]

pairs2graph ps = l where
  l=genericLength ps
  
gtest = map f (vertices x) where 
  (x,f,z)=graphFromEdges [(0,10,[10,20]),(1,10,[20]),(2,20,[10])]
  
\end{code}
\end{comment}

\section{Related work} \label{related}
The closest reference on encapsulating bijections
as a Haskell data type is \cite{bijarrows} 
and Conal Elliott's composable
bijections module \cite{bijeliot},
where, in a more complex setting,
Arrows \cite{hughes:arrows} are used 
as the underlying abstractions.
While our {\tt Iso} data type is similar
to the {\em Bij} data type in \cite{bijeliot} and
BiArrow concept of \cite{bijarrows},
the techniques for using such isomorphisms
as building blocks of an embedded composition
language centered around encodings
as Natural Numbers are new.

As the domains between which we define our
isomorphisms can be organized as categories,
it is likely that some of our constructs would benefit
from {\em natural transformation} \cite{matcat} and {\em n-category}
formulations \cite{Baez97anintroduction}. 

{\em Ranking} functions can be traced back to G\"{o}del numberings
\cite{Goedel:31,conf/icalp/HartmanisB74} associated to formulae. 
Together with their inverse {\em unranking} functions they are also 
used in combinatorial generation
algorithms
\cite{conf/mfcs/MartinezM03,knuth06draft,Ruskey90generatingbinary,Myrvold01rankingand}.
However the generic view of such transformations as hylomorphisms obtained compositionally
from simpler isomorphisms, as described in this paper,
is new.

Natural Number encodings of Hereditarily Finite Sets have 
triggered the interest of researchers in fields ranging from 
Axiomatic Set Theory and Foundations of Logic to 
Complexity Theory and Combinatorics
\cite{finitemath,kaye07,abian78,avigad97,DBLP:journals/mlq/Kirby07,DBLP:conf/foiks/LeontjevS00}.
Computational and Data Representation aspects of Finite Set Theory 
have been described in logic programming and theorem proving contexts 
in \cite{DBLP:journals/tplp/PiazzaP04,DBLP:conf/types/Paulson94}. 

Pairing functions have been used in work on decision problems as early as
\cite{robinson50,robinsons68b}. A
typical use in the foundations of mathematics is
\cite{DBLP:journals/tcs/CegielskiR01}.
An extensive study of various pairing functions and their 
computational properties is presented in 
\cite{DBLP:conf/ipps/Rosenberg02a}.

Various mappings from natural numbers to rational numbers are described 
in \cite{rationals}, also in a functional programming framework.

We have learned from Knuth's recent work on combinatorial
algorithms \cite{knuth06draft} the techniques related to
bitvector encodings of projection functions and boolean operations
and about BDDs and reduced ordered BDDs from Bryant's
seminal paper on the topic \cite{bryant86graphbased}.
However, the connection with pairing/unpairing functions
and the equivalence results of subsection \ref{equiv} are new.

The concepts of hereditarily finite functions and
permutations as well as their encodings, are
likely to be new, given that our sustained 
search efforts have not lead so far to anything
similar. 

Some other techniques, ranging from
factoradics to cons-lists and
functional binary numbers
to DNA encodings and dyadic rationals are
for sure part of the scientific commons. 
In that
case our focus was to express them as
elegantly as possible in a uniform framework.
In these cases as well, most of the time
it was faster to ``just do it'', by implementing
them from scratch in a functional programming 
framework, rather than adapting procedural 
algorithms found elsewhere.

\section{Conclusion} \label{concl}
We have shown the expressiveness of Haskell as a
metalanguage for executable mathematics, by describing
encodings
for functions and finite sets
in a uniform framework
as data type isomorphisms with a groupoid structure.
Haskell's higher order functions and recursion patterns
have helped the design of an embedded data transformation
language.
Using higher order combinators a 
simplified QuickCheck style random testing
mechanism has been implemented as
an empirical correctness test.
The framework has been extended
with hylomorphisms providing
generic mechanisms for encoding
Hereditarily Finite Sets and 
Hereditarily Finite Functions.
In the process, a few surprising
``free algorithms'' have emerged
as well as a generalization of
Ackermann's encoding to Hereditarily Finite 
Sets with Urelements. We plan to explore in
depth in the near future, some of the results
that are likely to be of interest in fields
ranging from combinatorics and boolean logic
to data compression and arbitrary precision
numerical computations.

\bibliographystyle{INCLUDES/splncs}
%\bibliographystyle{TOOLS/jfp}
%\bibliographystyle{abbrv}
%\bibliographystyle{plain}
%\bibliographystyle{plainnat}
\bibliography{INCLUDES/theory,tarau,INCLUDES/proglang,INCLUDES/biblio,INCLUDES/syn}

\section*{Appendix}

The code in the paper is organized in a module with the following dependencies:

\begin{codex}
module ISO where
import Data.List
import Data.Bits
import Data.Graph
import Data.Graph.Inductive
import Graphics.Gnuplot.Simple
import Data.Char
import Ratio
import Random
\end{codex}

\subsection*{Bit crunching functions} 

The function
bitcount computes the number of bits needed to represent an integer and
max\_bitcount computes the maximum bitcount for a list of integers.
\begin{code}
bitcount n = head [x|x<-[1..],(2^x)>n]
max_bitcount ns = foldl max 0 (map bitcount ns)
\end{code}

The following function convert a number to to binary, padded with 0s, up to maxbits.
\begin{code}
to_maxbits maxbits n = 
  bs ++ (genericTake (maxbits-l)) (repeat 0) where 
    bs=to_base 2 n
    l=genericLength bs
\end{code}

\subsection*{Primes}
The following code implements factoring function {\tt to\_primes} a primality
test ({\tt is\_prime}) and a generator for the infinite stream of prime numbers
{\tt primes}.

\begin{code}
primes = 2 : filter is_prime [3,5..]

is_prime p = [p]==to_primes p

to_primes n | n>1 = to_factors n p ps where 
  (p:ps) = primes

to_factors n p ps | p*p > n = [n]
to_factors n p ps | 0==n `mod` p = p : to_factors (n `div` p)  p ps 
to_factors n p ps@(hd:tl) = to_factors n hd tl
\end{code}

We will briefly describe here the functions used to visualize various data
types with the help of Haskell libraries providing interfaces to {\tt graphviz}
and {\tt gnuplot}.

\subsection*{Multiset Operations}
The following functions provide multiset analogues of the usual set operations,
under the assumption that multisets are represented as non-decreasing sequences.
\begin{code}
msetInter xs ys = sort (msetInter' xs ys)

msetInter' [] _ = []
msetInter' _ [] = []
msetInter' (x:xs) (y:ys) | x==y = 
  (x:zs) where zs=msetInter' xs ys
msetInter' (x:xs) (y:ys) | x<y = msetInter' xs (y:ys)
msetInter' (x:xs) (y:ys) | x>y = msetInter' (x:xs) ys

msetDif xs ys = sort (msetDif' xs ys)

msetDif' [] _ = []
msetDif' xs [] = xs
msetDif' (x:xs) (y:ys) | x==y = zs where 
  zs=msetDif' xs ys
msetDif' (x:xs) (y:ys) | x<y = (x:zs) where 
  zs=msetDif' xs (y:ys)
msetDif' (x:xs) (y:ys) | x>y = zs where 
  zs=msetDif' (x:xs) ys

msetSymDif xs ys = 
  sort ((msetDif xs ys) ++ (msetDif ys xs))

msetUnion xs ys = sort ((msetDif xs ys) ++ 
  (msetInter xs ys) ++ (msetDif ys xs))
  
msetIncl xs ys = xs==msetInter xs ys
 
\end{code}

\subsection*{Building a multigraph from a natural number using a function
associating to each natural number a sequence or set of natural numbers.}

\begin{code}
fun2g ns = nat2fgs nat2fun ns
set2g ns = nat2sgs nat2set ns
perm2g ns = nat2fgs nat2perm ns
pmset2g ns = nat2fgs nat2pmset ns
bmset2g ns = nat2fgs nat2bmset ns

nat2fg f n = nat2gx fun_edge f nat2pftree n :: Gr N Int

nat2fgs f ns = nat2gsx fun_edge f nat2pftree ns :: Gr N Int

nat2sg f n = nat2gx set_edge f nat2pftree n :: Gr N ()

nat2sgs f ns = nat2gsx set_edge f nat2pftree ns :: Gr N ()

set_edge xs (a,b,i) = (lookUp a xs,lookUp b xs,())

fun_edge xs (a,b,i) = (lookUp a xs,lookUp b xs,i)

nat2gx e f g n = mkGraph vs  (map (e xs) es) where 
  es=g f n
  (xs,vs)=labeledVertices es

nat2gsx e f g ns = mkGraph vs  (map (e xs) es)  where 
  es=nub (concatMap (g f) ns)
  (xs,vs)=labeledVertices es
  
labeledVertices es= (xs,vs) where  
  xs=fvertices es
  is=[0..(length xs)-1]
  vs = zip is xs
     
nat2pftree f n = nub (nat2pftreex f (n,n,0))

nat2pftreex f (_,n,_) = ps ++ (concatMap (nat2pftreex f) ps) where
  ps = nat2pfun f (n,n,0)

nat2pfun _ (_,0,_) = []
nat2pfun f (_,n,_) | n> 0 = ps where 
  ps = zipWith (\x i->(n,x,i)) (f n) [0..]

fvertices ps = (sort . nub) (concatMap f ps) where
  f (a,b,_) = [a,b]

lookUp n ns = i where Just i=elemIndex n ns
\end{code}

\subsection*{Building Inductive Graphs from Lists of Pairs}
We can build a graph directly from edges represented as pairs of small integers
as follows:
\begin{code}
edges2gr ::  [(N,N)] -> Gr Int ()

edges2gr es = mkGraph lvs les where 
  vs=[0..foldl max 0 (concatMap g es)]
  lvs=zip vs vs
  les=map f es
  f (x,y) = (fromIntegral x,fromIntegral y,())
  g (x,y) = [fromIntegral x,fromIntegral y]
\end{code}

When the set of vertices is sparse, vertice numbers are used as labels while
actual vertices become integers in [0..numberOf Vertices-1]
\begin{code}
pairs2gr ::  [(N,N)] -> Gr N ()

pairs2gr ps = mkGraph lvs les where 
  vs=to_vertices ps
  lvs=zip [0..] vs
  es=to_edges vs ps
  les=map f es
  f (x,y) = (x,y,())

to_vertices es = sort $ nub $ concat [[fst p,snd p]|p<-es]

to_edges vs ps = map (f vs) ps where
  f vs (x,y) = (lookUp x vs,lookUp y vs)
\end{code}

\subsection*{Generating labeled edge triplets by recursing over unpairing
functions} 

The following function represents a number as a set of triplets expressing
branches of decomposition with an unpairing function {\tt f}, for
instance, in the case of BDDs with function {\tt bitunpair}.

\begin{code}
unpairing_edges f tt = nub  (h f tt) where
  h _ tt | tt<2 = []
  h f n  = ys where
     (n0,n1)=f n
     ys= (n,n0,0):(n,n1,1):
           (h f n0) ++ 
           (h f n1)
\end{code}
The function works as follows:
\begin{codex}
*ISO> unpairing_edges bitunpair 42
[(42,0,0),(42,7,1),(7,3,0),(7,1,1),(3,1,0),(3,1,1)]
*JFISO> unpairing_edges pepis_unpair 42
[(42,0,0),(42,21,1),(21,1,0),(21,5,1),(5,1,0),(5,1,1)]
*ISO> 
\end{codex}

\subsection*{Generating labeled edge triplets by recursing over untupling
functions} 

The following function represents a number as a set of triplets expressing
branches of decomposition with an untupling function {\tt fk}, for
instance {\tt to\_tuple k}.

\begin{code}
untupling_edges f k l tt = nub  (h f k tt) where
  h _ _ tt | tt<l = []
  h f k n  = ys where
     ns = f k n
     ys = (zip3 (repeat n) ns [0..]) ++
          (concatMap (h f k) ns) 
  
\end{code}
The function works as follows:
\begin{codex}
*ISO> untupling_edges to_tuple 3 2 2008
[(2008,14,0),(2008,14,1),(2008,4,2),(14,2,0),(14,1,1),(14,1,2),
 (2,0,0),(2,1,1),(2,0,2),(4,0,0),(4,0,1),(4,1,2)]
\end{codex}

\subsection*{Building Inductive Graphs from hereditary base-k trees}
We will first build a set of labeled edges, recursing over expansion to
polynomials in base k.

\begin{code}
nat2edges k n = xs ++ (concatMap (expandEdge k) xs) where 
  p2e (c,e) = (n,e,c)
  xs= map p2e (nat2kpoly k n)

expandEdge k (_,e,_) | e < k = []
expandEdge k (_,e,_) = nat2edges k e
\end{code}
working as follows:
\begin{codex}
*ISO> nat2edges 3 42
[(42,1,2),(42,2,1),(42,3,1),(3,1,1)]
*ISO> nat2edges 3 2009
[(2009,0,2),(2009,2,1),(2009,3,2),(2009,5,2),(2009,6,2),(3,1,1),(5,0,2),(5,1,1),(6,1,2)]
\end{codex}

\subsection*{Building Inductive Graphs from Unpairing, Untupling and
Hereditary base-k Trees}

We can now turn a BDD as well as any other unpairing/untupling/hereditary base k
function generated tree into an inductive graph, as follows:
\begin{code}
to_unpair_graph f tt = nat2fun_graph (unpairing_edges f) tt

to_untuple_graph f k l tt = nat2fun_graph (untupling_edges f k l) tt

nat2fun_graph f n = nat2graph f n :: Gr N Int

to_hb_graph k n = nat2hb_graph (nat2edges k) n

nat2hb_graph f n = nat2graph f n :: Gr N N

nat2graph f n = mkGraph vs fs where
  es=f n
  (xs,vs)=labeledVertices es
  fs=map (fun_edge xs) es
\end{code}
The functions work as follows:
\begin{codex}
*ISO> to_unpair_graph bitunpair 42
0:0->[]
1:1->[]
2:3->[(1,1),(0,1)]
3:7->[(0,2),(1,1)]
4:42->[(1,3),(0,0)]

*ISO> to_unpair_graph pepis_unpair 42
0:0->[]
1:1->[]
2:5->[(1,1),(0,1)]
3:21->[(1,2),(0,1)]
4:42->[(1,3),(0,0)]

*ISO> to_untuple_graph to_tuple 3 2 2008
0:0->[]
1:1->[]
2:2->[(2,0),(1,1),(0,0)]
3:4->[(2,1),(1,0),(0,0)]
4:14->[(0,2),(2,1),(1,1)]
5:2008->[(2,3),(1,4),(0,4)]

*ISO> to_hbase_graph 4 123456789

0:1->[]
1:2->[]
2:3->[]
3:4->[(1,0)]
4:5->[(1,0),(0,0)]
5:7->[(1,0),(0,2)]
6:8->[(1,1)]
7:9->[(1,1),(0,0)]
8:10->[(1,1),(0,1)]
9:11->[(1,1),(0,2)]
10:12->[(1,2)]
11:13->[(1,2),(0,0)]
12:123456789->[(13,0),(12,2),(11,0),(10,0),(9,1),(8,2),
               (7,2),(5,2),(4,0),(2,0),(1,0),(0,0)]
\end{codex}

\subsection*{Visualization with graphviz}

\begin{code}   
gviz g = writeFile "iso.gv" 
  ((graphviz g "" (0.0,0.0) (2,2) Portrait)++"\n")

funviz f n = gviz (nat2fg f n)  

setviz f n = gviz (nat2sg f n)

eviz t n = gviz (edges2gr (as t nat n))

pviz t n = gviz (pairs2gr (as t nat n))

psviz ps = gviz (pairs2gr ps)

uviz f tt = gviz (to_unpair_graph f tt)

tviz f k tt = gviz (to_untuple_graph f k 2 tt)

pbviz k tt = gviz (to_untuple_graph to_sqbase k k tt)

hbviz k n = gviz (to_hb_graph k n)

fviz t n = gviz (es2g (as t nat n))

es2g :: [(N, N)] -> Gr () Int

es2g es = mkGraph lvs les where (lvs,les)=es2ls es

es2ls es = (lvs,les) where
  es' = map (\(x,y)->(fromIntegral x,fromIntegral y)) es
  g ((x,y),l)=(x,y,l)
  les=map g (zip es' [0..length es-1]) 
  vs = [0..foldr max 0 (concatMap f es')]
  lvs=map (\x->(x,())) vs
  f (from,to)=[from,to]
\end{code}

\subsection*{Plotting with gnuplot}

\begin{code}
plot3d f xs ys = plotFunc3d [Title ""] [] xs ys f

plotop op m= plot3d op xs xs where xs=[0..2^m-1]

cplot3d f = plot3d (curry f)

pair3d pf m | m<=8 = cplot3d pf ls ls where ls=[0..2^m-1]

plotpairs m | m<=2^8 = cplot3d bitpair ls ls where ls=[0..m-1]

plotdyadics m = plotList 
  [Title "Dyadics"] 
  (map (fromRational . (as dyadic nat)) [0..m-1])

sizes_to m t = map (size_as t) [0..m-1]

plot_hf m = plotLists [Title "Bit, BDD, HFF, HFS, and HFP sizes"] 
  ( 
    [bits_to m,bsizes_to m] ++ 
    (map (sizes_to m) [hff,hfs,hfm,hfp])
  )

plot_hf1 m = plotLists [Title "Bit, HFF, HFS, HFM and HFP sizes"] 
  ( 
    [bits_to m] ++ 
    (map (sizes_to m) [hff,hfs,hfm,hfp])
  )
  
plot_good m = plotLists [Title "Bit and HFF sizes"] 
  ( 
    [bits_to m] ++ 
    (map (sizes_to m) [hff])
  )
  
plot_best m = plotLists [Title "Bit, BDD and HFF and HFF' sizes"] 
  ( 
    [bits_to m,bsizes_to m] ++ 
    (map (sizes_to m) [hff,hff'])
  )

plot_worse m = plotLists [Title "HFM, HFS and HFP sizes"] 
  ( 
    (map (sizes_to m) [hfm,hfs,hfp])
  )

plot_hfs_hfp m = plotLists [Title "HFS and HFP sizes"] 
  ( 
    (map (sizes_to m) [hfs,hfp])
  )
  
plot hf m = plotx [hf] m

plotx hfx m = plotLists [Title "HF tree size"] 
  ( 
    (map (sizes_to (2^m-1)) hfx)
  )

-- plots pairs
pplot f m = plotPath [] (map (to_ints . f) [0..2^m-1]) 

zplot f m = plotPath [] (map (to_ints . f) [-(2^m)..2^m-1]) 

to_ints (i,j)=(fromIntegral i,fromIntegral j)

diplot n = plotPath [] (map to_ints (as digraph nat n))

bsize_of n = robdd_size (as rbdd nat n)

bsizes_to m = map bsize_of [0..m-1]

bits_to m = map s [0..m-1] where s n = genericLength (as bits nat n)

plot_linear_sparseness m = plotLists [Title "Linear Sparseness"] 
  [(map (linear_sparseness fun) [0..m-1]),
   (map (linear_sparseness pmset) [0..m-1]),
   (map (linear_sparseness mset) [0..m-1]),
   (map (linear_sparseness set) [0..m-1]),
   (map (linear_sparseness perm) [0..m-1])]


plot_sparseness m = plotLists [Title "Recursive Sparseness"] 
  [(map (sparseness hff_pars) [0..m-1]),
   (map (sparseness hfpm_pars) [0..m-1]),
   (map (sparseness hfm_pars) [0..m-1]),
   (map (sparseness hfs_pars) [0..m-1]),
   (map (sparseness hfp_pars) [0..m-1])]

plot_sparseness1 m = plotLists 
  [Title "Recursive Sequence vs. Multiset Sparseness"] 
  [
   (map (sparseness hff_pars) [0..m-1]),
   (map (sparseness hfpm_pars) [0..m-1])
  ]
  
plot_sparseness2 m = plotLists [Title "Recursive Multiset Sparseness"] 
  [
   (map (sparseness bhfm_pars) [0..m-1]),
   (map (sparseness hfm_pars) [0..m-1])
  ]

plot_sparseness3 m = plotLists [Title "Recursive Multiset Sparseness"] 
  [
   (map (sparseness hff_pars) [0..m-1]),
   (map (sparseness hff_pars') [0..m-1])
  ]


plot_sparseness4 m = plotLists 
  [Title "Recursive Multiset vs Multiset with Primes Sparseness"] [
   (map (sparseness hfm_pars) [0..m-1]),
   (map (sparseness hfpm_pars) [0..m-1])
  ]

plot_sparseness5 m = plotLists 
  [Title "Recursive Multisets vs. Sequences"] [
   (map (sparseness hff_pars) [0..m-1]),
   (map (sparseness hfm_pars) [0..m-1])
  ]
        
plot_selfdels m = plotLists 
   [Title "Self-delimiting codes: Undelimited vs. Elias vs. HFF"] 
   [(map (genericLength . (as bits nat)) [0..m-1]),
    (map (genericLength . (as elias nat)) [0..m-1]),
    (map (genericLength . (as hff_pars nat)) [0..m-1])]

plot_pairs_prods unpF m = plotLists [Title "Pairs vs. products"]  
   [ms,prods] where
     ms=[1..m]
     pairs=map unpF ms
     prods=map prod pairs where prod (x,y)=2*x*y
 
plot_lifted_pairs m = 
   plotLists [Title "Lifted pairs"]  [us0,us1] where 
     ms=[0..m-1]
     pairs=map bitunpair ms
     us0=map fst pairs
     us1=map snd pairs
     
plot_lifted_pairs1 m = 
   plotLists [Title "Lifted pairs and products"]  [ps,s0,s1,xys] where 
     ms=[0..m-1]
     pairs=map bitunpair ms
     us0=map fst pairs
     us1=map snd pairs
     ps=zipWith (*) us0 us1
     s0=map (^2) us0
     s1=map (^2) us1
     xys=map f pairs where
       f (x,y) = x*y
 
plot_primes_prods m = plotLists [Title "Primes vs. products"]  
  [ps,prods] where 
     ms=[0..m]
     ps=genericTake m primes
     pairs=map bitunpair ps
     prods=map prod pairs where prod (x,y)=2*x*y     
   
plot_hypers_prods m = plotLists [Title "Hyper-primes vs. products"]
   [ps,prods] where 
     ms=[0..m]
     ps=genericTake m (hyper_primes bitunpair)
     pairs=map bitunpair ps
     prods=map prod pairs where prod (x,y)=2*x*y  
\end{code}

\subsection*{Generated Figures}

\begin{code}
hset n=gviz  (nat2sg nat2set n)
hfun n=gviz (nat2fg nat2fun n)

hmset n=gviz (nat2fg nat2mset n)
hperm n=gviz (nat2fg nat2perm n)
dig n =pviz digraph n
dig' n =pviz digraph' n
plotdag n = pviz dag n

hset' n=gviz  (nat2sg nat2set' n)
hfun' n=gviz (nat2fg nat2ftuple n)
hmset' n=gviz (nat2fg nat2mset' n)
hpset' n=gviz (nat2sg ((as set mset) . nat2pmset) n)

unp' tt= uviz unpair' tt
unpp' n=pplot unpair' n
unpp n=pplot bitunpair n

---cunp tt= uviz cunpair tt
cunpp n=pplot cunpair n


p3d' m = pair3d pair' m 

p3d pf m = pair3d pf m 

ukl k l n = uviz (unpairKL k l) n

uklp k l n = pplot (unpairKL k l) n

klp k l m = pair3d (pairKL k l) m

f4=gviz (nat2fg nat2perm 2009)

f6=plotpairs 64
f7=plotdyadics 256

f8=plot_best (2^6)
f8a=plot_good (2^10)

f9=plot_worse (2^10)
f9a=plot_hfs_hfp (2^16)
f9b=plot_hfs_hfp (2^17)
f10=plot_hf (2^8)
f10a=plot_hf1 (2^8)

f11a=plot_linear_sparseness (2^7)
f11=plot_sparseness (2^8)
f11b=plot_sparseness1 (2^8)
f11c=plot_sparseness2 (2^10)

f12=plot_sparseness (2^14)

f13=plot_sparseness (2^17)

f14=plot_selfdels (2^7)

fs1 m=plotLists 
  [Title "Representation Sizes"] 
  [bs,es,hffs,hfms,hfss,hfps] where 
       bsize n=genericLength (as bits nat n)
       bs=map bsize [0..2^m-1]
       esize n=genericLength (as elias nat n)
       es=map esize [0..2^m-1]      
       hffs=parsizes_as hff m
       hfms=parsizes_as hfm m
       hfss=parsizes_as hfs m
       hfps=parsizes_as hfp m

fs1a m=plotLists 
  [Title "Representation Sizes"] 
  [bs,es,hffs] where 
       bsize n=genericLength (as bits nat n)
       bs=map bsize [0..2^m-1]
       esize n=genericLength (as elias nat n)
       es=map esize [0..2^m-1]
       hffs=parsizes_as hff m
 
fs1b m=plotLists 
  [Title "Representation Sizes"] 
  [hfms,hfss,hfps] where 
       hfms=parsizes_as hfm m
       hfss=parsizes_as hfs m
       hfps=parsizes_as hfp m

             
f15=plotList [] (sparses_to (2^18))

-- see also plot3d f m
plotf f m = plotList [] (map f [0..2^m-1])

plotss xss = plotFunc3d [] [] ks ys f where
  ks=[0..length xss-1]
  ls=map length xss
  len=foldl max 0 ls
  ys=[0..len-1]
  zss= map (\xs->take len (xs++repeat 0)) xss
  f x y =   (zss!!(fromIntegral x))!!(fromIntegral y)
\end{code}

\begin{code}

f16=gviz (nat2fgs nat2fun [0..7])

arp24 i =468395662504823 + 205619*23*i

arps24 = map arp24 [0..23]

arp25 i = 6171054912832631 + 366384*23*i

arps25 = map arp25 [0..24]

f17 = gviz (fun2g arps24)
f17a = gviz (fun2g arps25)

f18 = gviz (fun2g [2^65+1,2^131+3])

f18a = gviz (set2g [2^65+1,2^131+3])


f19 = gviz (fun2g [0..7])

f20 = gviz (pmset2g [0..7])

f20a = gviz (bmset2g [0..7])

f21 = gviz (set2g [0..7])

f22 = gviz (perm2g [0..7])

isoigraph n = psviz (to_igraph (as hypergraph nat n))
isobi n = psviz (as bipartite nat n)

g1 tt= uviz bitunpair tt
g2 tt= uviz pepis_unpair tt
g2' tt= uviz pepis_unpair' tt
g3 tt= uviz rpepis_unpair tt


isofermat=uviz mset_unpair 65537
isofermat1=uviz mset_unpair 142781101
isonfermat=uviz mset_unpair 34897

isopairs = plot_pairs_prods bitunpair 256
misopairs = plot_pairs_prods mset_unpair 256

isoprimes = plot_primes_prods 256
isohypers = plot_hypers_prods 256

isounpair1=pplot bitunpair 10
isounpair2 n=pplot pepis_unpair n
isounpair3=pplot mset_unpair 10
isounpair4=pplot xorunpair 10
isoyunpair n =pplot yunpair n

isozunpair n=zplot zunpair n
isorepair i1 i2 m = plotList [] (map (repair i1 i2) [0..2^m-1])

isobij f m = plotList [] (map f [0..2^m-1])

-- xorbij is the diff between id and f 
isoxbij f m = plotList [] (map g [0..2^m-1]) where g=xorbij f

-- bijection N->N using multisets and factorings
ms2pms n = as nat pmset (as mset nat n)

pms2ms n = as nat mset (as pmset nat n)

-- same but iterating k times
kms2pms 0 n = n
kms2pms k n = ms2pms (kms2pms (k-1) n) 

kpms2ms 0 n = n
kpms2ms k n = pms2ms (kpms2ms (k-1) n) 

lms k m = [x|x<-[0..2^m-1], kms2pms k x < kpms2ms k x]

xms k m = [x|x<-[0..2^m-1],kms2pms k x < x]

eqms k m = [x|x<-[0..2^m-1],kms2pms k x == x]

xpms k m = [x|x<-[0..2^m-1],kpms2ms k x < x]

eqpms k m = [x|x<-[0..2^m-1],kpms2ms k x == x]

qms k m = 
 [(toRational (kpms2ms k x)) - (toRational (kms2pms k x))|x<-[1..2^m-1]]

q1 k m = plotList []  (qms k m)

q2 k m = plotLists []  
  [map (kms2pms k) xs,map (kpms2ms k) xs] where 
    xs = [0..2^m-1]

mult_vs_pairing p1 p2 = fromRational ( (p1*p2) % (ppair bitpair (p1,p2)))
mult_vs_mset_pairing p1 p2 = fromRational ((p1*p2) % (ppair mset_pair (p1,p2)))


q3 n = plotFunc3d 
        [Title "Prime Multiplication vs. Prime Pairing"] [] 
          ps ps  mult_vs_pairing where
            ps=genericTake n primes

q4 n = plotFunc3d 
  [Title "Prime Multiplication vs. Prime Multiset Pairing"] [] 
        ps ps mult_vs_mset_pairing where
        ps=genericTake n primes
       
n4a n = plotFunc3d [Title "Multiplication"] [] 
        ps ps (*) where
          ps=[0..2^n-1]

n4b n = plotFunc3d [Title "Multiset Pairing"] [] 
        ps ps (curry mset_pair) where
          ps=[0..2^n-1]


n4c n = plotFunc3d [Title "mprod operation"] [] 
        ps ps (mprod) where
          ps=[0..2^n-1]

n4d n = plotFunc3d [Title "pmprod' operation"] [] 
        ps ps (pmprod') where
          ps=[0..2^n-1]

n4e n = plotFunc3d [Title "mprod' operation"] [] 
        ps ps (mprod') where
          ps=[0..2^n-1]


n4f n = plotFunc3d [Title "mprod' x y/ x * y"] [] 
        ps ps (\x y->fromRational ((mprod' x y) % (x*y))) where
          ps=[1..2^n]

mplot f ps = plotFunc3d [Title "product operation"] [] ps ps f
 
dplot f g ps = plotFunc3d [Title "division comparison of operations"] [] 
        ps ps (\x y->fromRational ((f x y) % (g x y))) where

nplot f n = mplot f [1..2^n] 
rplot f n = mplot f (genericTake n primes)

ndplot f g n = dplot f g [1..2^n] 
rdplot f g n = dplot f g  (genericTake n primes)
                    
expMexp k m = plotLists []  
   [map (\x->x^k) xs, map (\x->mexp' x k) xs] where 
   xs = [0..2^m]
    
p4a n = plotFunc3d [Title "Prime Multiplication"] [] 
        ps ps (*) where
          ps=genericTake n primes

p4b n = plotFunc3d [Title "Prime Multiset Pairing"] [] 
        xs ys (curry mset_pair) where
        ps=genericTake n primes
        xs=ps
        ys=ps

p4c n = plotFunc3d [Title "mprod on primes"] [] 
        xs ys (mprod) where
        ps=genericTake n primes
        xs=ps
        ys=ps

p4d n = plotFunc3d [Title "pmprod on primes"] [] 
        xs ys (pmprod) where
        ps=genericTake n primes
        xs=ps
        ys=ps
 
 
p4f n = plotFunc3d [Title "mprod' x y/ x * y"] [] 
        ps ps (\x y->(mprod' x y) % (x*y)) where
          ps=genericTake n primes
                         
q4c n = plotFunc3d [Title "Prime Pairing"] [] 
        ps ps (curry bitpair) where
          ps=genericTake n primes
                
q5 n = plotLists 
  [Title "Prime Multiplication vs. Prime Pairing curves"] 
  [prods,pairs] where 
    us= map bitunpair [0..2^n-1]
    (xs,ys) = unzip us  
    ps=primes
    xs'=map (from_pos_in ps) xs
    ys'=map (from_pos_in ps) ys
    prods = zipWith (*) xs' ys'
    us'=zip xs' ys'
    pairs= map (ppair mset_pair) us'

plot_gauss_op f m = plotFunc3d title [] zs zs (curry f) where
  title=[Title "Gauss Integer operations through Pairing Functions"]
  zs=[-2^m..2^m-1]

gsum m = plot_gauss_op gauss_sum m
gdif m = plot_gauss_op gauss_dif m

gprod m = plot_gauss_op gauss_prod m

compose_nperm l nf nx = ps where
   fs=nth2perm (l,nf)
   xs=nth2perm (l,nx)
   ys=applyPerm fs xs
   (_,ps)=perm2nth ys

ip n = as nat perm cs where
  bs=as perm nat n
  cs=invertPerm bs

rp n = as nat perm cs where
  bs=as perm nat n
  cs=reverse bs
 
ipb = ip . ib
ibp = ib . ip
  
--permPow l p k = 

-- complement borrowed from bits
ib n = as nat bits cs where
  bs=as bits nat n
  cs=invertBits bs

-- complement in {0,1}^*  
invertBits bs = map (\x->if 0==x then 1 else 0) bs
  
pc1 l = plotFunc3d [Title "Product as permutations"] 
  [] ns ns (\x y->compose_nperm l (fromIntegral x) (fromIntegral y)) where 
    lim=product [1..l] 
    ns=[0..lim-1]


-- nat to nat bijections
pflip u p n = p (y,x) where (x,y) = u n
 
pf = pflip pepis_unpair pepis_pair
bf = pflip bitunpair bitpair
      
xorunpair n = (x `xor` y,y) where (x,y)=bitunpair n

xorpair (x,y) = bitpair (x `xor` y,y)

yunpair n = (x `xor` y,y) where (x,y)=pepis_unpair' n

ypair (x,y) = pepis_pair' (x `xor` y,y)

xb = bitpair . xorunpair

nr = (as nat fun) . (fit reverse nat)

di n = as nat digraph (map rev ps) where 
  ps=as digraph nat n
  rev (x,y)=(y,x)

xorbij f n = n `xor` (f n)

enctest w = isoDecode bs pwd (isoEncode bs pwd w) where 
  pwd="eureka"
  bs=bijlist

isoDecode bs pwd txt =  encodeWith bs reverse pwd txt

isoEncode bs pwd txt = encodeWith bs id pwd txt

bijlist = [di,bf,ip,xb,ib,rp,nr,(xbij 2 3),(xbij 3 4)]

encodeWith bs r pwd txt = as string nat ctxt where 
  ntxt = as nat string txt
  npwd = as nat string pwd
  b x = npwd `xor` x
  ctxt = foldr (.) id (r (pwd2bs npwd (b:bs))) ntxt

pwd2bs npwd bs = newbs where
  l=genericLength bs
  lfact=product [1..l]
  mpwd=npwd `mod` lfact
  wperm = nth2perm (l,mpwd)
  newbs=applyPerm wperm bs

combWith f xs ys = [f x y|x<-xs,y<-ys] 

comb f m = sort (combWith f xs xs) where xs=[0..2^m-1]

\end{code}

\begin{comment}
\begin{code}
     
-- tests

refl1 x=
  as nat set $
  as set fun $
  as fun funbits $
  as funbits pbdd $
  as pbdd hfs $
  as hfs hff $
  as hff uhfs $
  as uhfs bits $
  as bits bdd $ 
  as bdd nat x

refl2 x=
  as nat bdd $
  as bdd bits $ 
  as bits uhfs $
  as uhfs hff $
  as hff hfs $
  as hfs pbdd $
  as pbdd funbits $
  as funbits fun $
  as fun set $
  as set nat x

\end{code}

\begin{codex}
% GP experiments

a=(a1,a2)
b=(b1,b2)
||
\/
ab=(a1,b2)
ba=(b1,a2)
||
\/
a=(a1,a2)
b=(b1,b2)
\end{codex}

\begin{code}
cross = bitpair . cross2 . bitunpair

cross2 (a,b) = (ab,ba) where
  (a1,a2)  = bitunpair a
  (b1,b2) = bitunpair b
  ab = bitpair (a1,b2)
  ba = bitpair (b1,a2)

repair iso1 iso2 n =
  as nat iso2 (as iso1 nat n)

rep1 = repair nat2 pnat2

rep2 = repair pnat2 nat2

plotrep m = plotList [Title "Re-pairing"] (map f xs) where 
  xs=[0..2^m-1]
  f =(as nat fun) . reverse . (as fun nat)
   
main = print (take 16 (hyper_primes mset_unpair))

pchain unpairF pairG = pairG . unpairF

plotHill t n = plotList [] (hill t n)

plotHills t m = plotss (map (hill t) [0..2^m-1])

hfsHills m = plotHills hfs_pars m

data BinT  = Vr Int | Nd BinT BinT deriving (Show, Eq)

-- binary tree generator
bintrees n = bt n 0 
        
bt 1 k = [Vr k]
bt n k = [Nd l r | i<-[1..n-1], l <- bt i k, r <- bt (n-i) (k+i)]

lsum x y = a+b where (a,b)=bitunpair ((bitpair (0,x)) + (bitpair (0,y)))

-- pairings and involutions
coPair invF pF (x,y) = invF (pF (invF x, invF y))
coUnpair invF uF z = (invF x,invF y) where (x,y)=uF (invF z) 


-- multiplication and pairing/tupling

guntriple  z=(pred g,pred x,pred y) where 
  (a,b)=mset_unpair z
  a'=succ a
  b'=succ b
  g=gcd a' b'
  x=a' `div` g
  y=b' `div` g

gtriple (g,x,y) = z where
  g'=succ g
  x'=succ x
  y'=succ y
  a=x'*g'
  b=y'*g'
  z=mset_pair (pred a,pred b)  
  
rprod x y = (m,z) where
 p=mset_pair (x,y)
 m=x*y
 (q,r)=quotRem (1+p) (1+m)
 z=bitpair (q,r)

qprod x y = (1+p)%(1+x*y) where
  p=mset_pair (x,y)

qfig m = plotop qprod m  

-- todo: rebase b in p*q-1
prunpair 1 = (1,1)
prunpair z = (a,b) where
  (pq,rs)=splitAt 2 (reverse (1:(to_primes z)))
  a=product pq
  b=product rs

--invF :: [I]->[[I]]
invF xs = map (map snd) zss where
  l=genericLength xs
  ys=sort (zip xs [0..l-1])
  zss=groupBy (\x y->fst x== fst y)  ys
  
subsets [] = [[]]
subsets (x:xs) = [zs|ys<-subsets xs,zs<-[ys,(x:ys)]]
 
sset t n = map (as nat t) (subsets (as t nat n)) 

tpair x y = z where -- ((x,to_base 2 x),(y',to_base 2 y')) where
   n=max (ilog22 x) (ilog22 y)
   y'=shiftL y (fromIntegral (exp2 n))
   z=x .&. y' 

ilog22 x = head [i |i<-[0..], exp22 i > x]

ilog2 x = head [i |i<-[0..], exp2 i > x]

exp22 = exp2 . exp2

exp2 :: N->N
exp2 n = bit (fromIntegral n)

ttpair x y = z where
  xs=as bits1 nat x
  ys=as bits1 nat y
  l=genericLength xs
  r=genericLength ys
  m=max l r
  m'=exp2 (ilog2 m)
  xs'=genericTake m' (xs ++ repeat 0)
  ys'=genericTake m' (ys ++ repeat 0)
  xs''=dropLast xs' 
  ys''=dropLast ys' 
  zs=xs'++ys''
  z=as nat bits1 zs

--dropLast = reverse . tail . reverse
  
txpair a b = z where
   x=a
   y=b
   n=max (ilog22 x) (ilog22 y)
   y'=(exp22 n)*y
   x'=x .&. ((exp22 n)-1)
   z=x' .|. y' 

{-
data PL a = 
  Atom a | Tie (PL a) (PL a) | Zip (PL a) (PL a) 
  deriving (Eq,Read,Show)

pl2l (Atom a) = (0,[a])
pl2l (Tie x y) = (pl2l x) ++ (pl2l y)


data Op a b= Tie a b| Zip a b deriving (Eq,Read,Show)
data PF a = At a | PF (Op (PF a) (PF a)) deriving (Eq,Read,Show)

data PListF f a = Zero a | Succ (f (a , a )) deriving (Eq,Read,Show)
-}

fbpair x y = z where
  xs=as bits nat x
  ys=as bits nat y
  lx=genericLength xs
  bs=to_base1 lx
  zs=bs++xs++ys
  z=as nat bits zs
 
to_base1 x = (replicate (x-1) 0) ++ [1]

orderTag x y | x<y = (0,x,y-x-1)
orderTag x y = (1,y,x-y)  

dropLast = reverse . tail . reverse
  
pair_mn v m n l r =
  ite_ (var_mn m n v) l r

pair_n v n (l,r) = pair_mn v (bigone n) n l r
unpair_n v n tt | tt <= m= unpair_mn v m n tt where m=bigone n

pairn n (l,r) = pair_n (n-1) n (l,r)
unpairn n tt = unpair_n (n-1) n tt

pair0 n (l,r) = pair_n 0 n (l,r)
unpair0 n tt = unpair_n 0 n tt



    
\end{code}
\end{comment}

\end{document}
